{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6fc10208-7733-4000-8adf-2019708b2c2b",
      "metadata": {
        "id": "6fc10208-7733-4000-8adf-2019708b2c2b"
      },
      "source": [
        "## Prerequisites\n",
        "Before we start, make sure you have the following:\n",
        "\n",
        "Access to GPUs (preferably 80GB or more since videos require high sequence lengths).\n",
        "Familiarity with Hugging Faceâ€™s Transformers library.\n",
        "Pre-install necessary packages by running the below.\n",
        "\n",
        "From video decoders you can install only one, the one you will use. Below I will provide helper functions to read videos using any of the three libraries, yet the default is decord which I found to be x8-10 faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b4c3ad0-0753-4474-a916-042a4b04746f",
      "metadata": {
        "id": "3b4c3ad0-0753-4474-a916-042a4b04746f"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q transformers accelerate bitsandbytes peft dataset\n",
        "!pip install -q av decord opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5be98cd5-0546-4938-894b-0a3128beb7f8",
      "metadata": {
        "id": "5be98cd5-0546-4938-894b-0a3128beb7f8"
      },
      "source": [
        "## Fine-tune LLaVa-NeXT-Video on  dataset\n",
        "In this notebook, we are going to fine-tune the LLaVa-NeXT-Video model on ShareGPTVideo dataset which is a video captioning dataset. Note that video datasets usually require a lot of hard disk memory to download the videos, but we'll try to not save videos in memory but rather discard after processing the inputs.\n",
        "\n",
        "LLaVa-NeXT-Video is a new Large Vision-Language Model that enables interaction with videos and images. The model is based on a previuos series of models: [LLaVa-NeXT](https://huggingface.co/docs/transformers/main/en/model_doc/llava_next) that was trained exclusively on image-text data. The architecutre is same as in LLaVa-NeXT and is a decoder-based text model that takes concatenated vision hidden states with text hidden states.\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1fVg-r5MU3NoHlTpD7_lYPEBWH9R8na_4\">\n",
        "\n",
        "\n",
        "LLaVA-NeXT surprisingly has strong performance in understanding video content with the AnyRes technique that it uses. The AnyRes technique naturally represents a high-resolution image into multiple images. This technique is naturally generalizable to represent videos because videos can be considered as a set of frames (similar to a set of images in LLaVa-NeXT). The current version of LLaVA-NeXT for videos has several improvements:\n",
        "\n",
        "- LLaVA-Next-Video, with supervised fine-tuning (SFT) on top of LLaVA-Next on video data, achieves better video understanding capabilities and is the second best-performing model among open-source models on [VideoMME bench](https://arxiv.org/pdf/2405.21075)\n",
        "- LLaVA-Next-Video-DPO, which aligns the model response with AI feedback using direct preference optimization (DPO), shows further performance boost.\n",
        "\n",
        "\n",
        "In this notebook we'll use the [LLaVa-NeXT-Video-7b-hf](https://huggingface.co/llava-hf/LLaVA-NeXT-Video-7B-hf) checkpoint\n",
        "\n",
        "- LLaVA-Next-Video [documentation](https://huggingface.co/docs/transformers/main/en/model_doc/llava_next_video)\n",
        "- LLaVA-Next-Video [checkpoints on the hub](https://huggingface.co/collections/llava-hf/llava-next-video-6666a9173a64c7052930f153)\n",
        "- LLaVA-Next-Video [project page](https://github.com/LLaVA-VL/LLaVA-NeXT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d2f666-cbe6-4556-a5cd-2206c27a0028",
      "metadata": {
        "id": "f4d2f666-cbe6-4556-a5cd-2206c27a0028"
      },
      "source": [
        "## Define variables\n",
        "We'll first set some variables useful througout this notebook and doo all the necessary imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae9f053-d1f6-4baf-8b08-756329942eb1",
      "metadata": {
        "id": "eae9f053-d1f6-4baf-8b08-756329942eb1",
        "outputId": "25bb0810-84d3-4af3-f997-1cc7596706b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-27 08:39:59.358137: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-27 08:40:00.287781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import av\n",
        "import fsspec\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "from transformers import Trainer, TrainingArguments, Seq2SeqTrainingArguments, DataCollatorForLanguageModeling\n",
        "from transformers import AutoProcessor, BitsAndBytesConfig, LlavaNextVideoForConditionalGeneration\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from huggingface_hub import snapshot_download, hf_hub_download, HfFileSystem\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 4\n",
        "NUM_FRAMES = 8 # more frames -> more VRAM needed\n",
        "DATASET_PATH = \"/home/raushan\" # path where to save the dataset\n",
        "OUTPUT_DIR = \"/home/raushan\" # path where to save the checkpoints\n",
        "MODEL_ID = \"llava-hf/LLaVa-NeXT-Video-7b-hf\"\n",
        "REPO_ID = \"RaushanTurganbay/LLaVa-NeXT-Video-demo\" # Change to your hf-hub repo\n",
        "\n",
        "USE_LORA = False\n",
        "USE_QLORA = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11dcfbc3-46da-4413-a3f1-095469fd147a",
      "metadata": {
        "id": "11dcfbc3-46da-4413-a3f1-095469fd147a"
      },
      "source": [
        "## Prepare dataset\n",
        "\n",
        "We will start by downloading and processing the dataset. Downloading all the videos from ShareGPTVideo might require more than 900 GB of memory in hard disk to donwload zip-files (unzipping them will require more memory), so we'll try to download mini-batch of videos in temp directory and delete after we're done. Note that this will stil require some meory to hold temp dirrectory and cache the processed dataset.\n",
        "\n",
        "The datasets in the hub are usually a [DatasetDict](https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.DatasetDict) where keys are data-split and values are `Dataset` objects. We can inspect the dataset layoiut but simply printing it and see that ShareGPTVideo consists of video path and a set of captions for each video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da82ca2-e1db-4a7c-878f-aeed972ba9e6",
      "metadata": {
        "id": "5da82ca2-e1db-4a7c-878f-aeed972ba9e6"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"ShareGPT4Video/ShareGPT4Video\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc5ff9e-6685-4e1d-b2c1-b360e5888fe3",
      "metadata": {
        "id": "ebc5ff9e-6685-4e1d-b2c1-b360e5888fe3",
        "outputId": "3f33ebf8-d577-49ab-bca3-dcc3dc78bc25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['video_id', 'video_path', 'timestamp', 'keyframe', 'captions'],\n",
              "        num_rows: 40178\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e147c649-f8aa-4243-b228-6f7aeb761cc9",
      "metadata": {
        "id": "e147c649-f8aa-4243-b228-6f7aeb761cc9",
        "outputId": "9bf4c8a1-5488-42b0-c43e-5ed3b65d419c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'video_id': '02bd228227979a5663a155011f5e3740853f729d68bc12f8fefc75eeb7630379',\n",
              " 'video_path': 'pixabay/02bd228227979a5663a155011f5e3740853f729d68bc12f8fefc75eeb7630379.mp4',\n",
              " 'timestamp': ['00:00:00.000', '00:00:04.000'],\n",
              " 'keyframe': [0.0, 2.0, 4.0],\n",
              " 'captions': [{'idx': '1',\n",
              "   'content': \"The frame displays a person with a complexion that appears fair, as indicated by the visible shoulders and upper chest. The individual is clad in a dark tank top, the straps of which are slender, overlying the person's shoulders, suggesting a casual or athletic attire. There is a conspicuous contrast between the subject's light skin tone and the tank top's dark fabric, as well as against the background, which is predominantly dark. The background offers no discernible detail, thereby isolating the subject as the focal point. The lighting in the frame seems to be directed from the front, casting subtle shadows and highlighting the musculature and contours of the visible skin. The posture of the person is upright and static, with no movement evident in the frame. There is no camera movement discernible from this single frame.\",\n",
              "   'time_stamp': '0.00'},\n",
              "  {'idx': '2',\n",
              "   'content': \"In the second frame, the person's posture has changed slightly; the upper body appears to have leaned forward, causing a subtle change in the shadowing across the skin and the angle of the shoulders. The tank top remains unchanged in its position. The person's right shoulder seems to have moved forward, while the left shoulder has rolled back, indicating a potential initiation of movement or gesture. The dark backdrop continues to envelop the subject with no discernible features, maintaining focus on the individual's upper body. The front-facing lighting still accentuates the contours and definition of the visible skin. There's no evident camera movement, the angle and framing remain consistent with the previous frame, indicating a static shot.\",\n",
              "   'time_stamp': '2.00'},\n",
              "  {'idx': '3',\n",
              "   'content': \"In this third frame at the four-second mark, the subject has settled back into a more neutral position, with less of the forward inclination that was noted in the previous frame. This suggests either a return to the initial posture or the completion of a small, contained motion. There's a slight shift in the lighting as well, as the shadows cast on the person's shoulders appear marginally softer, giving their skin a more even tone. The tank top straps have maintained their position, and there's no significant change in their appearance. The backdrop remains consistently dark and featureless, focusing the viewer's attention solely on the individual. The camera's perspective is unchanged, further indicating a static setup without any panning or zooming actions.\",\n",
              "   'time_stamp': '4.00'},\n",
              "  {'idx': '-1',\n",
              "   'content': \"The video features a person with a fair complexion, dressed in a dark tank top, against a dark, featureless background. Initially, the individual is in an upright and static position with direct lighting accentuating their skin's contours. As the video progresses, the person slightly leans forward, altering the shadow and angle on their shoulders, hinting at the start of a motion or gesture. This motion involves the person's right shoulder moving forward while the left rolls back. Shortly after, the individual returns to a more neutral and less inclined posture, suggesting the completion or reversal of the small movement. Throughout, the lighting slightly shifts, softening the shadows on the person's skin, and there is no camera movement, maintaining a static shot with a consistent angle and framing that keeps the focus exclusively on the individual's upper body.\",\n",
              "   'time_stamp': None}]}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b716b0-716b-43a6-b80d-da11d416a7ee",
      "metadata": {
        "id": "91b716b0-716b-43a6-b80d-da11d416a7ee"
      },
      "source": [
        "Below we have three video reader functions. We'll use decord here as it's faster than PyAV. But I am leaving PyAV as an option in case you encounter errors in decord (especially windows users or in decord-gpu kernel) asit's no longer maintained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0026027f-4a75-468b-bb15-f067824d04b0",
      "metadata": {
        "id": "0026027f-4a75-468b-bb15-f067824d04b0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from numba import jit, cuda\n",
        "\n",
        "def read_video_opencv(video_path, num_frames=NUM_FRAMES):\n",
        "    '''\n",
        "    Decode the video with open-cv decoder.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "    total_num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    indices = np.arange(0, total_num_frames, total_num_frames / num_frames).astype(int)\n",
        "    frames = process_video_cv2(video, indices, total_num_frames)\n",
        "    return np.stack(frames)\n",
        "\n",
        "\n",
        "# @jit(nopython=True, target_backend='cuda') # <-- If you have a cuda GPU\n",
        "def process_video_cv2(video: cv2.VideoCapture, indices: np.array, length: int):\n",
        "    index = 0\n",
        "    frames = []\n",
        "    while video.isOpened():\n",
        "        success, frame = video.read()\n",
        "        if index in indices:\n",
        "            # Channel 0:B 1:G 2:R\n",
        "            height, width, channel = frame.shape\n",
        "            frames.append(frame[0:height, 0:width, 0:channel])\n",
        "        if success:\n",
        "            index += 1\n",
        "        if index >= length:\n",
        "            break\n",
        "\n",
        "    video.release()\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2833775e-ff3d-4311-a357-f22b1e7b033c",
      "metadata": {
        "id": "2833775e-ff3d-4311-a357-f22b1e7b033c"
      },
      "outputs": [],
      "source": [
        "from decord import VideoReader, gpu, cpu\n",
        "\n",
        "def read_video_decord(video_path, num_frames=NUM_FRAMES):\n",
        "    '''\n",
        "    Decode the video with Decord decoder.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    vr = VideoReader(uri=video_path, ctx=cpu(0)) # you need to install from source to use gpu ctx\n",
        "    indices = np.arange(0, len(vr), len(vr) / num_frames).astype(int)\n",
        "    frames = vr.get_batch(indices).asnumpy()\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4396473-fc50-4ad4-85d5-33cd59fee938",
      "metadata": {
        "id": "c4396473-fc50-4ad4-85d5-33cd59fee938"
      },
      "outputs": [],
      "source": [
        "def read_video_pyav(video_path, num_frames=NUM_FRAMES):\n",
        "    '''\n",
        "    Decode the video with PyAV decoder.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    container = av.open(video_path)\n",
        "\n",
        "    # sample uniformly \"num_frames\" frames from the video\n",
        "    total_frames = container.streams.video[0].frames\n",
        "    indices = np.arange(0, total_frames, total_frames / num_frames).astype(int)\n",
        "\n",
        "    frames = []\n",
        "    container.seek(0)\n",
        "    start_index = indices[0]\n",
        "    end_index = indices[-1]\n",
        "    for i, frame in enumerate(container.decode(video=0)):\n",
        "        if i > end_index:\n",
        "            break\n",
        "        if i >= start_index and i in indices:\n",
        "            frames.append(frame)\n",
        "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8205ec9b-803e-4aad-9851-116b5d1281cc",
      "metadata": {
        "id": "8205ec9b-803e-4aad-9851-116b5d1281cc"
      },
      "source": [
        "## Custom Dataset\n",
        "\n",
        "In the next step, we'll define a the necessary functions to prepare our data for fine-tuning the LLaVa-NeXT-Video model. We define a \"collate_fn\" function to handle handle the conversion of dataset samples into the format required for training and evaluation by preparing a prompt and making array from videos.\n",
        "\n",
        "NOTE: LLaVa-NeXT-Video accepts videos in one of the following formats:\n",
        "\n",
        "- an array or tensor of shape: (batch-size, frames, channel, height, width) where batch-size is an optional dimension\n",
        "- a list of arrays/tensors of shape: (frames, channel, height, width)\n",
        "- a nested list of video frames, where each frame is an image as PIL Image/array/tensor\n",
        "\n",
        "Here we're going to use the processor to turn the (video, target token sequence) into the format that the model expects (which is pixel_values, input_ids etc.). NOTE: We do not need to do batching right now, so that we can do dynamic batching of data during training and evaluation. It ensures that the data is padded to max length within batch.\n",
        "\n",
        "We also decide to limit the length of the text tokens (input_ids) to a max length due to memory constraints, feel free to expand if your target token sequences are longer (I'd recommend plotting the average token length of your dataset to determine the optimal value).\n",
        "\n",
        "The formatting of the input_ids is super important: we need to respect a so-called chat template. LLaVa-NeXT-Video processor has a special `apply_chat_template` which will help you to use the correct format by simply providing the text/images as input. You can also have a multi-turn conversation, and the template converter will take care of the formatting for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9491299-d12b-4f8c-8dc2-fc12b477ab01",
      "metadata": {
        "id": "b9491299-d12b-4f8c-8dc2-fc12b477ab01"
      },
      "outputs": [],
      "source": [
        "# We collate to save everything in tensor format to speed-up dataloading process\n",
        "# Saving the whole video clip (array) along with caption (string) will slow down iteration\n",
        "# because unprocessed video clip will take up more memory due to higher resolution\n",
        "# The processed video on the other hand is always 336x336 in size and fixed frame count per clip\n",
        "# see: https://discuss.huggingface.co/t/slow-iteration-speed-with-and-without-keep-in-memory-true/33587\n",
        "\n",
        "def collate_fn(example, path):\n",
        "    video_file = example[\"video_path\"].split(\"/\")[-1]\n",
        "    video_clip = read_video_decord(f'{path}/{video_file}') # change to the video decoder you want\n",
        "\n",
        "    # we'll take the overall video caption, not per-scene caption for each frame\n",
        "    captions_all = [caption for caption in example['captions'] if caption['idx'] == '-1']\n",
        "    caption = captions_all[0]['content']\n",
        "\n",
        "    # Let's use chat template to format the prompt correctly\n",
        "    conversation = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Provide a detailed caption for this video.\"},\n",
        "                    {\"type\": \"video\"},\n",
        "                    ],\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": caption},\n",
        "                     ],\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=False)\n",
        "\n",
        "    batch = processor(\n",
        "        text=prompt,\n",
        "        videos=video_clip,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1dc2d4-0e2d-42fa-8db5-b31ec6ba6583",
      "metadata": {
        "id": "7b1dc2d4-0e2d-42fa-8db5-b31ec6ba6583",
        "outputId": "46413325-a4e5-4834-bb42-d7072d01b621"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# And we also need to load the processor for collate_fn\n",
        "processor = AutoProcessor.from_pretrained(MODEL_ID, use_fast=False)\n",
        "processor.tokenizer.padding_side = \"right\" # during training, one always uses padding on the right"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e70f960-3ec6-425f-a149-6a8753f9e797",
      "metadata": {
        "id": "3e70f960-3ec6-425f-a149-6a8753f9e797"
      },
      "source": [
        "In case you don't have much hard disk space, run the below cell and skip the subsequent. It will download and process each zipfile separately and then delete videos after processing.\n",
        "\n",
        "If you want to download everything and have it saved in memory/cache, skip the below cell and run the subsequent.\n",
        "\n",
        "Additionally, you can take a look at how to do streaming from HF Hub [here](https://colab.research.google.com/drive/1suYlqG6gyjeslUcXbWAn6EsiFqJXqKns?usp=sharing), in case you do not want to download anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d092b5a-7306-47ea-b0b2-710165f1cc97",
      "metadata": {
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "a0d643ea45604b069b79ed42c5cf3e9c",
            "b36b408d2efd45e0ab64fbc7a407232d",
            "9ff13e9445d64049ae80c73df348f4d3",
            "5d30f09cfe564251aaab321598975c8a",
            "a9f0b3c9ac84443db782622a92b12a2f",
            "f85fa66f27d943ef9cfcbb5d3297642f",
            "a7718d9cbec34c4a96f3a1bb65f1ceff",
            "d7d807a1cbfa46f5a672af952c7c88ce",
            "98f75e1d64b64f5fa365fa1d1d5260c8",
            "b94b2e5cadb447e7928b91eb64858ac4",
            "6ae35f2f29894f4991f4e68b7a2b937d",
            "8f57dd0c46eb41a2919eb88c62de3502",
            "01f6f0c529674935a3c765655e50a860",
            "a892222614354d5ba1939d2b13e582ab",
            "ff09f5f6e25a4ea5bd67fe6dc9b60c74",
            "88129a7cd62643fcbb646db737cb16b6",
            "c1e38eb751334310a276240a7fe5baeb",
            "92d22b151e974581aaa4c01a2604df3b",
            "7f65f8a7b1d04dc19d409af9ffc074e5",
            "49614c51591b4797a5ebf6c2d239969e",
            "6f0f0b0e29924ecc920be195bff7d090",
            "6063b60044b54b558a3097f9e5a7531d",
            "882cc9f03a8f4a4397e8d1c69050d109",
            "51d82c8b0101411888a7078777e3720d",
            "ae64e8f0116545ceb53277cb975ceee6",
            "ce3ab0902a9841f3b2b47515628a574d",
            "3761f82ec913474d9e4dced49f549951",
            "72fd1827ae8046fbae86e99ef3ae3123",
            "1e8cf72564774f1693b3a426accb4ca6",
            "e44952d8fe014f569865848105540153",
            "1e3c5427f11f4a3fbe0ad78586319cc6",
            "603c46e311984810b09ae1b290dba174",
            "5d7b7f510b454cadbe5c4c05fbf4ae39",
            "bc0cc368dd9d475ebe710e9735df7cba",
            "e14c4bfd33124b4891c99918659f22a3",
            "84a6c34cbbea4bb0b78af5b9af556c76",
            "cb5259006e0340e29030fc75d0dc88bf",
            "fce34c170d85418799cce377b048e9fe",
            "8df560a27b26482eade3033af9d8ae25",
            "cdb400f9f9724d3a8132f75a98ca3a1a",
            "46a5d1d7a21044dc88e1f4e693922b49",
            "e5044f44dec442f291cf4f8cb1263595",
            "7b9b12c378114b208f5f9ed2798855c4",
            "f36aa23581a5464f945744248f7bef9b",
            "7e1ad8fa12bd439fbc0a6a66ce4d52c0",
            "f3471a6df347406484869af0c7b4be00",
            "95b4d69b0e044274aebaa4a29feafb3f",
            "57e2f08f1e774657a9520111a6fc10b6",
            "780d3bce501d499f942fd03f92933101",
            "4fca4d63ffdf40ecb6daf5ead354e10b",
            "1ad08d8a8efc4204a43c59953ce2be24",
            "8c9a685cf179407dbab4814fa6e86ea6",
            "2349320c41a04a26b7d426f4f17f49ff",
            "fb1c3d7680c94439a96d9936acea7d1d"
          ]
        },
        "id": "9d092b5a-7306-47ea-b0b2-710165f1cc97",
        "outputId": "064a869d-dbe3-4e95-f230-4c7589873037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing folder: pexels...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0d643ea45604b069b79ed42c5cf3e9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_1.zip:   0%|          | 0.00/14.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b36b408d2efd45e0ab64fbc7a407232d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/196 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ff13e9445d64049ae80c73df348f4d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_10.zip:   0%|          | 0.00/14.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d30f09cfe564251aaab321598975c8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9f0b3c9ac84443db782622a92b12a2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/195 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f85fa66f27d943ef9cfcbb5d3297642f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_11.zip:   0%|          | 0.00/10.6G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7718d9cbec34c4a96f3a1bb65f1ceff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7d807a1cbfa46f5a672af952c7c88ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/199 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98f75e1d64b64f5fa365fa1d1d5260c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_12.zip:   0%|          | 0.00/15.6G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b94b2e5cadb447e7928b91eb64858ac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ae35f2f29894f4991f4e68b7a2b937d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/199 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f57dd0c46eb41a2919eb88c62de3502",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_13.zip:   0%|          | 0.00/19.6G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01f6f0c529674935a3c765655e50a860",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a892222614354d5ba1939d2b13e582ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/198 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff09f5f6e25a4ea5bd67fe6dc9b60c74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_14.zip:   0%|          | 0.00/14.1G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88129a7cd62643fcbb646db737cb16b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e38eb751334310a276240a7fe5baeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92d22b151e974581aaa4c01a2604df3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_15.zip:   0%|          | 0.00/16.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f65f8a7b1d04dc19d409af9ffc074e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49614c51591b4797a5ebf6c2d239969e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/199 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f0f0b0e29924ecc920be195bff7d090",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_16.zip:   0%|          | 0.00/16.0G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6063b60044b54b558a3097f9e5a7531d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "882cc9f03a8f4a4397e8d1c69050d109",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/198 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51d82c8b0101411888a7078777e3720d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_17.zip:   0%|          | 0.00/14.6G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae64e8f0116545ceb53277cb975ceee6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce3ab0902a9841f3b2b47515628a574d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/194 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3761f82ec913474d9e4dced49f549951",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_18.zip:   0%|          | 0.00/13.9G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72fd1827ae8046fbae86e99ef3ae3123",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e8cf72564774f1693b3a426accb4ca6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/199 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e44952d8fe014f569865848105540153",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_19.zip:   0%|          | 0.00/16.2G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e3c5427f11f4a3fbe0ad78586319cc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "603c46e311984810b09ae1b290dba174",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d7b7f510b454cadbe5c4c05fbf4ae39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_2.zip:   0%|          | 0.00/11.8G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc0cc368dd9d475ebe710e9735df7cba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e14c4bfd33124b4891c99918659f22a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/198 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84a6c34cbbea4bb0b78af5b9af556c76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_20.zip:   0%|          | 0.00/18.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb5259006e0340e29030fc75d0dc88bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fce34c170d85418799cce377b048e9fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/196 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8df560a27b26482eade3033af9d8ae25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_21.zip:   0%|          | 0.00/12.0G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdb400f9f9724d3a8132f75a98ca3a1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46a5d1d7a21044dc88e1f4e693922b49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/197 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5044f44dec442f291cf4f8cb1263595",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_22.zip:   0%|          | 0.00/16.0G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b9b12c378114b208f5f9ed2798855c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f36aa23581a5464f945744248f7bef9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/198 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e1ad8fa12bd439fbc0a6a66ce4d52c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_23.zip:   0%|          | 0.00/16.6G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3471a6df347406484869af0c7b4be00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95b4d69b0e044274aebaa4a29feafb3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/199 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57e2f08f1e774657a9520111a6fc10b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_24.zip:   0%|          | 0.00/19.8G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "780d3bce501d499f942fd03f92933101",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fca4d63ffdf40ecb6daf5ead354e10b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ad08d8a8efc4204a43c59953ce2be24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_25.zip:   0%|          | 0.00/13.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c9a685cf179407dbab4814fa6e86ea6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2349320c41a04a26b7d426f4f17f49ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/199 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n",
            "/home/raushan/transformers/src/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb1c3d7680c94439a96d9936acea7d1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_26.zip:   0%|          | 0.00/18.4G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zip_file \u001b[38;5;129;01min\u001b[39;00m zip_files:\n\u001b[1;32m     11\u001b[0m     zip_file \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShareGPT4Video/ShareGPT4Video\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip_folder/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# save in dataset_dir\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     subdataset_name \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(directory): \u001b[38;5;66;03m# create temp dir, remove if it's not the first zip-file being processed\u001b[39;00m\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/huggingface_hub/file_download.py:1202\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local_dir_use_symlinks \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1194\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`local_dir_use_symlinks` parameter is deprecated and will be ignored. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1196\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe process to download files to a local folder has been updated and do \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1200\u001b[0m         )\n\u001b[0;32m-> 1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_local_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1222\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1236\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1237\u001b[0m     )\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/huggingface_hub/file_download.py:1487\u001b[0m, in \u001b[0;36m_hf_hub_download_to_local_dir\u001b[0;34m(local_dir, repo_id, repo_type, filename, revision, proxies, etag_timeout, headers, endpoint, cache_dir, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(paths\u001b[38;5;241m.\u001b[39mlock_path):\n\u001b[1;32m   1486\u001b[0m     paths\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# delete outdated file first\u001b[39;00m\n\u001b[0;32m-> 1487\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43metag\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1498\u001b[0m write_download_metadata(local_dir\u001b[38;5;241m=\u001b[39mlocal_dir, filename\u001b[38;5;241m=\u001b[39mfilename, commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash, etag\u001b[38;5;241m=\u001b[39metag)\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(paths\u001b[38;5;241m.\u001b[39mfile_path)\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/huggingface_hub/file_download.py:1884\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1881\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1882\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1884\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1893\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1894\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/huggingface_hub/file_download.py:539\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    537\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/env0/lib/python3.8/site-packages/urllib3/response.py:525\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     chunk_amt \u001b[38;5;241m=\u001b[39m max_chunk_amt\n\u001b[0;32m--> 525\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_amt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Download iteratively and delete after done\n",
        "\n",
        "datasets_combined = []\n",
        "fs = HfFileSystem()\n",
        "directory = f\"{DATASET_PATH}/temp_dir\"\n",
        "\n",
        "zip_folders = {\"mixit\", \"bdd100k\", \"ego4d\", \"pexels\", \"pixabay\"}\n",
        "for zip_folder in zip_folders:\n",
        "    print(f\"Processing folder: {zip_folder}...\")\n",
        "    zip_files = fs.ls(f\"datasets/ShareGPT4Video/ShareGPT4Video/zip_folder/{zip_folder}\", detail=False)\n",
        "    for zip_file in zip_files:\n",
        "        zip_file = zip_file.split(\"/\")[-1]\n",
        "        path = hf_hub_download(\n",
        "            repo_id='ShareGPT4Video/ShareGPT4Video',\n",
        "            repo_type=\"dataset\",\n",
        "            filename=f\"zip_folder/{zip_folder}/{zip_file}\",\n",
        "            local_dir=f\"{DATASET_PATH}/{zip_folder}\",  # save in dataset_dir to avoid caching\n",
        "            cache_dir=DATASET_PATH,\n",
        "        )\n",
        "        subdataset_name = zip_file.split(\"_\")[0]\n",
        "\n",
        "        if os.path.exists(directory): # create temp dir, remove if it's not the first zip-file being processed\n",
        "            shutil.rmtree(directory)\n",
        "        os.makedirs(directory)\n",
        "\n",
        "        if path.endswith(\".zip\"):\n",
        "            shutil.unpack_archive(path, directory)\n",
        "\n",
        "            # get small part of dataset with curr downloaded video files only\n",
        "            curr_video_files = os.listdir(directory)\n",
        "            small_dataset = dataset.filter(lambda example: example[\"video_path\"].split(\"/\")[-1] in curr_video_files)\n",
        "\n",
        "            small_dataset = small_dataset.map(\n",
        "                collate_fn,\n",
        "                batched=False, # false to read video one-by-one\n",
        "                fn_kwargs={\"path\": directory},\n",
        "                num_proc=2, # set num_proc higher to faster process\n",
        "                remove_columns=[\"captions\", \"keyframe\", \"timestamp\", \"video_id\", \"video_path\"],\n",
        "                writer_batch_size=400, # reduce writer_batch_size to have batches smaller than 2GB\n",
        "            )\n",
        "            datasets_combined.append(small_dataset['train']) # ShareGPTVideo only has train set, so let's save only that\n",
        "        os.remove(path) # remove this zip-file after we're done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79825057-c53d-4221-82c0-62def12723c9",
      "metadata": {
        "id": "79825057-c53d-4221-82c0-62def12723c9"
      },
      "outputs": [],
      "source": [
        "# Download in one go\n",
        "\n",
        "videos_path = snapshot_download(repo_id='ShareGPT4Video/ShareGPT4Video', repo_type=\"dataset\", allow_patterns=\"*videos.zip\")\n",
        "\n",
        "# uncomment if you want to cache in specific folder\n",
        "# videos_path = snapshot_download(repo_id='ShareGPT4Video/ShareGPT4Video', repo_type=\"dataset\", cache_dir=\"PATH WHERE TO CACHE\")\n",
        "\n",
        "# Now Unzip each file and process\n",
        "datasets_combined = []\n",
        "directory = f\"{DATASET_PATH}/videos_ShareGPT/\"\n",
        "zip_folders = {\"ego4d\", \"mixit\", \"pexels\", \"pixabay\", \"bdd100k\"}\n",
        "\n",
        "for zip_folder in zip_folders:\n",
        "    for zip_file in os.listdir(f\"{videos_path}/{zip_folder}\"):\n",
        "        zip_file_path = f\"{videos_path}/{zip_folder}/{zip_file}\"\n",
        "        shutil.unpack_archive(path, f\"{directory}/{zip_folder}\")\n",
        "\n",
        "    small_dataset = dataset.filter(lambda example: example[\"video_path\"].startswith(zip_folder))\n",
        "\n",
        "    # set num_proc higher for faster processing\n",
        "    small_dataset = small_dataset.map(collate_fn, batched=False, fn_kwargs={\"path\": f\"{directory}/{zip_folder}\"}, num_proc=8)\n",
        "    temp_dataset = process_dataset(zip_file)\n",
        "    datasets_combined.append(temp_dataset['train']) # ShareGPTVideo only has train set, so let's save only that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad0351f0-f241-4afe-8c53-5310fb733b1b",
      "metadata": {
        "id": "ad0351f0-f241-4afe-8c53-5310fb733b1b"
      },
      "outputs": [],
      "source": [
        "# Concatenate the datasets we have and load a tokenizer\n",
        "dataset_processed = concatenate_datasets(datasets_combined)\n",
        "dataset_processed = dataset_processed.shuffle(seed=42)\n",
        "dataset = dataset_processed.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "983d486b-1251-4775-82f8-5f5d20c31ea4",
      "metadata": {
        "id": "983d486b-1251-4775-82f8-5f5d20c31ea4"
      },
      "outputs": [],
      "source": [
        "train_dataset, test_dataset = dataset['train'].with_format(\"torch\"), dataset['test'].with_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b90937-2cac-4858-b31f-c4c71ccc6974",
      "metadata": {
        "id": "01b90937-2cac-4858-b31f-c4c71ccc6974",
        "outputId": "ff81d4ee-e156-4ec5-93aa-1cd25586d3e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['input_ids', 'attention_mask', 'pixel_values_videos'],\n",
              "     num_rows: 2851\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['input_ids', 'attention_mask', 'pixel_values_videos'],\n",
              "     num_rows: 713\n",
              " }))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For demo purposes only a small portion of the dataset was downloaded\n",
        "# The whole dataset has 40k videos\n",
        "train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89bf62f6-cd7a-430f-bf51-831ad93c3169",
      "metadata": {
        "id": "89bf62f6-cd7a-430f-bf51-831ad93c3169"
      },
      "source": [
        "## Create Collator for Training\n",
        "\n",
        "Now we can create out collator which we'll pass to the trainer for dynamic padding of the inputs. The below collator is basically the same as `DataCollatorWithPadding` from transformers with the only difference that we also add \"pixel_values\" to the batch\n",
        "\n",
        "Labels are created for the model by simply copying the inputs to the LLM (input_ids), but with padding tokens replaced by the ignore index of the loss function. This ensures that the model doesn't need to learn to predict padding tokens (used to batch examples together).\n",
        "\n",
        "Why are the labels a copy of the model inputs, you may ask? The model will internally shift the labels one position to the right so that the model will learn to predict the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f2fd13-b5bd-4de6-a8a2-c6e0626f89ad",
      "metadata": {
        "id": "e3f2fd13-b5bd-4de6-a8a2-c6e0626f89ad"
      },
      "outputs": [],
      "source": [
        "class LlavaNextVideoDataCollatorWithPadding:\n",
        "    def __init__(self, processor):\n",
        "        self.processor = processor\n",
        "\n",
        "    def __call__(self, features):\n",
        "        padded_inputs = self.processor.tokenizer.pad(\n",
        "            {\n",
        "                \"input_ids\": [feat['input_ids'][0] for feat in features], # each element is one batch only so we slice [0]\n",
        "                \"attention_mask\": [feat['attention_mask'][0] for feat in features],\n",
        "            },\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        labels = padded_inputs[\"input_ids\"].clone()\n",
        "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
        "        padded_inputs[\"labels\"] = labels\n",
        "        padded_inputs[\"pixel_values_videos\"] = torch.cat([feat['pixel_values_videos'] for feat in features], dim=0)\n",
        "\n",
        "        return padded_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46c49a5d-31d7-4b95-b611-503f68328160",
      "metadata": {
        "id": "46c49a5d-31d7-4b95-b611-503f68328160"
      },
      "source": [
        "#### Let's see one of the video clips we sampled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "562760d1-4a8e-46b9-bac2-c78da2e9ab6b",
      "metadata": {
        "id": "562760d1-4a8e-46b9-bac2-c78da2e9ab6b"
      },
      "outputs": [],
      "source": [
        "example = train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71015567-a4c6-4d35-a1e2-a6eb9aae9a63",
      "metadata": {
        "id": "71015567-a4c6-4d35-a1e2-a6eb9aae9a63",
        "outputId": "a2699ac0-f36e-405d-c2e9-acb207303d9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAACIEG1kYXQAAAKvBgX//6vcRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MTUgbG9v\n",
              "a2FoZWFkX3RocmVhZHM9MiBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxh\n",
              "Y2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHly\n",
              "YW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3\n",
              "ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3JlZnJl\n",
              "c2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAg\n",
              "cXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAApEWWI\n",
              "hAAQ//73gb8yy18iuslx+ed9LKzPPOQ8cl2JrrjQAAADAAADAAA/yP425VR62BLgAAAE7ADZy//E\n",
              "Y/K4ACvgUNItcrm2vXdyPQ33PzKkTM7xM0rqAWnHDJhVFhbietpFdEks1PY568bNHEoLuh9lt7ty\n",
              "aQiWK80N46Y9cAmWgSM4PmP5W9/UH3J0ixVO/SrVz9gwBgDDgitOUNFIX9094CvQ8SsPBND6Z3e2\n",
              "0hS+xK12Um4dHqf/SRbf+thlyIyhFSuv2DULaj5bm3IKWrMxO0R/jD8//Wh9HMtpEVmTgXPz8dED\n",
              "ILprBjL4bhuLTYMekSFt76Gv3PHwmT1O3sV+mNFiwjLE+8Nf2z22ykw3sLqHdMCMk5FmbFZjQ51q\n",
              "vmJrBY1GU6WN3TMRm8StyN6A/6sbeIURfrm4AELQ+/nfBfVQ09HiJuAJcPsZp73xpC/8aLfuhYVZ\n",
              "lEPcjMeFwwnlsbfXBUBXtA36ppC1Z1Af+KrJUfC+ytrj2ors1ovQKLLnOGX9Xr2Gg3lPCiHgbZ8O\n",
              "zg4m4WArJTN38J84biHfhldZwjgZffiz2MDfUCsO4CBRpXPOp/4FgRVPmTcLU0zT1Gf/RCSIFTmo\n",
              "683uWt2InRwGou0vZ6ziylVQCHuK4R5np5ikDEDeCmzvHrIT6WYpUzp8mmUyBlJ15FBMhEjffa1J\n",
              "sugSL5sFNA4D5rrlcyn9S15nGONPw3f+eAwEV6elOJbBCK7L1wnunNhRb9Ut0AtqWSA6U28nKj88\n",
              "D/1eDE8IpYxOnTbMWS5dwYwsYnB/Gea0R8/Hb6CGIhcH7PqV1ZaTXRWikGjewxf7Hpgu451sTko4\n",
              "69q4dgalrz7H819uGOkVwZ0kjLeT7gWlO5eOmH4i5hoGTfG8on0b1x1wLwqoERfc3DFTwtlvAY7s\n",
              "xMHrkt+0d7DreIS4RoooMjJ2yXRI5M6xKi+UMBXrf78CBIcFstP0DraxPlOymReIXHNYsat8M2J2\n",
              "mAWl1nA7IuCfhXnOhWiVPJW8C2lZpA97zuPmhz7KYP1XzjlSNspMxsWFGfWHtcs8wCUfxUq9BDe8\n",
              "itcS5yUGxvoJDQ7ORdwWIPyEPbnxrTU8K/YqiLLFWhRBYwm8Cdwh4KT61XtXhs3rcf2X15pfjGuM\n",
              "2o52ClzRNfV5EhjYgJRGs+UOaLGJ1R/c1qx8h1symrD98DppFll0lB1MP6QyBrWXpPE2hZ1q6grB\n",
              "8wGe0MwTqGiteCwr3kCwMFHByEFBA2KAXt8uS7pHZSlGc/wQ1LcSTMInPdwVKk/ytvg1Ddz8GqkP\n",
              "irBrqVAIXYQAi6qVd8HpK/bSPOPRCcNSCBcBa60QbA+pLeRLL7NPcqjkq8Qa2407//vLNUeY0+6d\n",
              "UneYW/B2bEhggjA4++EFoLXQVI7UqnmHVEiqhStDu5QyKPo5nWyAD/DlCsFOxroGWwYXt7uCNhnj\n",
              "4ieeHYNoFMrT0Kmz/IBylsUTkyY+zE5fRhf32c7fMWNLJO//fIY789RgC/XZvBp4KCOhm06wMA4C\n",
              "cxlXpHQFp9dO0h0QwvcDv+3kjGqFvP6li0W5f+EGyOw0cGeJSAWwLFdiQi8YWcGFB7beRW2j/HNj\n",
              "Ai6v2kIv9Ixw/E/NYDZM2N9R6SBFdSIGM/6C0Hw06k8zYhC4hIPy117dvdXroY9giWQml8CSGAgU\n",
              "hvW2akbZI4TUbiKMC4rLNQVrD8iGqknMkRc8QOPTueCRvWEY3vwaYQZeckmvbyoKnbtSE48fUY6+\n",
              "ilag2rm4Az9x0w37KUODOLLarFfue/edFAiPU+vZfkhiv+nNXCgI1pzr8opBmHPe2K0BQvhxOo+9\n",
              "Ki3N0w1xKHmo4J0P3PsDnuQPWae0RZ6vijEJ5xolD1coZvU6ytR+x2yR3/UhEkLw81/SuIV5nLfj\n",
              "bqrpy+Xw7c6gzQCJ83CuFY9qkJGYGPKDDrL/RAgaN8D21qsXcvM0vklAmho79d2Z2iuC2B/rOZYY\n",
              "l4nhn/SsrcIxH+oR7JDEDCd0CXVXfsuBnEK8mObsX+xO+yxmuaR3IgNgs7grqclVED81dXSURVpC\n",
              "a6Xt/Y48hR+U2FTH6kEWtGPROwWHwAMTqjHTyE4iC4jPL5WTdxT7IuVVcJeLWkmrZ79Xi1RW3Yj7\n",
              "7qb4FBBHCS7oyZNfM7atdx/K9qKAHUUNDMS/1GSht4FDR46Kkivji3hwLs9lkWsm2tz62xB/A4mB\n",
              "y0r4o05kveXuwDbmzVoqrOOtNnidBIHoKs/1mvoxnXUyo+pW8YKTjZB9/3n38rg7OHpU+91YNveY\n",
              "OgbI7pIqaLNKoC6N8d3rPWuzjFbfPIsd5RUXJ6klXfxqAALpS3WWpsbEsPI4jV6eZTjGiPrsEaN2\n",
              "SO91GRs7//KWYnlwh+P3+60jjGIhzf5D7ET5sC7jcv0lvLMuqNwghGBdCixOJM5dNvrprl6d8xCA\n",
              "TRn0+ypmFQIu55j+vaYutM1OQOeF7FuGlddrTmO3Qyilc/uW4u23JJJadRGSlslnq7rETcz3vTfz\n",
              "1gDf16tQJ0JnsozqpPciW4o1qnFyVoOsM20LCCAJH0Ljm1yaLSzZb0+zlspPzrfUOunJUcsnt2Mk\n",
              "vXUoUP38yFDLAS/JdrJfbA5QPSMtqbtmPv1nWEQOhRYZznuckhzEtZYgZ5ufG1HaLzBOyMj3QdmR\n",
              "OShyTGduyoy+UeG5rdqP3zcn2HHwklSnOlRsRdF3sADmOEZTNhfuC2KFXNtXkoDKMFi7AmPidjm7\n",
              "A1Dkb879YTaZsPNGHyAYbx806zw2XTMcM2IB9PWBsnFtZY84Da82+Tpow9dpMusjRgqAxKdGLnuY\n",
              "Vnqm4Qhn8Zj5oIN8T/foiDLITIswjnDsylVGTmFPEVBIWOPKtR5+uweLOxkXvFwh660Mbo1xFA/F\n",
              "gX1HZIVgC+aGXoG5mqZUZNX+Nv8Lz9FNfHJYOQKg6Mh7ZgjWhus2A6+9DxpUxB1hIHXGF4TjQaKz\n",
              "IQbsGIaqjBKB1nKnEHuhHMJFmmJfJ1uZw3jd/XUi1eM6lcM9miZI2wVutaSl2bo2xg4duAWWNyBz\n",
              "y+mzVv7O88WQgCJADtk9I6itz/kcfhWMXlilV7mt0IHRkiqp5JovAWX/BZV6E74vZFgcLocrk/ao\n",
              "vzv3iduVtWzSWE9Mq9P+xtgG+JyhsL/m3J8RmDaGs6HuXLkVB1/8mr+edYBZiFQILiLqQKcrBWDQ\n",
              "IMtpss0i6jtlQ/vRAereoG4QcXVqT9KeiwBjiJBoxXgHq1QHwLnERni857stCoyxlwcnbjNUSy7d\n",
              "2GesDm/jXVaVDsRBtkV3aTPqFrzzlnAlgfYHii6Fnl3F2Ctf1t/45koxkxApaQFt1dFjEn5tUfX7\n",
              "xj9Goam2P80ANNS4JLEoQxCNqhcfuA4AUkjv/2wzpcZTXK9V8ICeC9nLrQMQ3/nJSBRPXMK4dg1c\n",
              "1TGfyukjg82G9N6WHjFO490ZcMZed2M4fqY34WHMWEDl90RXNqESGTe6tQEf9W3K/oSiz3mg0VAY\n",
              "r4EIkM0rnBQfqx/QXMPe7EfOKMbdRvbabpM8jZzj6yFAXDMiqfw0tQTnDgcn6LnakariO4xY2d66\n",
              "XOE4ltTyErQMwUWvc210hvokuPCCgUrRzNurBSUPNxIgBao5Ci6GvczgapUQgJ0nuA/VfxtXUEK9\n",
              "12A/igcDwZ3OmEN7fcLqlcc4tVitHYad9dmiFzz7YQbrs6WTUafu/vJTvbFeYuy1DHbPpDupNYnA\n",
              "BTG8rfjhr449xhHv5bHDZhneGjssKPydJYZfcwIvzAgo6gCrWSYtoIFvbZWiNTxmp9wEpCmQvBKx\n",
              "mu/lWUllsFrVejR1Np1e68XHQD+q35igPRoJz0STb6MC/rP2SA2NSOK6oOg7vmqTXi0qIST3VxUy\n",
              "AqN7fpf7sbVHUgexa8cleQorcYjwNklprllJoVlelpljOyHaQJuNZzrs6zW/qkTc+WCN0lsUsV30\n",
              "Bv4df+C0/40MHXlqroErOeaI/xHkurAbsIzIfugxP309iYmnkJVDaxBmn5aE/kIiG4yIa03DjiJY\n",
              "gkXVCn3YaccSFDG7CBagE++KbV59Rnfj6y2KotHcaZyITe3arWCB/2yv7f05mUSyOBQsdyg4hqlf\n",
              "5TukV8FX5iWnIcQwRxoGEvwIolt3Dt/3fFR/hyVFZOi9yRLKSqt25hYCzHu1kHnTzoWn3FAiHhhs\n",
              "n2iivesVkghR8CwcuUvUYdYsU0cZmLS0jSfZpRAmPiUT0e+ytsOinvJjzg+P8NEfguXansjzQ1RI\n",
              "3w1Iu96jHlrdGV4rK8Q79wL+5Xi8N1BNgYW7rTiRezSQCcv9GfLq+I7QfLHoMs7VsvACXWhwuPqI\n",
              "RyKodgBPYw2L5HOA+9Xj+n1/+GFIKNfvGVRfdT8tzjtOUbfSdCELZ6oFDrdbs6JOCjkLszgwl2+L\n",
              "gHIbmkyDfGXDJTJaomMLpV+3Px2/sXko3BoacP/Y4QVqo1OuBKrZY3bmnOQJkW6J2zVRtqXVUFvq\n",
              "mkOQRp5Ia4vIp2WN4tmVRu+4kU5xdDk/fBrSs1jyWqcKCr0HY35pL4MkfnvY11WNaIZK+ky4llrS\n",
              "7lGiahFs7l2R/iDDo8DnbzmBlo/+hRlZQ9RLu7LleexRUcl9hhJAXQXCqB1IM+POaRoXsvNUtprh\n",
              "it68sddjtVlArEUqWPpEpQgPt/UM1OW//MeuT6VE1FUDuWmf/eFNfy/6L7BszVvvviGChZIIejMl\n",
              "/Kt2h2kjeAFAX6Ci0UdxG/QqozzVS01ESgmguhi3q4aBg/f6Bgv2tx5iaLfDBUVBkiDvpZfESgv7\n",
              "8s5TGLWDdEjw+cCvlrCGB3kqo2kyrhRQrIsr68LKUKfJVtEEOVqA1YWjVCvLP+PaISYIsXAIPYU3\n",
              "QzWpIiW0rEN++9dVfcm58YbHw+Qv4yrOVyPnB1OpTZm4kJofUaTRefauGbEzMgy1cj5S0X3b5l/y\n",
              "cl1XZgNe4vrFL6FgT70t+82iC2TRXTqARAXntg4+TMGV/L4lq6Hy/lHYOnhXLwIKqWgsuBvisBaC\n",
              "rIMRnxfcNHGZTNRwtZlfZgcGb4vfh3BUrXXeN4bnOnBAQDgqcFpLd9/Js/+JFKMNJD26PIut2HZx\n",
              "1vwaHH2Bn6v+H4MxibudLtvixrC6Bvatra5GjHLt94n/mbOJs0avk9tePiSpexltaXfv2cFW0gcU\n",
              "AzTwtIC8bXQy6/DufnK2yqOY4Jk1F33wDfVD6SFEMjjMZ9vlA2Hs4iwoIm8YacoqfIBG8fQl6yht\n",
              "jlYtuNrK51H/7+oqDMKIChRk7YO41XQBUerbF4vyi+bdHdJIbBJUnMp0491r7m32M5gs225jSlOa\n",
              "IbeoRdWb9tsx+V6P3/llShOV1IHfqFKjwkNFoG4Qf+bmDK+Is8QU6ffFSfKd4HxyshVV2c2DAHKN\n",
              "sRr5/cHxoBJWVgnlrQjS4tlMF5aKPUlj0Q5O3FiYCLXnbRaKMV+gOxit3aPx5Af4KRqTlS4IX3po\n",
              "4wUYFHGnakkfrQr9IS8tJUfPssqyYAXa3QhI923PwU6qoa3/b0fqf9xhRbS0mi42+869NAc7HdIF\n",
              "ttrTO0QQQV4hedsBUQ9a9T/33vxGryjb/Dok5DNQU+AY5iZp7B1mx3MeziHPMrvHmxeZKoG0Ttlz\n",
              "C91TDz1Vk5RwRfP9l3qdl1D2rNaWA2GWgXWjtPJF22LjEMTFUUbfYmpCiC2dv5CcjVV6G+tyublI\n",
              "MQ7/chW91izmIUlSJUN5sWCd/AzNysQ37JI2v4/45Vdq8qEWAglBVTAhe6X//Ldm8l/QRhEV/T2t\n",
              "8SC1GyBSf/L9hMHkmdptH3/ldpsde5OjkcEO2/lj2v6untuhfDlDuhuqgjifrIIqLlSe154JAOYf\n",
              "lCwdaRKaj39OUPyS/iqRQwwjVsqR/mWECh9D9+qF8Q7k7L36TtTPUbC5N1W8f7AvPeNeA93ynh8R\n",
              "lu76TCwS5UxnS7KaSrlGl6P/I8mMNwghU3m64HMUfcrD5BuxWre//v4hzQh4PIwBi9BHLNJUCkBl\n",
              "fcPL666xD92TY+8Fqsx676jlPx/O4b60yCLG0w8jaT7Po4ZVhI2EhKKYt2MfYYeOpgBKpJYxnGN+\n",
              "IHFB109rMwFNoua4TY0TM2DAXJ4oku/gwFz207iMpjmCE+MzjRgfm0zN1dAw1hxy1R9HADyr9824\n",
              "HQ9hIKpKIf9gVHtt8hpTFk+l6E/pMxwA09F2UjIjdTT7ydsii9ozIiT7UlrdBIN1/DJ2JqzIlUCe\n",
              "g82bfupVcdL86o2cwRSPKHGAJDyAh3WdW8m0juYvNSmSxejyNgy8LZw/guvtxmDcq1CpDHPICyxa\n",
              "LcEvzNhszQpXWaLZrdkjloG0YKefXtqqY5FzMombbAe6A1imJR4riU4YlvFj2UuOGgJWrn+JCnOc\n",
              "VKR2j19wPcYwiiTuKRgpEN2rX2ZoZb425I31opBca2XAxrTfUioQ/vhNkCRpgen2fB0HqnrHdnsQ\n",
              "gTuOmIftWeZ99e61yyJC3ZmSsPCtG1SA2veC5ACUpu0CdpLcDm9utkNZ4QZM8fCWDdS+hJUALdPj\n",
              "xASfqaCBO7y1hZSaFAp65TZcFkS9wp4y2YiJReroiSJOfKXSo9mOptFoXdO8VU31LvT7pnbd+hZm\n",
              "L1PfOgD9ASSVQHPob5AKAovK3Lpmi+MeN8W31Q++Oq/bZ9A8fzT6PTDdxbIw7X0KdJNLC5Y0lpyw\n",
              "zztmM/UzdrBjoDQHPAmVPx7rTJFL/C8X6Gj+fYQKULc9zqfvdOS0MxZOq5u+AYBqZ3CtDngeWMNM\n",
              "gjg4R7CTQOQXI6Ab52BEFCzwRQkYC+awe4jzNeMFxBsXHhvYvH7vfAHrAOAN+GOsLjCoWpEZGMye\n",
              "tb/KDyvRn/YmAch9vIaHDhKjSh7uxlmVvh7xYVovBqmvYFHkMvfgsfpig9feUcVoAzky+MTtjlw6\n",
              "iqWYjIFkrTF8A1yqNSi6o2fw0kV3fiStKhCLheQNJGFrDZQyqb0n9ja/xPS97bN5Gro/iiILdIPw\n",
              "LIlfsSbEd6C0c7IbxcR72sfDUy4SsvJx5B1snfH1fq1nhVmCCSgnoKiZiizJf9qPMNw8v1stWYBi\n",
              "7bjiajzbQYhXt0n5NFLv4iSSXAZOjE9HXo1F9YJbAAL4xszH6v5OgWrhuNF6UfmgyezsQnUVdl/s\n",
              "/4c76Y+QZIMB3f2Fdv5zj7QriKc/J/tKgVgwIalTxmh0A2Vtu83d68wf4blrETm0xJ5m7c+85dnC\n",
              "cFiXpZ2DUGOoGL46dNgS1aBVbTJo/FiewIswLVaiRfkbkbHTBzM9bXlRj1zRiDz0NC8hvKv01oC5\n",
              "QrMYmnbYm0AXOmj8Lt1gt1J7ukXdv783FOnDmCUi4R5+klGZ0dOQV4ijIFtTnUqCKIA9NzCImVSw\n",
              "+ZqSKA9iUlb4qUGNOgYk05DY1FDikNJoD6ZjPXboSrw0lnmfng2qEtRyzWlvfKDu0miElgorQ/2Y\n",
              "8X0pp9P0S1EjYtFXJX16mdix2/P6rrGdzgs7Ddx115hoAiy/tPwgvbzeeLUQE+zrIM9lUNcJ8YQ0\n",
              "/2SQo6rggR7gz4PXPPwBiP7HT6fRP/DAeFQDzy5SvSjI6mWubr0KodsXWzxG7qbZx9Fui9j18pxv\n",
              "/GtCbckeFdwWB32W3qnVchUT5lIGlUrvX+akZhjGguL4cDtF6mDLAExqFDGrphlZ/qa6a3iyDArD\n",
              "7L+oYv0pb2lg0JQV1iWTCXkkVn9SNd4yNyHvxmItt0txieq9B12oxCwF+niB232ukVi71KsqoMXT\n",
              "McJvfta/e/CD9xezqkeFiKk4AEJgfVIUeg2z5QFrufEhH54kr++UtYdBBuGUwZxX5vgR/3qUZ9Cj\n",
              "PLqTahA+E+jCOG8azRQZM2KXxlytc/v6BOBaGEcdNlPjq09YcvucR61GeX9Hd2AJ+SoK6Rjmtmfl\n",
              "pRmxONMAGnvJNhctXJ2Piv43fQ33K9NuEK4NvOyv4OeUVagFMCI+tKsi1kD8C1NnO52oweya42XN\n",
              "gNZiE539ha1N50q7Wu8M31xZfDCiI4EtNDnBZYF3+cNy4uxLFWY+GUuiQHkS9ek7Y5k/DHKBw5Qg\n",
              "ySfc8Cb/N2xSq///7qxiRM6oE3LV65Ohxmnm4NXNqyI3k2fkO32QknX5IwR9mxn5y7wXLbsPoICo\n",
              "x+XQ19gMFI991KMW2YWSdtEiU4VRy3S2PaY/q0kylh949vPF3ThC7P7S9cniH/HdK0lk7699zcpK\n",
              "9WdTSG1t1glq6rWQPjKbwhrs9KQhbv4cA/D2a9Jpk5124KKn0ilpUbzGTDFKjmF8NoaFKLYJuvaC\n",
              "PyKxKYi4QhC2VQ8lcZj4IMKBBOp03BKlulUIMbd02Pb7486vzu0wNq33VlEB3tHHe7aHeeH48Nw2\n",
              "Fo7s4e8ffm4ceTuISLKcPmLwMQMMOSufKI0vZHoz9+/LDWJZ0Bo7cWMV4myvQJeRNXTbyL/o8BqD\n",
              "nltBq3fDejzu61J3XyDxUgEuLbMkASnuACtf38Q4AM0Bz0tfPVAHNNRmi60vn3DAVb5Paz3rh/ns\n",
              "TQ/GaZEf9JuoPvwOxu8Kli5SbB0pbpyTCNZ0FoHdnduCLqO1VbdcCSBFSzFslTyTi4FpAO0+M1w7\n",
              "/wouph+AGWqnHrrl5mphJg4+sANhGiz/qS6Y0gTmX/WSDQt0rtsjFTQxOFz7NGc+sHYvRcaGNcvi\n",
              "ijqW6uoGXx/pUkm9Kfzvm1qZIWJsfiCBsi3Fv0VXZjl8vxso8KQ/Yat/UPp/AqZt7cHOqFfkcMKS\n",
              "b/KbZ9Jn0r+Dp+613nTVuyAIDNb7i2k40F+zZ3gi1N1AGYSAk3U6EVs7KSJBfo5txxETHczFeiDS\n",
              "Avz27djQavZ1g99BcsnfRQA8ky1Ld/8IzvY7WsInj2XLf/Ghrv5x4WsnNe70sSll9rrmOZFgjN63\n",
              "P7e/ut+ExpMVFFlQCr5hnEIpqaVUD8sLgZ3ssHRJrSwLL6Phbd88Gkxd5k+GrRB1UXAIrw59j1KD\n",
              "cbQjr8ip1KaWzev5NRf6PsmyvJkWDlb4C+X0lP2h3cNAAiUnTZi7OAJmxZFjwJmfFfLW61Q/DXGl\n",
              "mjchTOK3R4UEiLKkqHjor300TvLFcluB5abLEe7Qc3SCYhsCPVNBAtCtrB2l6vlb2KOxf+jmlmuX\n",
              "9tCUjkQYeN3MwqMcRL71DqnIaMXFpn0cB541kgyWxBJ/j3fjWpDnMPB+mHTwg4x1pu4aVbt1O3Zx\n",
              "c09PJ4QjLbnjbQA3HFWuoX6yyREwYyyc3J1uJ1kS6YmkC4WepO9oPDWTu/q/fWybB4CSrzwIoj9z\n",
              "bIvGGDWESfvwRquovhGeElKfAxd1WL4xCBOeXh5RMYDDZ9l4xPi7/0lBp8jv0KSwhj/CxLLkNr3b\n",
              "tXy8rQvz5DayUBraYfbZMx2uKhOaAydCk9fLDnq06UeAmywNr08AsozAosmu4B1wFR4Iah8QJ0zF\n",
              "Zn2uwrTP7mMymb7/k4wj7irJS4YXKLU2XScCqDcANGqBbYpxtlKzFlHqEdMjbKps1sgLbclaXu2/\n",
              "HsFAiXeFRa2IjgtOjpiRnm616d9ktcclpadSky0EE47d3unS1Rku32ithgTPxIhaHd+mOPa604MJ\n",
              "I7+GuPe20BRky0O+mesT5ylGWuGlAcHLkWmOPQ9Prlsed5v8LYCsZ4R/K1dNglHZ4PypX/chtf8u\n",
              "GLreI8v/tA2dpTssiLSWoaslbdrgRbQHAnO3tX0U86a5plkAW0TsA1qt5qzx6zT8QdZMSG/DkfOi\n",
              "/ClGo97J+LWV5VhSiJgXuEGwtCuEV/d81/Gdb+PzQ744galQ1Wo+0sI1ENI9qhm2+2Pw0Mq+woM5\n",
              "+fni2xXZ7qRB506tE1G/B/C8yN/yDTeLsuchPY38WTSysQh1zDVz9OtauNE/VcqWNhg7+vuD2atA\n",
              "/x9m05hl+eeqt/vB0pvK4xMY9umFxmLmN1MWKiLZs84c8TfzS9ASe0AVXI7pPhdAd1Xv8m9dQ3Cq\n",
              "3QfHcR7chi5wcBkDsCgjESSJnywp2H+Si2AEwKyE3sJh7XX6Cp1haDPI3pwkycbYqt5nPUOkxa8+\n",
              "7pJUgKkznpFW5nmL47K3bMY/JkGAoCxvt6cOPgPmJwmBG7Ah98fzrJ+68828LVoQ7a8EqTfeYNcG\n",
              "YZ2DHlshseeNLrElZpzKhy5dFqUSNkKSHJ0PG0M5Mq8wM8rCbkpZbnwO2WfTcjlOwuuWmuSWoxdK\n",
              "RLjQgksr+FB8LnlqYfNhB+Igq2PqNYeNgQNJZhnjMAC4HBPI2cVTGcYStzdIdcL8+UyKxsV4Vyp8\n",
              "EMjZQZ1NsPXcXWT2aYyeqvBF+a1MuGl/044KOYL5BfPKTRwWzcshpB6BxRjcgY71vtyVtNMEkgGd\n",
              "EdxcnsP42WR74dUr1xhSUvyWwOTF6UV16RO5buSwDg99kf5T0GnfSqAfVddBjaL29VQFnyzK0Mk2\n",
              "OrF03EdK9pSpNSajjMsVnGFRW+KnZSKKQpTWYYZNDFc8J6jOlHIJZ+Ddh0js7VageX/AdxoE0dJ1\n",
              "8sPMdWa3Pz8tjdMYAviFR6nVSFiFFc0Z4kSrI3vkaK+lJWot8kIlU1+QgHZN5WbKaijnhFG6hQBB\n",
              "EUW+LWwNgRYU3LWOimZlMi3hBhFtDZtFGirnj29DqRXv7ark5FZrSVSLrUveWnC5DooyCCcXB+QU\n",
              "yZ3IQd4/uRdzneKTZPzexgFuaw0VyRFPkNO1dW/qs14z/cR+FkNd73Bsc3VEd1jdWmPMaT1/UVar\n",
              "7AO/7CiKNE0mpLWpP53lqq++3JT8viZns4o9tl+jekWNvq3j66DWYHSU2RUjCPe5BIeqIoiPBV9Q\n",
              "yN/PpaFTyBXDtHdMVx2FgzNZ3rxG3hmwwrK3VWCg8yRDF4hoXugb+CB7uqXdntPP5YhcTBPnWa01\n",
              "tY+dCthnSBMC5R1HXeq8Iq2InuGCeTIEUqNm4cUb7Nzl0IKUI5jG/5Y7GfhdfRhRvukwe1dCCAtB\n",
              "tReBVIOjVovTyDADH4AAfWuNa1E2TqF5eOisfX3A74I6MIU1PJa+HfKGbA2zwCcv4n9Ai5dAe1Gc\n",
              "jh9fF0kU0AAtK/Yn3ix/qifZyi/0UPiLFHOxkvnhXMPJNaNY6k6lcrPup1bws9OF1aH77eOIJLqs\n",
              "F9JDbkZPJph/J0eCcUSszqf4nTo9+7nQ4/hBatMLzO/1AFrvEEVB1eZ8YCEAYZkNX6TytzI7Gn9z\n",
              "jYmM1SV15xlv9gTlpWQ9+k3wksiWSeI/hzLN3rYGBcTAd/OQxWOLygG/lc8+7NQXXp0kxtJCocNs\n",
              "OduZPE/58S9/plPhCsT8GsHmQUtEQ5PonNKMKEwaeFCOZzmvC8z1spA74C5BUpanRhEX/bv3bOQj\n",
              "LTTnhfQO5uEDrf3Na0yUJyahOQ4meETQyYrhjX71cwCwxciwWxyTVK/HPJvi/LR3/4ErLp6op5T+\n",
              "T5gS+s8uQUYGovQQQYIJP2iUe6pNvxCIwwlTM7E5F5YWBkhPZLNZmRXUDeXhc5mD+VzOd808I1ok\n",
              "0a1TAxH+075U5xdfpYdPWcKyHfmjKNOpltcKBzhjJfW9R3t9qJMKFR8SrVpdgzuHGRQ/HXGnmDbd\n",
              "fyjthNHryl1+Yp+CfAbpbQxSQ9OljfxMiJBqbcuJNWCeCrqP/m+mNxtHJwa9vYU2PMaYPsd1ewhE\n",
              "BPW9bY66WnJXm/vcmF5XSCxcoCdzoy8wxK9Y+cfyu2czHss0MBRi1GB4IPjHCk14Qq6a149/DOIR\n",
              "yDc+x8v45HRCvV0u4P4pnNLMdi6My7OGfaYrrFx1eFXZJyiAsM3KEG+6QDfJzKHYsQX0ra1K3aE3\n",
              "dObPTE2VORP/qrYi3wJ5a/xojeHOjNGx1I5d0WOrpRSfUruobZ2QLegtv2RD8yAK1tslakFN0zdf\n",
              "u3r//drplq5y4oj1daey/o+64t0fVALkR2v24AkayYIzfDLGT+RVnpa175IiphFYyRW7F08hAThv\n",
              "jNvq3K55KFw5DO1wLPVGyTnkUyaiyouHslUVTBlUl2SErTvjGA+SItO+2q0Tuxlyxuzkr5Jczk+i\n",
              "X8cn8qvWWbJNRjU2ivMZNIhO5zV8ZgrtBKOWXn9rzhfKHCsccGuHgulKNVeJmJ/ge7h0anlLAiga\n",
              "fAASUMd/5gKRCDd9oQMQ9IMFVzIJQZ6PSzqEvgP4XHDnvdHZRZMr3MFNfnRMHr6JVeT1LL/pNDOS\n",
              "1FcEgMfQhUj5Ag5Fn2L8KnyUkQ+Q5H/rCicFcvo6WeoGr7rrYMCd1/yCb5/sEUHQg06k4cn2WsYO\n",
              "6Hd6K6FTmepmMRFDn1P/35aKQ5xuBWLkPQCMLb76vplTnYOV3hybdXjGRg2W1i28A0vuFjyXMKw+\n",
              "6R/AM20jXgvy9g+lsw7rF2ncWj7bIENnsvIAAUPSZs/W9p3hfYqVuXLlFpMwqRunRD1bQuboSKrx\n",
              "faSFZ1lpPXhmnkCsAFbjtKRk35kxWvVcOeXfHLt2+YIIriSjxy+8E4Q3S3MAf2kO8ABAPrlPOf8n\n",
              "SeHTIZrfZl6XQjaK4unC2tmDBL+yaSsGRSG+FNp98PHjh01njvmuSwf3q8groVP+fikKBgnw/7u+\n",
              "yZ2nQ63B2CAkhUC/RbiBorldg6C1qpeq/Ue9BjZ2rEtR+cOHBYVx8toFqMYClS9Faa3J1eLuF93v\n",
              "IRuBw76oUNkelDpOscAdS8IQbmVTsFXSLQEqUgyNRB1LzV2RUKxKmRqgcPIRhbN/DnsKgE7cJA69\n",
              "yFstSaMlfTZEkV8H9tMGMv6uLK5vezuCbdzq0AjkJfPMMmIi/kK/pUMXsWXNwdz0KPMbaxEJhgC0\n",
              "3igYud1qccUalMxZ/LX0QpLWfQORw1aVN+Ozf8lqLzq/oiNGFu+Bvf3PO/xZIvGJdU890w+C9+he\n",
              "5EjyJCcsoEJaQuZq4trANTuXHsowRMEALXIxWNCwtWf0V6IWmJUJtZofRs2PShZh85l46yMMRfSp\n",
              "q3/7112sSEOxDXDOabgo0/s6MRSElq43aFabpYKrPvFxlX/vOUOhJH4YmP6bcFwHFVezJxaTE8RZ\n",
              "60qoKNPSjMyVGQ9P3KSUoSm22v35aUwhzykbW0V7UXZ+R9/8UvEiUYIrqzkmCZ1cUJ9c30nEdb/N\n",
              "N6+tPVj18aHB1pbw0ZkAWFpMGLDqHAHMyT7PrqAiXIpFd5IlPiLeCf7SsT9whl4NQyxG+6K2HE6N\n",
              "Qinm0T8whFW/v6dRhlGX3ygKP4KKHhEq4We14tfF3rFvVrbYB00BVW5Ma6mkAq6AYS/Bs9znBPnA\n",
              "QoRTZiaKbJqXp+KAkgH7Uf+rP7CHbWHlEpbqPbVY/8IjCHQ1GqGz1iVucKiKsbwGOCbYl3bheiK+\n",
              "mNWCKHIbhMeRTjJnsB4+pdnr2+zvzyVFnFfcyrF7Wi5NBxlc/vpL9qJ45wMVCxbGS7CD+jqL8ZxC\n",
              "8xSzKRiAm3J7Zxck8w1gyrhyo3vhwN3G8G6BLj1+fcvstMrq/HW3gZ0JY8zde7xgC1Ovw32BW9Qm\n",
              "dAh14tKfx4nwZn3pNqP8H/Bv5b/wrcYD3Hbb+HJEehQMzhnwkQ21jqbitnS6y5tPDNKjCU4tF4Ze\n",
              "dcO6de1HzOAIndYGaNd1jYsIFz7D6dwi/DpXk9XaxOZVJCYEzv4wV05Zdw5HUBmZZbnwql3W14mj\n",
              "qq+As7TZ6pNEFAPGReMw5UPCPD0yRR4xI76FEC6J3LJ6zmkNOaPJEUC57OMGmAon86U2hi0N9FIC\n",
              "pF9IQJSnMtNOF+METaMxqCId2A16vCIWQBn7kIHgGjn7IRE2xtVHfqITzxSkNmKdu3nOIDS/DImW\n",
              "PdfEmEQdvLtsqzlQEGcR9dVcZRVhlFqcJQSn0D/3zXds9o5gLk2EQQTeVq05Jt/fCHmxliFdBKEc\n",
              "X2aKT+c8ARBkhC2UWgWDFNK9xkuh1iMRmjE7dvCnIxnXVVxcqcH1iYZ3HuLsAIOnd2523NUzYDkE\n",
              "kmeVAhxzP5fGsIKvBwitv4DJegwNS/KsdGAgPSPpCMbhdJufRDtpbnlADvmKa8y/6LCBhPJoGP7G\n",
              "jtpHb8M930Y8AAyV6G3hPxhZAAADAgsAABSBQZoibEEP/qpVAAkPLn2NcYtbAAt5buF2Etlre8g7\n",
              "vi3g1D2Y5cK9LaxghIsJDd9TUodp8n8unBy1Q6jJL215/8XR6/qZxvSQOyTp8SwV6DTfZoPxup14\n",
              "ut8LX8aEmM9Wprjy7LIDlW+GNaFh2VMy2NUz//0fvnjJBsVLd9+dR7UKMjo7J6aSenJi/Mnq0GWr\n",
              "/ic6Yq7Seme6q3vIjvKUth7TczezmWVXvR1lFIPSeAl6qfGBaGmSz8ZjoAUQb6ncZKyvelid98Ad\n",
              "9OxjYFc5TF0ARRE/hy6btFHLHxs79Yz9ekK6vHKgaZPYs/MnW7GBYcTSQBeaijAdJxZqxgbXEFZm\n",
              "6QyqVk1zMgoxvsWEXwmGsHtMbLNPr1rsL//O7Msp1Zr6/aItj2czmlFRhRUvB/+hicGOZk4kBeoL\n",
              "9ERKsyh+O/8jsesaIHDbnCUEGN6fI4W3Tjp/Rc9E4bns/vq9yX8iK0tmCc6tpWD1jnuYow2dqIsY\n",
              "mtEJ8esS1cFImK7PcaCfRgc8kbgpy2Wd/LasPhb+Q1rzT8sdEc4zO6zd7a8qXXq749SKR8Omqx3z\n",
              "tEqxvGj6/CEwThu8YLK3AKnrbaZgsiG6GRGmVO15gDUy+JvvF4JXfEbXtmyYuyo9pQ8kxJVFMdFf\n",
              "6IqTMdDM+IXaP1+nbxfxck6zjjnKaHip+HocSpFMedxszXfvzw0qxfJEC5sCvYbJFx2SBvwdqPaK\n",
              "hwp6kiqXPI0SSbM4UdLIfQyVKxPs/UcVrpk5U6cUEqUpPhwBKLCgcZX8Tm4XZ1GrWrft+TiNkLEp\n",
              "W/6ZT283LwvCUmEPMtYUxnHqJ3NmGw2XQ1Cd2pvzqGqDSdTWx88kUacJqGEt18kq47X7vvHFIrIr\n",
              "GbHQ4ovXLD1q+sggbRlqxqAPs5IukgnzYJ6bnb5v3E3YQTMj8KAjKhZSKn7+f8POs8cmYssk3J0f\n",
              "aRicq4l68n10dAIgLiIv6ODccGhIviNIETyYrfkBUcn8isZsWaZSIGls1NgSKHO+r8cYQzXNI7j1\n",
              "N4SbbHa6e8OFsu3AzMfQ6hZOWr7vdWgeN8pjcZ9f3Rs82mOfQ/Sd0Yqq78aTLvKkj1IP5dt5xkzZ\n",
              "patdPJRP+Aiu65fl5p9LSR0mOnNn68Zd8sJA7zehRKObhSBcb2ud+uEOhysNvQOaMovguMZeD9Co\n",
              "aHG7LKNUY6MbmBMwltcYxyEnO11JVbXhzSdrm/ZNmGNLo05Woe1dtS78r+uml6+UWOw/t+yFJBeV\n",
              "o6LU6h4BYgU3ygCqLZRII1RCZDiYZY3PyD2u9kCEeWKac8i70JDXFUrIyFnih8MGrt+K7AVYUSJi\n",
              "V2NoNMj+AwXRRa+JHrFoxYK2G9lT/lnkwY+YXmKhx+P1EsGmZ3I+BgFGHBkZglFmdEGNrCX7pp8U\n",
              "xEZUBGy1/ligrG2RV6UEGVjEfqpoHlljVB97txKPFuSGwY4imiSTcy7TqHshOE+oHq7zT+j88w5c\n",
              "+Rt7KQejprnX9xo7subBdemD9WhJZEjWWFB9XwdYao9ajvRnnIJgKggqFt1+Z85qXZ/dAFZx9wj8\n",
              "3KcHj09AbMTSYFjU+fFrTd0zfMBFsqXjyHnXueh7soa+F1YorOJdOKwfxqrkZ997GNFB4vTiQwW2\n",
              "0oaI/bocDOgoBB6FkYK014/9WbRbhHbSMB8x8KqGBq7H/KYtsxLigpa3F7K46UQWSv5AqcwBBse4\n",
              "N79iL8KKkZXMJN/AMtuh/S7rgEOelLYLdyIGBxwtbM1zilOA7RqSeFcwujzKJ/oFIwOE5a8JAhi8\n",
              "3MZfjU1S26H5CEiOWjLvWmHYziMcau/DCjI01nJqhcnRPvCOVwJvx9FrqdneYzfCN/t/gRfiPTpe\n",
              "T8FxN273L8epd9AwF8D1ih+3WvHRUJI/p2VmqhlZjNDnpIJzC98wRv/qRn0ts88RIx9F67vILgZ/\n",
              "nAFSYFISE7yFc/Byb8vFFK8DXS+lyAFXrzzbOUbglriSGOBr20ZodyLuBP3LeSEvfuObW/rBzbds\n",
              "/uSWVvfpjC0vtRz1r7Aj1KwF9b1a/VAowKJNQo/euJiItLZlo+0atHFeZhpxzl1D5wjBvOLv5eLV\n",
              "wNzzZN5B2csqwYBCBvY779/i/bMIlWlh1EIkN1nbzCWKVw2k10RPXIQ0ZXLP3fIN5wdx7eo1avcG\n",
              "I+Fp/gsgk5nN60UcnvT1WUggkd32VksByd8Ia4YxERsHeKmfrq4c9o+zm+stu66L9Zsnk/famECp\n",
              "RA/0G3MfsXHFzT6Ic2SYbehFlrvQBeaPTaDj9h8mATlkTf5mf6hO2Yj9yZyWh8qQ9CRdvSsvm9Gu\n",
              "5xqZ8vcJAe8VLWBUwr5RN4B34D1iFCMEbkw9qSEwfg+GOvR4mt61cg5PjvPvt+oAQ4+GhWNH0mJV\n",
              "rO7ekWn+LlGZpT1IjZhtkMZqAmbtqaGPnjRtir5ftVNhgOcgOL6HoofaCeylHp4/l5atvov1+SJ2\n",
              "9T6oqORagUx2jf1t6yPK4KRCCSMi65f+UVXOaU7OLNDBsWCDQF/STfgS7wl+QfidTOBPV7nSygVP\n",
              "LWXiRQgAWJZzHR650IVzMzhIP+f4icfobVG3LWm8dEfJJs0OFsBXbRL3DRLZP+plHs+FoIqb6bK7\n",
              "y0P4vipQgSFJs59ulUud90CupY7qNnaFdIW3wYvXLRGX7QA+1vuJ1CcG0gG6/NcSTYj8ceNSJzfr\n",
              "1bYzzZSrXNMWqlRCJJhVBMc8iZmE7qNic7pj/VwIgg67v2uY+NUL2joq9cF96tjONLAdoFA/VmBK\n",
              "MvIAm48D15rKomZ3fRPXt9qvwgmQhJIYs/VoKy3DV+rJELW/oCNLC7r/9apntk7cCKlFLPGtFkVM\n",
              "eUmCRskaGj5+cq3j+8qs1EP/fD+BHVTAjZTVK+lnqkgagCRv+tkdNlemSAlGTfntOC/osRGcwfjs\n",
              "lpclVTavg0GZpSwD6ai6KdIPsastEGF3mqtrE+Hlw7NmrY1LxkB7EAVDeiZVVScia+RqWqe2Yd/R\n",
              "hDc3D45QyLec41OVqoV/Iz2AkIFoQrfrWGx8fYScn5U5muo7xCfMLZWKz5OBvxuncakzhD+nc/G/\n",
              "+gTL/9udHUCJkOCAxqEjjMSKH37tTSp0GiRwwCl6OlPxMobdvHYc8CifMYCgdjht2c2zYA37P6x3\n",
              "/wmCdHzOMQ4e1m/tFV/3ktJyFaiZYlpR+KJj2TmkGHSopIvTIuqXxhNAv1h4IzE4LtjsdSG7LNq7\n",
              "P9icaKgPY65ZRxmwy8nTkjRKO2RVj9Ft4yP8JjuMF23Obsr502LSkh89snK6ttljyH3cK3UScKo3\n",
              "6hUC3Qzxu6MHh1/iqsyKQkdsNHuwgnLkN7MtmZaZPUhMmD7ym3rU1dljYkgGoay7kj/P8whKox9I\n",
              "n2tfl6VkggQ47Xa8RICs0wpHK0tvMnQsn7rNlt+zeAiLINPC5tm2ONrSvcROZi+nGfBol0cmUjjW\n",
              "NWoUtjdy3PzilKrVgg4aZ52Uuq6zAXswKw/HbikL8s9eMDpqd+v2XhphfMtuPvGiOZtyxNqX7UIA\n",
              "8K6YiLEx3poUWMeBzyfC+4z1JYXZWMYlxBLoi14BjZEamInV2OowCCM2BskJpeGlT7A3prS+tw8n\n",
              "g0pjLHMceXMx9n2k784Kg9QxGsAWLvIOlUDms9jwxdlHg0kLyhyUmp3RO2RAmJoOCmFfzfr/3Ato\n",
              "aNJymJiKWtHvTklWMtXBF6YwPOltey7eMZJJMD8rbLFrettf3CETHU7FT/6fXTxRQs+UIlV3YyDf\n",
              "yMz7Xu9aNPmYO4IGnYUcpmH3VSyo530kv3TsUAxU5W12Mqpo/Z1UhohWufitDCOnIJFgwdJBElBW\n",
              "lvr9tDztexYaCNQXgCqwS8u4mcQYgNPpcK8iReKzMUxblS2LXHqpht3TbUne7WAne/XPK+BA2hNI\n",
              "3hGYr+54H6nW90aoVLtSF+HK2qX9p0ByoKC3zavtUR/AQO7wO5PvqSmEWxfSg6ptWy/mxof20ivL\n",
              "p8D1VLcGBozJ9LkD+UInxQgXHM8BscCmYA6E0dIoOPFac1uRQTCNoj+9iadZ1IZS3DFrthf/cUCM\n",
              "qSjpAY5LBs/wvLW1b6luxbfGQMWqTtD6nsSgZNyZZCoMQeFWvuXTYnRpgS4ZMSPewImPPLRquY9O\n",
              "lr0IIV3zqcT8zlsQFqnnA3e0CoLAYmkQ36sURtxnLGmUSVEDwM/oNEbWbNCzT0Ta1XmgqQ2M4nXj\n",
              "ZgkH8A3vusa0bt0ydG5absiD7Rfg7ZSpVLPzmgbm/kPgDfY325oTb7GDjy4c90a4eZme7ZKgZ6Lm\n",
              "t0wmfaTasnFJRTjYyfvOlXCsNF9PhsUcRFDhQl8a/Rs6H0VJxngo3dG8Solz+F+Gzzqkry4gdq8k\n",
              "xwxd8W4B1y4e2Q1baH+4t18b0HsQaeNCAAwIDxVfIBQwosSf1i2pKiBFh81Nz+/5Hy3HnPO0/uRS\n",
              "fK3M38OwFc+1VRIrQ9QPFs0cYy2KwB5UiJ77+sdf8yFwdgDp0GW9fcMYFUjpO4mCZc7wa2gtePm9\n",
              "KomtF5JDYhO+thzHPoODF0ksk7wD5MyVeNhuX1yUONg3fEzMR2XK8LXH36nyp9LoBIUzpQsoso06\n",
              "rnwKbhe353AgaMGTgVdtUgRDp5Wum9nLdwUoIeDyOHPJoarpyF6rIXi4AXwmatqI/TE4zjKyURYd\n",
              "X3uSmNARCbNf8ciyljjka9qBpRoYbadOGhNVHQdAfKSHUAziC0oTD0pdbuR2zcGq23mW11pFY7eV\n",
              "eS8unpzA+Y88yRwVu9g9sZo8kpZYFucWf8O1Fz18P9N3YUoct2qu2SZracH9yw0nhOgFmOQWgjrp\n",
              "RP/wna03bC5730j2Mzml7cJdtv/IMkVR8ngi0vc++klNKzwfEy8S1r3krky297OzLh+L/0O+pDHg\n",
              "u07dEwSqsTtD8BY36YQn5oQvqLnFUKAyhzrp36UTePvXbhdrCTSBYdNXMlPKinJHFnTBC0f8hB1O\n",
              "8coJrTzYj7LljJZorTCerwm9k6tT2nHPFFwnbd8cZ1T4vjjzbGITFG7Ywy5wZciRcvwKWxKXlDqP\n",
              "pe2ItBolcaqDm3lXUNcFEyKCEgOWOOyItN3Ob1H6UwIgZOvkq57k6P4Pe2IsKp2L8sS4AcvZhOFQ\n",
              "1le+BvE/88tOYDJWgGTFWxUfAiN92yTTviPIyhCQf1ihUCpdcQcVnuX8AD5fyeRhbmZFDqzCehJE\n",
              "zVboFbCLxAca6AKXWXS4ss47HgoPeeRJ21Vv7EDi1qtpm4dOOdxbhMXqwNtxAYVBtA8PiZkGjI5v\n",
              "H2Em8+oB0mmfJZGxvSACdaxJeuN47k8WJgENRLiZgoLWNZGrEC24tmzNK6+bLqgLgem7ATONJhLx\n",
              "5H3yyugmdd19vj/QzS9ozM8MnYCmkQL/KJuc7lU7LaMxFQQuGFZKqr7dJ2/hGh9br/vGEFRoc1pn\n",
              "XN2bNGJGwZB2RRnYfuO0JM4CV5nZ0dyShvgtEPfYJ5vWypwdtxgD3k8ZtiD1IvU5uiCmyG6aTzwY\n",
              "B0W3f6cqtca1vfLxZLf5Qg2la+wJAySWkUNztBQ5ufkdGEUAejSYqLSF996hNRvqVak+HzrHcPdd\n",
              "xu4AbF2rsC8P+AzyS+/gMvAA4ZMvqEmauDE3fhWyBq4RXFgmVS6fjGtPCQYD09lhKy9btH1rR17v\n",
              "kgjIblnM9khT0WHP6x7dJsihtHMXdWfJCe0KhPLFfy80fMt739Sp6R+RiGkeULwBxAl4HABhLj95\n",
              "XvybGpGdv7XaFwMxtQ60ryKfnt4rIWcfxANUoGCT/BwG6f3OQr4ymurQeJ/msBp+WwOwNEv42tmd\n",
              "rSi9Kon36ifYJAP4ptJlbxGJpwhWimYV0mc+9m3Trr1sNOjCcCd5uViD08p29TRrK0VxTyCIOmhV\n",
              "EEWPmLxfbSjolZPfkEKa0tJQX9L8SCMv3JaG0MIWZcjklubNEfRrVD78Cnav0vt2BDZbJXc7xUBD\n",
              "M+pgYXig4gZpiovryfUTOc2Wbnm+7JyMYk0T3Lwqrixg1rJabRz/sg6igjIGwqNdqtenJVHAafIn\n",
              "LtxrDeejTxZURff8WxMP5rmwalvwrI4ye8t3+bG/SC220rRSfG+GT40RbSe0IDgFwkiU+T2dyOl+\n",
              "BMLLrM2LEtRrK9jeKQvw4GKmEJ9OGCtOLj2LygPnaa+hLF4S0HrgkpSbkO9KYfifgACYpJnAS59H\n",
              "vD2pbMS6zkonfITL38Xcy/1aNHWRpgLQSss6ho3q5bzGpTzhWhJX1KFpALIeteCVasxz+WdRTLlN\n",
              "ZDVaTZJkr0HcTKwJPFyAfbDsK2t+LfjYxxbVE6lOrPR5C1oRK0UHWpAYboO1bXpyNYUP+ghligGA\n",
              "0vDGGf+GHii4F/rejCrDMOyrGSYrhRmfG04DY56+WDBb3Ib9RLt4vZXkM5l+oWYL4qFs2kbvJZcp\n",
              "ydQnP+Heog73cTCv24pACFTn/Lj49CSJZhLwlNW3gWnix8j0SP9TG/HrlomWj0bUAibwqX3PKB33\n",
              "YsfNMY75KyTZe6S0At26uFY8r1jVsj+0DOTaDXFmHUV1ALmVru/OwNZG4gv95sDAJxZsMCjKQk/l\n",
              "+mE+2/+XtNIFw00fvRT5Y6RQplBV2UEDdVcB5Yk7piyebOcTmuKlHQZzJuWPMxb/OHf/G9UTxTmE\n",
              "tt0snU0uaOxCsOEWrY0D1zqjebisH2CLR/8BxFL50LggC24PWAVGb4ZEi/NVY5SaWz/oVU29OD/7\n",
              "uDUS9RpkekKnOl9fA2fFQwn4q0Kp9NpeXnxD3F8RVE6FLVGTBABC64It0mnttJu4/8cbMdvctIyi\n",
              "JtWyoreFzYbQEbqD7sN5ozTSEuBRN6lG6H3FmyMToVK7Cy/e2E9kEd6YoZ87yrayH8Lro/yTMNuz\n",
              "T14PreYh7stvxgdDV8uG8r/+aZWCX0qq3MXeib4qwq2QW2O16ko+fle/XI38QKzBBkrrQS3U8v6F\n",
              "Wm4xd95URNJ47swiuojNYxfEXRdwU2E/lR5ERkk+pc8AAA2mAZ5BeQ3/ADzHyaGX6AC1Ib+l9APs\n",
              "G5+XAwbAd1/9/3VLGOPYU4jzNTWZMCc7tR9PuoT5xt56RcNo57YqwnoSqy42KA0i4HfFi5JqV8BV\n",
              "Gs2lcYlt2/1nX02LH5tc+xWDC0A3XdinbfrA+Y5BEcm45Ilcm7qse+SPSM2sJSvP8O1JQnE6grtA\n",
              "ddobDq8V6BGebV7AQs9KE4/GKoVBnjgATwjImF9/HsWGiOL9wGPi+I0Qv8bfmdma1C4PjVxXhDRS\n",
              "lvYx/c9KsebmjIKlgPI49TOOVAIoa0UdKuJSrqU15D6DYAie4AlE9ty+arMnAxp4ICpycyE9c2q7\n",
              "t2Bqa4lZzXOUC5Gt3CjW7i+PG1n8kwzqTfGVZkJPULIAyU9aKZs67J7zCKD3TuWItxIJdZzzz4Fk\n",
              "GKeJbzE6tIADQyv/ZhIgY93ebQRjfgkyp6reDj5xQbXfb96m6Pl0/TfcNpKNhsxRBSVjWKzECJ6j\n",
              "P6K5znnmN5nkT43xQKrnxCMPSQVm1Bu98Gijy9QEuye0fVU3XMru6YE9LmTaBy+EoFYasrKZ1VMZ\n",
              "r3eXM+SaiFe3zkeIzpOcOlMyHyJNW/fUSTNNj2ul2iEG6+7WIrMTvV9+dmAPNSgizaDjuYw2PvNX\n",
              "mE7/h35wTrK6IT/L7/nsCMB+SSl4FDar+XebNvT7+5tmynyuuyivry/tN2cdabVqGZDQkvVMD709\n",
              "K82KK6hLTjeHMQY9bXLy73psWbX17TS2MpVZQqn9fi68mVT5so3IVDPUpIILFev7T9ANBn0gebtr\n",
              "hTHIOIX6K6a3D9QJIJjdf+vVKIeR0bq7rYDDxN5PYdApB82KGiOwc15P0Ylixa+c0Lrl1x4NHAuI\n",
              "6RlaY9NSYoYzPxqF7Dc1c0bkb/rGnIZaIAuHj7YxrolVEoj+F8oLBM0Fjg2/OD3RANE6kFFJOjQQ\n",
              "la6dsSABp3e7y+BEHnBO8GTrCdNT3QOroomDpl0eSddsmHVYw/cN6po+pek7jk+HE4RM0xQ5PpKG\n",
              "HH0Ott8OOOQ10KoX9912df1J8t6cLxsv2Uwu4WgGc7PQElQ719S3/UuraN1fuRf84dtST6zcQ2qU\n",
              "mzWaFpgYwKic+TYTc5I+HqpNx4gT9pLJaaZ5O8fyZ/l+KBKUXIMCP7u8Hid/QIGUorTO1IIoHPrj\n",
              "Gta8aAbOvbeRUme6bucRQtmslN9qEll5sKen6eFr7iZ6eTIBx72SZXcVaOncTVbUV5WF7cpjXI8a\n",
              "UrPOT/aukktlAKF3TALIUkgNH72UNQ/rCqQzXBnoolPorzJSUMnrlY2fHHf9axIILImWizdDxUYP\n",
              "XCnRhflx9qpE4qTiobxSicWFhdnPK9EK9V47hRkgOB7Ed6o+i0YAJmhr6akKdLI5G0k/krwqe7yb\n",
              "WgDhARqSot5p9BIJTmRBfCb2N95Or7Afu7bWWuvOQ5K9zQDEqn0ROo21XqN9zEdQY0bbKTiqx0bZ\n",
              "SKXUKqi9HOxtJPiPcO5Bms94c6ht9whCNctjPoOrtvINCB50tF1MCsWoOfQIiBJDIfQIM3lFl1eS\n",
              "2fKCWC/I2Y9pfr3zF0Yz4URSyMez49G6vQHUhZe2t7M6jvr6tF7IQ/7qUeDjloX8kdcjYHzuAROf\n",
              "0rY5mk8Tz8DPWRkQhVRQzb5WBBXKmOitJ2QVnVeqh9Pb/Z6Hp2AECCrt9w9ILkZhAN6vir0sq1BE\n",
              "8/mU9Qgt4f7vUqbHGmgVHv/YkMaB0oeFSS1h8h2MefWZ2HHawF0FPxqkzXw4uAGxV8jXi1vP3KZR\n",
              "NBxxOIeY0YH9lKe2uiRCFKuuwe/ik+cbT+lyq8dyLOX9fbt8io4BHc+rB/r0FyQiKsWgZS1NYiY+\n",
              "QfqBNQOYVRKXRft0i9es3sD2s+LAwZID6GsyiUlDS5rwJzvATJqRe7j0scLFuMDUwxXJTXNrluQK\n",
              "Z0UxLiTSndYfK8rKqxVIkiiRMOekd192Bhuu9I6C33naOv8tMnxDj/Z/IucNFFCgYZ4cZqx1FhBm\n",
              "BLF8Qwr0D2bLewj3u4ymm5qrww6pNs0zRb3mZLprdmbHByzWkGmZxyISoI/lxIxW4G8SLa3/ywTh\n",
              "+Xyh018CRL8Mku4Dc8JwSFUvjlX6ccaArX42lBVvocY75Of2K6268wC6+JALQHd58LADHAlkE6pl\n",
              "vLLIqxa+wK9DB+oIxtXahln5s5J5LZatQGQWlYuY6yN1Ri3mggVm5lAXxPEEn7YmkfJtABcE4ZSl\n",
              "R/DQ1OfJ6IiLCvqilAWMek8ytue152w88yoZmnyUo+R472iE0ffxQcr1Be5tJE42hg/R21AIeKNr\n",
              "DLKKSl9Sb6GUkVIwGTnFugbZnd2vv9JA/V+fADTE34v2EaYqYFO1AjBuQepAoGXL/3zdMC5HeUTv\n",
              "Gd16S9iRRDzwNlMk7IrSvWATc9HSgckYTfV3UZRkR09zKLA6oRmn/n1eskrM0mRpBXu9MnQopIVt\n",
              "PtNMRQ63yOmZzS2jqR7VIqHhehhdObiWv8NjbAQaKJLiq+JwgNOOSUJK2K5OGKPl9LABX7bDztaM\n",
              "m1+f/eVa12SDlk+iA8tjf8teecVPGRU9CtEaE/5NX34SymWlSbJ4RFpVyN89YxAcXChxZA5rLbq2\n",
              "kA/K098JtTEZRrhxXkKf8ZAHRZoJlP4nK3BpEDP1OuWWnK5c2E5Ug1G7inr41u2IWlL/NFGnL3kp\n",
              "1Eug1B0wgKYUq6RtphuLxPBVgOr1/8FIVP3FtnozC3YekYyCRJFCIpRqNJ6lxh4qqiVUNxJ+pvwO\n",
              "w3X7ZMX99LfC3MYLesKpZCx/40uoTFsuvNQNB2p39U+/mv9CGfxCkCvakMvHI7+97DHgWC5mRd+9\n",
              "jSpCNw/yB8cucxCkRKPfMarLjk+Czv0YLJbyZamYCwLgHIQ/H3+I0QcbpDPja9+oysVcxZ0AeyS8\n",
              "D9xrHrSV9zEGE5ACLandait2K9a498QmBV0nYGSZPyo2tcugsdOOAJVxt9cm+v8JBkqWUAxfyDFP\n",
              "65qckGDR5umOPnJCNN0rD2U4QNUjrRQt5skuY3+nnX9JLXQn+ucE4kYGKKYv3iJtq/Ba4ai+Ki4+\n",
              "JRO1SAkO5ZLzr9uW8xEV+tTXFfl4Zj8L4pX7IHeEmRu07w6k/QB12m3Ig+nXOnpoI7v2EYXohT4n\n",
              "9SpQtWT7UlGzzsTi9pP06S4khLNRgStUlj3x+oGCD30v6ygo2Kdnp7qsm7YDu/43CGJeextAppGA\n",
              "7uf315aT423E1DNpJka5GUbQD1hbCeqG4ZDZ9nQGxiiDPi6xh8V1QyNRhXqKc3wGwVR3VCRMgsM5\n",
              "wqGuwEpzAnkcej7TjDM4ar0dnRaOZh5eGqv7hj7MKam9aivlCL6RNTLk0Rrd3LoyUMZ37FMUA4Yh\n",
              "NmcR+hLr0wDb3heg6TSuKuqQGkYEst1uK5OwXmt6HTNFSbh4RbxBElnCbARluChx1zpJC+uGnLGo\n",
              "vT4olVrcVjfHlEKf6FQLEQLmLDvfmzf2mTkAGQjIbd+wZWyEEgHy70jzy/uCwrPPztKFxmVSZ3Dd\n",
              "hNfSZJhS6lqzLNikWnOxerQEUQ7Bt5Fm80LsNeAY+axL1U2PIFt7H5VaGBUvlFGQoY8W1bsgYMh5\n",
              "JlPdT00wURWcEz5gsrjrktgBvTxmLJiT06FO2uUza+hxn7ClP1WiIOrJBgTNOfMp4BMbRtdCtQ8L\n",
              "+q6gtBVSVg8ScyAdF96tXiFhhiGxwN2jvk5MBwqKn1WE5rwRncM054PKR7XPC28xtdHICq1DW1GP\n",
              "LpvdXIzOhZqBl7OtAyLSZJIvsGuxizQPCFy3TfVpAMll9Oah65zkloN6ZQuGXJU1+rWSB5093I5b\n",
              "lagsJ4EdqiRdgO35mMe+DAX2Yt8SGaktpA3foYrBdt66jAG1JeqbnOohyukOXmY6i5Nj1vP+Urte\n",
              "fx0Y14s9WL5PN+2vqVLO7aPkzANgb0RHSvErFgAu+AE2GMO4HQWbQO2k8qi6+ijcr2bj1njTUNJc\n",
              "evVYCZCly8rfmnrCwcyhnLanJ+7BfVMpAgcHl5HoNtFxO64ZxxxQhhwddWPB6KQhzNWScMHdd52k\n",
              "OUBQY+R7UzP5Lneqq1Xcj1mHk6/Gx9SJitOLjoOfQI31JRoVIqVckNWUISXBaHr5W4amvU+Ey94a\n",
              "qSIUK0VYmTwnYkIrKg0THL/+8Ik/AboRqVNH5gnPICrFQWQ5YqMeZkZVthR9INsoneOMXjbl+bjF\n",
              "k8hhV3R+HJDfuUzgchFjZ8BqChHiOzNyH7fsSWCjGH+YLXSXlvjyT42vXskeTGhNiRhSybUKbrOD\n",
              "2/FKUIOCYYbfp68l5egHHGJ95uruq9ITkRYITnwp06lbbvTlNe8CUgo6d9OY+BThJam+cHMo8r5o\n",
              "DZFhv+EkuTnYWYFK++RPlrwd4eiRjIDL556Oa/DMkJe/PvNZNYi5bbG8G4R36Cu1kWxFVY/vBu4r\n",
              "HPwYVOp81GD664K7v5AfC9bOaDFGt57MwRdkXIX6FYH3XuvMooIgu+sOg8GlOESoKvUeQVUzuXMf\n",
              "XTnv1c/DU7XuadSDVN47Whyac94wFV6nWGk5rCvwAga8CbEbDzffkkkXEWQOSMP4dX2dmGqFPFgW\n",
              "ejsuT1M5403UGmnLg0VUf/UZkSeVX6OQJkXFyPYK4/q+KZx9NW9ZJ98/+HgkouPCmTof49EAAAxw\n",
              "QZpEPCGTKYQ///6plgBXfhXFi7NtxLUoU+1OcExASWNQ+8jkDpg7DE4FSm+lAmGghfqDqUpkB3n8\n",
              "M56acnYBYtLmXudx6j83C5ARdDtwwt/RoFP0NpsFmhXlM/g3tQ+yYX8cvn2LStE5kjPqTmQ80K6y\n",
              "Kvaqpi+uj5xDEBawURSZAEl7RJeFX/Cv/dGqtjUDBLWS+r+pArVg1hBqtKmmSbvLiFI4AHNO0vVC\n",
              "81eqydWfEnpyC3kOngBBySQGxODJZnfI2QW1oiRREjq2V9xigDuX6VFd+OM2x2Jx8xWjmyx4t0fh\n",
              "31mEoZ5Ek3nWBeWyaZrrQU46PInGXKGJgTGJOTxcllI5uOXv8o1+yUti/Bqnp5y5RfqdWSsebviv\n",
              "H5G1HF54xnoOrFlL4yekxwNGxOB7vZxvEO81Xwd5qCNlg0R3LYNbWA6m7IWOmnkB49Wzlwl+sxK6\n",
              "ci+dl+XdSf7Nzc4p2JKebS+vf9p1sriHGieTbBcYZ7D6AkpEEMt0xIxFKEnV90B02TCajJ7M2NX2\n",
              "lFt9as7OF+GHlJw/z2kDFz4T3qrIeGYVqo9HkXFl1eG3ZsZrzNgJ7XdVJIm3T5FAfDIb+sKsK2Cn\n",
              "DFqxO0CMZhLd62O5XEgKfnF85waSKH3DCp9maDjh2rfBJVgzS3KbUarIheXTwnmXNBokBrloFBny\n",
              "oebT24uz0+nlMpl4H3vgldNbC9Amw6tj99yLGHthF+PEehiu6eYvsw3xdx0isQ8K/GWnLmBA7Gt8\n",
              "Oh/Agr9IGaiJTbG3au+c9UEF6n8DGvZWjWrEE6cA2b+Vg0/tSl4axADPhXeUVovw+W0eGlsfbB3t\n",
              "eioW2+xYn5epUf4hrgmp9TPcVJrqF91toC9zOlMnjl+uLUSTfOEsabarWVL+ZDsgj9uhFMdAb7LU\n",
              "ZaXAsjXzr4EFUSLE5Rg5hAtOQSdf4bv/uu0xB32RkaOPJZ+fDAzmyagAyKlijEvVpEOvzdsqaYDd\n",
              "ItH8o0qZOMOHpAQyjjyY6rKjfl35hlU6TlIQu1FqNOJjfZt+sJtVHwnx+EdNko8LJOqH7KwlVUfN\n",
              "Dwf9mjp/4Uc8UIR2t+0UJEQWPnyKk7FxHPOYPURuAArjEnfZc2njGtvkzvfbrpDwoULA7Qsg3EMd\n",
              "GHJLb4NzO0n5CuUKcPu0Jua3jGebsBIdSdXj35Uftm+GkqDBD29ZQ1pXicNKs14KYS0ytQs5aFd6\n",
              "AVG4iIkwQR8+eIOEZLxwngru6jMhRFVmSrrn1/LJAjiKJXdhx90TtjvCX2Xtl+bJZQLgGtw0OBGt\n",
              "MXOQXH7rDXKcsstAB8cd9CZZH/UEEOWqJDE6sIM6/VJ/l27xA39TxfHwe8CGAg+mlUptM7SmI/MT\n",
              "wSN+PNu9ilIW6W5qOvyDe8iPQrEfSX/5aqKGhspP3FCvVeKPsddJWM0DXgxlfZK9Flyeetc7iS8y\n",
              "/Ja2q4F98+CCVTE0hEp573CuzFPHuiBgv9HCQG5U4mexkcHpF509pdSL65z+39t7D38Lxw2CWKSj\n",
              "2x/0VMtwKHf6TSYKqNPpYwxb7XnVYhw1pARyu8P+QX4XnHwb0rdFcsT7U1OLLVFTvRIbWW0vgFsw\n",
              "lIgNxhcWXsbX6lWZ5N61slH6Bx71gS8W6X07N8Up59pHqUSeGDD14IQb7rEEJTgUHzm8bTbKUF+h\n",
              "F/5JlI9HnsnrR3qs/bsb2pX9Ca81HocsjAcVlkCZyKyAAD9JASSUssgnXxS/QjINExtaX3RApzAf\n",
              "m40fGA6+LlfTd17uZNH9xImtYjcgZDEQjggnvU6Lb2sfJXxhSi2k5yMsRU44+zf5HvopFE6dl1Ax\n",
              "Cjgi1kJ2OsgepnzJ6xpllbC6+cTYZ59VQl8Y6zePJBQ+mk79PCvM0XfAXYDKq3W6XgDlFPJ2lepy\n",
              "TdeDqX6O9SbPp80mVjEsx/WH1lWstvd1tteDOQjP2GG/DS/vq5xpNNgnczbeQeKvN1Vh2gkFRgCy\n",
              "thS69zvP/E3X5Ws7iQFKRoIYopJ95sB5jJwpZn7J8WWgLZOPiOiMJayXLMMzGc6RNLss56cEKiMj\n",
              "jKm8fa4Zq9HuZFdLzu2KSmHKPDVMik8mFqggkeIOj7FAV3gvpSsB1YjOQWo2iER27m5aNzQrPUyA\n",
              "m1UP/aiBgtUT+noqRDkIlZbrigiM4BYciKMuplQw3TlS1rLpwF6oR/rF95CLkjSp7jX1WCJGzVD8\n",
              "JOrDlY/0Le1Wrdb4AsItWu47UmeKdxQCMOz4wsuCuoCzLEKfjt8xLe+lIJ6jKOAgAG1FPjItbtX1\n",
              "Z02hXZaJCzXXZb0ENoIjCIed62fle7sf5YGMY47D4/bU0QrOW8eAJRtxN79lsHdsv2RBJoPPCX9t\n",
              "u64bhHa1WHabJVQSxa0R45siMQ0RiKszUJHYAunn5T9qL6HZ2XDjkr4ILz8ZfO/BEn4x/6m4e7Gf\n",
              "Yl3W8gct9b2WmHT1MqSb3gC+Sc79+7j3WCyULbV0hRLgLZN/j2/N101f+s16yuw+RnvwJKxLEnwx\n",
              "q7sETd4QEvLm9/gRvcDGgf7G2T+Nbf8JHfPyOr1EeyWpbc9qS/1Kxv0VWE6TvfZ8UsaNqZhyh+hX\n",
              "uAuy1ArPvNPpf9qEgrdB98Du97Jr1rqwR4/qWbT8tKYgznVMO1i0+Z68t10zRJFvqnpPa3Zs8iuR\n",
              "p31WU/cBWQlTn3FTuCE/EY+vkW740u6l4qrDoQKloaVIn+dtr+z1148cL/pv+34ugqV/EIugMRJz\n",
              "SAk8XkN5QGV4hIucPubG4P8qcVrUqdO3qDrNCmcGT6GWLHAw3pAUVWnCwKSW/z5sQJVX8F/6dPQR\n",
              "+OkCQuntObaYQ2WIuqZB3+FiPRcQIQUSH5k26AJZilQeDorVxtrhvWZrRo2xXeJGcv1OJTOih6EZ\n",
              "tiRaA5Ges/usgAbkt9aZiC6y9AU7ZUUMMME2C6UWIbKusOtjKAVriqvXpXoZ/xR0k4Bf3hpo0nQ6\n",
              "fRMrsOkEn+gELbVqt/LXL/XX+o+rBE9jMuNOlzdFbLOulFUPnw/fclZq54dOSUItJcnWA+T5LFAp\n",
              "/Gu+m/zOUEPYFtVxh6o272S4R+8CHgx7XF7rDT/UI2K2XpSUluyEVo8uLr8sWcXAkdb9Qi/M6X7O\n",
              "KcnmE1GjftvGSKD6hUyhXvq/pXWbm9berSbeKPRis19k6MYraaJyfwngx6CE+yifez+dTt1bNM4k\n",
              "NRRxjsR7X1t4oy5mJd49rPOsVdDPedTFvhhSU51WdARPBhr70S5p1Ub4ccf07skkQDN+/ZagMgs1\n",
              "ysUx9WHI8DyPBHf9/gsVNVV36lz0AFTQh1ctwMNd0zNEF/PaeQe43R1nSloAFTPUYfTlx+3insuC\n",
              "8ed5+nJnPT80Tv/pmnHlp2HAbwJBrQlS5meIZgtwEsawNZUDQ6jGKG9nQ4llRJpvt94FnGoFi9Db\n",
              "z6Sk9RGTd16AZzvxmiOqjUBU3vjmau2Y5gm2/hbXRIKkxhlD1DmTftLdJ7AzykCnJvBFQKHhkooq\n",
              "z2o80xYJGMJBkB+oXoP+cYBFZ7wlEqZrOFdcvSMcLfz113sfl6g9q+vX15eePPY/KJhUpKQ/aCM5\n",
              "QvTRs0DOWNi4BEXki14f99t2hU1ISL+5MmTNKIjWyA4B942vpwqiFdKkRkk/lPUxldvT5B1eEo7e\n",
              "NRcglqGijqGm7jvfoAsaHts5SZAfliwBDxGTFoX0uo2DnEgXuZkIySha77YLLZe1c07/G69psnhe\n",
              "FeKdOFmFuxgGCJwBorVopu+Atu76jWHuzuTuZTHVr91wal7yPsnVrevzYjZhENj1YZY/xjzJ2PQ2\n",
              "PyQjFMM454CzDUk8EXq7B50lvPQeVYKEhoGdFA6lM6E9HfxD2YseYoc5Fv+DJiaRLaf2K+qZjIsT\n",
              "OXncNgHpNT4JU9ds08yfF/MEosKl/3ZO1dHLGGp5KOJ8gjfe3MS6OQ7cEa2uYES6OFqi/0Xfhy2j\n",
              "rnrIhE5C02Or9+FPmXOFEaKoBsuWXMFVJ8WV/nGwFJowkJ+7WpR+66IZjrp4RyMyNJ7NdqVetfCf\n",
              "oZzjuI3kOQsv6Vq+Y6Ak9B6zWOyvafQ2y/c9GkNok+JgTix2XRo8jPYYvtlt7jZ2uJbPj21Hlvu2\n",
              "8ezqp1kFKYdgywYsvYnUzAD3xSR7tS+jc59hvO9ZhHBCuSBOThJcSYD0cpbCr9b4TOo636mX9Wfq\n",
              "9wQBhaEqAazhilHYTdTkpwJ4HcAhDW2jcJ5xeenF3yuqUKz27wgSJCG1FNmQ5vgBrAAAB2IBnmNq\n",
              "Q38APL3BB3dcSAC+vgon4/6dKE+eR5lgEG/nAcTUyyJXoxGkwBvk2gHgKDNEQQCnwZ9bih2DnOMr\n",
              "SJeQwHd6bYNCvWFouhXeWK3ml+yUPFjfUcN+hV+8dHVUBZ6UwZdqhiQBNXYGh10C1kGEhPNrYpf9\n",
              "Wof/LlTyKurRrMJ3basFDxPya0W5uZg/1+66Czs3GoZ3mbS5LveCRmpnOm4OJmQw4THewGD/k2N6\n",
              "qpwd6LCARVHbLgddVhwVaUu9cxX1teoNgWk4qeDPadeb5uyxwwVnRv831nOot6Oorvc4H8mwxcoQ\n",
              "wuVy/Xe8DqypDbUS9g7JkS0s5yrbpqFyRo9nSQx7idz0f6JDYz6wkuIQigKwQaIziMaw1fY+JU0n\n",
              "Z3kbYucxG0TGJgfS5Uu8YQPStL6j42wjR8EKHZj6du7SkoL1YORP61ajtnSvZlxJUJIxqjcjvmIp\n",
              "7qj8QbrXIIHF2kp0dMZZ1dBVCRhkCZkKc8S0HmNwonaCfbX21IScHJd23lu/z4SKAcLyCmqQYeF1\n",
              "40ziGDDMEC11VYhR2uRxCsjWV8yFrxOkiV1IQpICaKivSt35P9SxWgAmmLtI7jlLh6lsBn5z2ugQ\n",
              "j4Wpfwry2uyPaMC9ROhZZBqpHiw/xbNvlvJgEmU29Fi+8mxhcLPm+xGhcUJxCqRoNgs+NJlYIq50\n",
              "AwfR5JEkw7Hu4CZGKDFffg5Gwr1aKfq1eHDZUYbl+3T8cCJbTjBthHsS4gn/UNeBUVx2CqkVreMe\n",
              "mQYU6aDZQb+iLdXzYI+qMz7LO0hEmcjtMhvZCIsI/nBxVAkCufW0VmbATm6tr+mQbOLu2uHotwTF\n",
              "zgKtzr7DvuofVbF5B0xASsrFpoZTYJH++xSyH8RO+lkfi6iKBPk6VLICNABCrNK+BJPg4W80loEq\n",
              "SDBRfVoy7Lhlh4CkxQl4kemI7o1nysQj9Q1zgpbDUPusNSGlyvHBlDkrDYqk/w1DdV7P1cMqwRw4\n",
              "1YwIRkPfzIR2xX551SoB1cNhOg14ohj3iJSYzNBBWNWPX/zJAsCFcyis3xqOfXPisO0SNWBpB4oN\n",
              "UBI7DDveGJXMGybapAmJE+f8/DIh1zDL3dBdUJBWjChQNP+/n+cOAd7mFafE7EdIs/cR2nYhmvHD\n",
              "UZyTsqPtwdlxlJAOKefFElN6rRbroosbCoZjQ2lsNI5hK3cmv/CK24dNYiAx4FO6w3o05grrYnJz\n",
              "7+wKs+pRDy2e9K853bnASw68erQ/hT/GcMkwHWLcgmnuZYkjH7hkMRFfiHTvBExFHreu9YkDMzuq\n",
              "FEz9o8XlB0Oxm/jfaxXtZC+LfQDYbRSJPqCsLuYaXtPCFBFodh032EzJNbC3NqwOe+0q0qiMAT2u\n",
              "g/sNCwezNgrUV1tfyKEcWg6ba9Yn+bA81nkJBHj4huobllvscE7jxjnJ0BXznUtcnQKcAOXKr/27\n",
              "x4AxNcG/5vHpaYQ/vBP2ql2aU9Q8awEh1gz3eT0+FfpLhxA1WzA6ZSuI+IgSV9tF5wlXVHu5O/EM\n",
              "XLtjFte47ES0qmGnIhbZcGYj3YTI8Jv5cJd+9Y9LGwxHDTrF0ECbFfSkDK1RJSAUc6Oz5IoMsEjX\n",
              "WB0e2zOfXC6JgfCmZnIbfHDavhuMNkGVSa70Jb8SzDuczkte7GJMnyCdcI8te0uuVLPKagrR4ZVN\n",
              "sc0JcMd27XjkNhLxWAM7bjZMrnZ8ReL9kou+PlRnXDBnHHf9Tc7pynC0kAIjUD/7DMuxA/GThjG3\n",
              "aGdUgp5sFXfPwyHt1kYgVr4KB2cBuPkd5/YQv5aOV3BHgbTpXSIOY0NGw8CXl60uMQhSOQS/Cgni\n",
              "h9azLD8Grfa6J+voQX1zLaLBv5go//6LGfja0otrD+Ur4CadlKKfPzTBp/Agi5ZOKk1Qe8Qtd1Ws\n",
              "Wxr//nCxuUs62TFGTYQDHBtw0x/thxQZ1w04qROSjt8x10ve4St9r8niK5hzDdwConMeeYp9YYTP\n",
              "PVEPbkGSHT3YgnJRHlkCvI3BuPTM3PGQKHSrO9xJEYaYok/yAeV/b9VyawlGqrh1kVJwshBXpsIg\n",
              "juXAqIANAFEXuzfvuKjpU6n9Rp6eEoMd4sVJqGZKtCkoyRW9CXgfvSno8EIsM+4HeqZfuyn7MbAJ\n",
              "dSbTJgIKMI/KWw4ueg4KIWZ03LrYlR+oYOyQa0BOYPrrcvqTJKw0AB4wDoC00tjIB1r26yvi0mue\n",
              "je0C2id30Gr5ME/ggzClrTUkx4S4Nw67dWHDtItKv8h5LCJFVpei23AiEBEZmIksxqz9FJPbKmbl\n",
              "IB+l9POYKsPQ9LUvbDyJPHMcD/05AhZPLBi7CdxvqDKV6kYi6hXN3GLIia21+l+cdAbMP3IQPnrr\n",
              "ZrtPWFLa6ktxN9CrsT2hESpNiZqDIOw0aDEtgKm2BtIr+jgAjghYI7+Iz4RSWWMQ/HJUvxH0+msK\n",
              "Qftp7p9DFG/ksyGmbMNUjv8h6DU+ca+TxnMrb2Uxttc3tFb0FF4dmX40StZDOJT0kTacWYeayM6k\n",
              "cMbAw8EAAAwDQZpnSeEPJlMCG//+p4QARUfc9mupfBLIep4AL5V5mgcv3QvUWlDogYW7Ye578uJj\n",
              "kzXah7kHxi4MNwFL/9LBJIQLyIKTmGgpGbIMuRnnW8/B4Eme0his5yDItXtGQz3AiobLKDwUzyQz\n",
              "dXz4wqO0CJIDP1VEtfZk0EyBD5obmCuzrMYtb6DlJ2NQMC6S9tsZT9whaV5fd4Jor8mwIUEjS8Nk\n",
              "9WA9oSVia09G5YW+7VqINehgQxtN6uZ+AFo+TTvg+szbh1/D6ytFVspJcXXI+QLuqovayUDtsuxu\n",
              "I88A9KCcSI+XdCjiLOXHMQdtLPQ2Zb2lhc0JtOCIiYDJmzCDL7USsfHlugKDTjVs+h/3iEwWvF7C\n",
              "7Vp2f9/gfcKbNe4bxgfioC8jEjXcpmiHv3b5pT/GfRSTnFm04/kBoY+qgtYo7XUO859dvCNSSGPN\n",
              "7P7F+66sBVTWuZxqLJMvQZFxwZdejrNtR5GXYNRH5B0tBNTOkVc18Cd2Zk+0SLe9ueTP7oklFxAt\n",
              "EnbwMGKN+EURyckfFyho1o30QTNV+2BRgPwekuhd2xJ+iFc/99McIFRjI/SiaXhw6uWW7aSpnLey\n",
              "cdTEKMz316jnv+IuNEVgWio2mPyvVVO4LrsjOnhsAbu7+mWVzNvOFrXSFHpYjsFGpoGWStAo/MYu\n",
              "I3B1miQjbqaVxgi7KYxL9PNskx+iOFRijqxWwNzLLKOlkVzDk4yBTPpIG/LP4RyGI1/iLlVfQZgM\n",
              "deQpo2vf8gdQk7dFMJkwLuWT0OCryAXVAmFdtPk0P7u7vCxNwh5h6OaH7MLggxS6RZ51iI927dpr\n",
              "sJyz2xFAwsuTVBvZ7nNY86ufPTXs/9jzUR9nDiN7CwSLI1zzzV0OliiZ/bkYmrV5tq1oTqhhX9ar\n",
              "AgMnln4LW02wGYPHWm2kEp5hNQFfKs4P8P1YHX1BV38XKSSwDZR7kWJWd4a/P3a3k5pFiXxAQK9g\n",
              "3QLaXPMi/oQOP2wtx8EpbhOExd2Y1HqA2dAn1ulT9pTWs9bB+zMdqqWxS/qHIxxaTZEQc5I0vi6e\n",
              "KHcf3rf2ir8PPdhFw1Ct832eYh6eOAMyzwUC9arK4X9j3ZZrU4Cj1US+uEZ2srW4ZVas12qlPhM4\n",
              "haT0LjWAKnWXBjfraa4iXsnKvM5OHFqhrNjKoSIOH15pz3M/O6jJy4pm+i8/oGkURqe9imdY3J1f\n",
              "HZptoVDqx1gqFGLpYMgEOHzyD3FzgLoiryPWB9QKggeo4QHhGJHijXcyT13hPvuegT+n+D3VfBSd\n",
              "AQqUSVYl+cpMvVwrAwe3QWYu2+/ltT1n1LXBE8n2xQoIqyqpY86ColES5QhPsdx+qS5eWAvlJzBv\n",
              "Y/XWrARI0COYZMKErFPfijphgvTWwLoMP7rIILwgi21V9nZD2h+PfeD2jyC3WBMEyu6uKRGt4X+4\n",
              "e4AQ1a+Npt9YrZUOx8JfTENpcXhT6seYZNil1sfbSlwCFGmN3QtRlzUUTbdej5M0hpWcZ9wTAs0C\n",
              "Ef1x0lC1alWTNZ7o2CMmKXbFgGrYnQViI36xcr8RN90MN1x4jw7auK7g1DP8670i29mbHmhX9PbD\n",
              "TSrEHvRFaSv2xfsv2EkCb/56bwOnQYQ9gT/BvsuwPK4W/EDsZSD8BOfNeSk/Ru6SR6A1fnHi+5oV\n",
              "SvXDp3vfXoWF0NwYHamtzwdbICtF05BfyJozTSJRgEx5vWIaABPxdaiq7Zcrv7bJgMTJwnrRugCg\n",
              "z59Uu10kD9AFrIgBK102GHMGjWZn8QiSR4r6yBwZS3ts6VNc5l8krk5sLZA6LZz16T5ZGLUTLXem\n",
              "uiqc8t1pjouYdfi36xFr97sIl6QM9J9Z2URfssqcCY6b8nIrTLUlZbOOc60Dq4utQCG/X+n0i1gB\n",
              "DfkcygIlhU0qt+gDtJ75xsxbaIEhM8rEGnLJd8p58wvoxSigdByyA7c291B5U7T70W7h/5pHdROn\n",
              "rTA21E80CtXpVCpOX8u0Q/UtBDyfdVlsBgMSszm7C/+nLUxwbePWe7bnl+HGcVfbjCaum1rpCml9\n",
              "UZDbgiHGNwRAKH5IAhmalgSxa4gw5uhwcbbHjz4a4mKaiEOdPqIPKhA4a7iySlTKypSI736pGqSM\n",
              "KQ81JX/EiVUhUYLuEEMIKVXO0V3e1mK2IxwjWjjBFA43RLCCKEkPbXYPuqwVthnE91NH+n9TWPhp\n",
              "AW50tyFll/uxEDtmbi+1LiU9w0ZbpMpEeAu2YN1I8y1MJmtGTRuaJI8Krdb/ywatCylkNAKorqgz\n",
              "oJS15D0R7wMPYYPFEJDE82/ga3HTLoPEDNiM9THU1ERirZhWtmH9bnwaynJkYUZxRgxg5Eu71BqT\n",
              "P+JNQVsM6rQs9uBP2MYzTge21FSWlaWvAtY6+J7OG4RwTloivfFWDeV9udGsqIkvoTewEa6mFvN+\n",
              "1mvN3DhNvTb0xQWrKifV1PdYIGhD2pvL6kF3FS3XbU3WCIGTHNGvWzT825UAom1fLyvdANqV0xZa\n",
              "iB2b8ZietfbFOtRrYn4ptKFCB7yVToxUoSvI7YsAcdJqCWGHPdxUoJyo8MJIRm1SZ8vVK3TBjWrn\n",
              "FLLy63XFvf/QdGwlPltaIVKsJGeMFOwyv1f1UeTwLhOqcKBeM6GLp1yvAGRKEpm/FFyTzsCgqkci\n",
              "TicW0M1nLUngTfgmucOUfMTT+cYcydUPvfoIX7B224pMcecgfYCb6v4yBUiwncTNbLgqBzLxUGcA\n",
              "0dtz7Y6v5nXe2gDfXjkAgfE4jYDKBdwTs7cyR+Dx5mI2JK6BN+61lRaRMCb0Eyq98QbQSFZSgYaQ\n",
              "L1H5LXJUPmCTz+/Qq3WFHukJ7eybBDHIaQNKtVx/A3E9cW/+i6mHXsA9SuMzmGY3kj4KshVp+zaa\n",
              "dCuiDP5IluMWUctA6gj2NFPHUufyWowU0urKL38MCM+R8KeNVu59W750GqIQdqSXSQJrC/gWot87\n",
              "MnXw0/bSBELpQ6+KR6hMImBgKPunuRRS4YR2ZBEOc75J9jJVQWDDX9NnV9F2/L7fPaRC96BDnerH\n",
              "K8dbzXfGUc+ICghFZ/uetfPaQl+RrlZJNGAEMZ2UJS1E6fcPXVAv8Z/ZkIcn54+AuB4JvxED1M0a\n",
              "blgOM027wfGD6XJBhYCZyh6VQYv0ppCVBD3p3OXOyfd9YVc4HOW2x60ivZWDX6AVj1Q3WgHdEoEc\n",
              "7/WjU/IaHnVvUsCnI6vaOgy00JokhTAc/s+/X+zegKK3CMDeUfGweyKZfkkrWBT1E4DaJmoS1Jii\n",
              "5PObCKgjiBixn5l1T4kXgrE34E2kqAr9/jv1NjAZjlcSisBt+FViMopqNUwQOD7rApPewvTEXVfE\n",
              "u4Wi5AlhWiBrhIF3IAg4yUv913hI6ZKWX2mpv9FeiiopE5nBA1q5WTNJgUNzVAaM9HLgH+6UQdOv\n",
              "brX/9CgCIquocF5Fee0wZAOFMTKKffqqxCazC79a+mZZhswKOYrjv+FeczETGmmhTXAWwELpA05i\n",
              "nzMP6jumAy2LG6DxXF+A3YCqegdBEDPYxdPTTaNkvDdJ5TTb07C0mNpRMFrRxMCe0FFwlPMmdDSG\n",
              "rCV+VeCcektr8HM4OBqFNHzYx3DinRA7332HMzc7mAN8dGJJ2SqbPJz9YCCV2ZSonvsRBLav3Su5\n",
              "WtgQ8Hp0gqEvZXkDkzF4NGw/KLUSVHuzhUSQYQExu3p2j61qzGBMd39KkNoEVwu808fT4F31nEvM\n",
              "jSGN2lRZCVSItLM/mK3VdLPaXHFd/dqjJaDyp/1jiz9IRA+b4z3rjvcCRDoFR9G8g8GAKtvTBuN6\n",
              "rZ+zclYt5c0m2fjGGw9pEIL0sQscN03/9w2RZR6pWunsQKFvyIaQO4B/7gzUABaerl8XVAy+PInI\n",
              "GQZdVelGtdLk6TlL+QOq3giP7IoM1HeuV9vSuSG8QKJaXr+gohhjuIHIuwVTw92Hbj90/JQ07tb0\n",
              "NHXUT49XMy1ngTRNn7Gunx4q1V9G4HHA4gxGhgP114bm+SnVvIf3X25FoK0Wj8Q8Mkr2aXvVWnAH\n",
              "h+YVfDLknCxtRdHN1AdqmuVVLvQ1vXn9XhrTD8HG3EXalff0emMUlZIHx231wZhZxN0LrLg0Xr6n\n",
              "x6x98peBAAAOukGehUURPDf/ABh6Uzg//ohwAE3wRTUwgGd6SyGTHKGuly7jL7NCIuc3ia9qMrNS\n",
              "RPnu4FKbvCsfbNVSVjyAL0jmo2ISrWKG8y4r2gM5paB96vSav+y8fBqcnrhA0EqQH6XIKdHpsH1Q\n",
              "NpM/22H/dRcI/AFDQ3JCjmNMhErJu3GHtgxmDUOrqELhvpGCoST0+xXDhA3Q5QNwgsYe1OohTSoY\n",
              "0Q/JoxGDaXr0N/DcJOmylYZuf0CnOV4D54aVkBrCcH8Vdf4Mgsnz3vDDHYcyKochr0btpwulFgSx\n",
              "SR27CwprHTk4GpbIA1/6W1tBBT9mnfWwIMGYC+BZ6IoYyWi7+90SFRhSlGiUvZnUuZRxan56nlEj\n",
              "I1wR4eZmCmOzvkSSJxffX1S9LYTFMjL3h7gXcD9PS7P5Zyfh3tyq7HuyQBy8zJOCxRBHiCJZrXDh\n",
              "qwAHA9P/CAf/xe88ysTD6YdoNaXXzDvuYf/1m9L3pI+PIY4j+NZv3IAevEuvRGMkorHNTrGS26Ak\n",
              "yP9XzsiB8gEqvUfvxqKhvqkhu9kH32y+P67szju3ZD9acAirf21fveT+MoCOqazsN29lCxXmoG24\n",
              "1eml12c6VEIDOIHfewkAI1Kc4UResefRpRXwKZ8IW5DmrcvwW7w/+DbCIBhEhWjit+9McxX0yvHz\n",
              "1aEmG7bXMf63f1akoVdgJNaWm0RvhqqWv8rdc36gt6ZR1oEI734Z/5TscgdlvnYzY+rZ1pGtbosR\n",
              "w8bbZpHIaCaQM5vJ3Wal3k7xWOyjoS4/iaXR9HauyKqp/oyRJAUThGeDkZiknDm5+fHmaas4QDh6\n",
              "1ts/3h7mvVzJKT6du2oQKVJarW4r8g+DNPJF5qrD4R84D5hcHklhmRaGYR4pHDnNWab/QglQZAnw\n",
              "43D1Czqfly/jBhb/gJfjXLHio3KMdTu2vVxxCpa9ZBed4ow2kTP7N0RdIvQyJU0TqjcZZ10QciQB\n",
              "q8m5AaNYggP0wAeX9vJ0h58C7t3VDVfurtNjnYgL9tB9YYe+ej+4mVL7rWoogbx7bUJlmXo6Q9qj\n",
              "jV9b1LzsnHYuMWCHlwGs5N/XmhsNQ8UexcAwKnhk5068xx2tKD058JOSkFtCh5DMSYwo1yZVBb09\n",
              "R+RKG9ptunDvVSkwjDCNWd788jRsuREsLfGXsZ9h2X5ZCIGZR/D7UH46+9sVkJ5fntcqwm7IlrES\n",
              "cIhJEi7bfkbuyMIw/4Ky3MnA7qxUHscl1Waul26SOZD5A5hi9qnsjkhXg4pSqIHrbZLd/l6nypr5\n",
              "JLYebqTeExSUWV353EGPz9bzWn0vOWwK51KYIf+iAVzppMl7r7y5kL8SUA1cg1aOVjB0733YUV7v\n",
              "Ryrktdt6Xg55/aWczKc6zqeVtXOn2fzjTVyE4wGSt1w/tYiNtXkfdqFfeuDdSRsQEicUpAjGlRLE\n",
              "zIEntOIfbJn0OYYarDW/59lpPnYeKbNxAlBVsLmDxSHk1Oyos1RnnkcsM8oFaAWfvknT1XoVZX5x\n",
              "7ClE3e09c8/QP1LBbPlY6FHRBsmO83IW8JIq2RLc19403s5bnKeN7O3ZRDmsY0Xg7f9N5ssJVfWK\n",
              "JFTGhh5pM1d23pjnOvP8EePINqx+cXYAMl2qBptSecRVrLWDgDDkBZkKtn2QRCCey4w5kmsdbjX9\n",
              "atzvEBBYO3gvdlyaeI8XF9IU6YfExIwYMa9nO73DiMU1JUheNW2MvTzPaCEmpVz2niqiQjaX/J6V\n",
              "XZMZZ/Z+PSxjObeevQFESbMpLWTQdSWVbabEs7mGBFClD3YRj1Ux2R5JwxrNQXlXtcZuoZ894PyF\n",
              "fhEHNhlP3PqP6cLas6ue/JbdLgrwjrUnEqXXuHQcteyyVLOaDo5nJGMtV+ov9V1D/g+VF0LvS+Rz\n",
              "cWY7sStO5QHt+V3Mw7iuTXFPG8T0td0thAz+1oY6+rWVzhClWhQPM0T6WYjGyenEZOwcPEeu9A/7\n",
              "93zTswpGjzE4EljsOc5aqPg9QpSbh0TemMpAGA5uNRkkzhQJfRDHUzLElbZCJTt4bAOGpJAg55MV\n",
              "VcZ1/oR8PdtYZPs4HEKfKFl3CUnF+Asf/LReVtI9azefj2WyM3YTtC9ZwGCkQ1dnawl0R7cnTNdE\n",
              "HMzpRNl/7Y/1Ah2p03EEJOmbfN4PO2ZClkZMvVdZddYuL8s8mS5ZA2duZEbXA4vpXVJnO8sUhed1\n",
              "Ps+NJuoH621tvgjyjOuP3RVTkylZO2dFS7P5kBlN94Obwd/o9WMgyv6xUrY8Y9ZmZ+cjGf77V7lN\n",
              "weeRw0NG7Q4Njmz3cdf8lwNqX7tcvnwFri9N9/MHjRmhMKc0U6Ovsxv2yriwhYUTb0h3c6QfGkyh\n",
              "zp7QD2SDmc4HSWfna9aDoiqWiiMigHNlKKSgNqquV0SFblMow94FkpvFGeehN8HIrgXpJK5cr5jJ\n",
              "nOsQasPFEbvuEIzSW1p+2DTtqv1ioaMXJSN5yXfn+VB20OpK74y2JsTWmJ3DEeRgfVcUygOOoJpP\n",
              "M5pUteK8BLL2caCCI5VU48iVLcDbrSN4nV1/ZNV2F1Yl2M7OT/tVdaA0RSqytSSRlsUgOVxrEPfP\n",
              "Yj0YVyPix8MnLmMZtunCYS/oEY45RsVo6QV4yRdgqs1RvSf4QgybaOkeuaxDbze7QWcMGFr+wv0e\n",
              "u1fdcz9YkDENPT+XJlaHTANqKmQflcfFRkhbhwsyKoM+T5K6wcUGid++nsoYCYw0FdvYh2Bj/wyu\n",
              "nDfReb32PN/xP8qnq2grXvPh9xcWOSdc1lR8aZF0sfpFHGEilRWP15NLOI5kr1d4lQddmJKEDulS\n",
              "n1ok754MsE3qqKsQTEcx3RXiGVCT1XVYAmnSOakSN4w3nX2wV+OhqMtu2Rw/D6bTJ68G2PMUf9gF\n",
              "NIHFWrYBY+eVVon/ojhNvd4X4z4EGPsui/oMFD3BYWCwcQYRyyV6zEh4GB40ekKLndkWCm2R6yRU\n",
              "473fEk6kIKrnwezdJChFxZ84pd892wTw9WU5qycCsugABGSyLy+4EWgtqKPsb9TpOb+0PG9YMQWp\n",
              "efGlG7drrsZfJ3Or1OqNj3Qn4tE5puoJn4UntW/etCxVae0xU45HV/BZ/JbyM3rdp9ViyzLm+Bg9\n",
              "XO1m4ogXqZRt6OLoFiL/xya9KmACIAhFdbsjwtJfDbr7KjdGbGlCMleOXeeDStUGEkHkC+lClhvP\n",
              "qXSqN3rLrRZ0JRJNK++OAOCIirjoijFKHzP0nxc2bf8yVfeU68spiWCJZpMxDeeqyu4bsm5BtULE\n",
              "hgDUw15YJ4oWPJpoLuWGzHoz2cPgxugTkyhpOv4kAoHrM/2swlWfZlp1mGb7TrxmDM/gVwl44N0m\n",
              "SSb0IBeVv0Ql62Hp9IDL5fxwJLq8q4r0AeP1fZVCmrxxKZ++RxiLpN2SI60l3HNTlC7SE7JMtrpe\n",
              "7R9r+lf1uFOrmb5NmN3GrC6iF4amO0xtLvq8qsO2HZCOFvY02j+L27DoXwcspeIgZr1IhUudnVmb\n",
              "TBfJjwJxcJwhz5TMySGbP+dk1rPEXjHEvCS7z4NRYbnC45gEFiCc8xYCkVnGL4sLxvP0t8S63orH\n",
              "7rwmtZRABI1BPM/DHAVgLRKVDvrurtfhAyabgERsRfrstsYYIbDTiZMBbhARlT+7DzvdoiDyrIfJ\n",
              "uEmQd/ytLxFZoPD2aP16T8pCd9dIdLw0sqj95b4o6ZGo38Z/axE8Hw9Jc8kjCP5X97M07lL9h4jA\n",
              "ImGH4VMnu/wlt29DOb+8I9V27Z8iVDMNt4yNP3KxUUsIcf2yfQbRei18Ny4PclzbcDOZV5mHGWVB\n",
              "Gji/LMzB55SbfNEfFxw3kCtoMk/nEva68gJi1UQD2ycytMkAt11Wj36dWeQMEn11IlG0ifodGN8H\n",
              "iKFE3UvMNESSjGkhiNC/+PwIYihJEvn6JVrye5JHqK7tobCaRvPsLZJC0Piv6MBJXU00gfIzCqDK\n",
              "8//D0kdGN6VLE0e0r3nLkAlqEqs6JNrVrNkU/2hEenWPGSqmDFDugUWoJHdSuWJ7mFwjuUAAEwOi\n",
              "PZZalkbDpaaVuJkvlwrvQ3Jr8G5DJp8ysF0ugYrMCyTfkLRhmM8nJ4sm/wM6qLiEw8BzqdD3nuCr\n",
              "/g6ihBs06iV/MkPL2RSTIWtPO2yNTe6aiivfGzD5JIHTWLc0p1lxOhAkabnU8csJql1T+thWA3aZ\n",
              "fdspqatB5U2OyU3WIJ3VZgK7U3JUImpK3IMLl2wgsu1f9FE2NqTNVQ/9edU9hYD/8hO9xNERTG3B\n",
              "RSS/LKZBGL0Gb28iTkTmIzUP7q8OiBIbHpKSNTnmkwuca416atqggqNIEpl5hNxN5DG9lnqEkbAv\n",
              "2Rw/61/uc1J/ODP7wn/ZXScYWpzN7AFQtsYwL/B46xYUY4zdfIjZG0KuIisH8HAtdmQooDR39xW+\n",
              "K75qnusDvrkBA3o4aMWa3DZU9XE2/KnJ6IEoMKod+lVsHje4ao45eZwVn/s5ohu0iv75qdXn/Y19\n",
              "tXkh1bpV62KLsJDyrVvutPyNHQeY4OhvLa7ocyvJS6HfAVSYQWse6TnRCjbtz6opSKc+TTqbxUct\n",
              "OdVhqtzLVeP98AoX7nGVqCq649A1ww5zXqboxuktS2+Tkj3KBBBoOQtfW7vQ7hFPDfz1ayAPykSJ\n",
              "GTGcU5OuqXpNPZx9DnDqLprCIt2QQ7bU2L5ZShg6N98kfKJ4v9MeAzlHhcqtFxWm51kS9J01b8OR\n",
              "FTj0YfvK6XI4Y+s29u2H0K4hRks5TKRJIDBl1QzztSWCAqjkhJl1bCfjAFi50O9A+PXfZ1N8j06Y\n",
              "e8WqmCP3bUAw/T6lpvekimHhvGSklskwf3QSMyEFlmBmFwqglVIJ3jPGw3xErakAqcpmItucPJIf\n",
              "2ImW7R/0ftMDAffXau+1QzO42ee1VnuaiYHEs9RMWN2UJNk4C85IlETyVs/dUmvt5wCYoYtWNiya\n",
              "hDeyFvnWLnF2fe7fOmxUPa/Pg/E5lLcafU5n8sEJEqE3S/W53a75mVGfw27TdpKaHiAdUAAmFc85\n",
              "gp6ZJyp0qy7edArkXdc38tWhAAALbgGepmpDfwAZIm16C4ABzpg9iGzHdw1TvKJFp7zGyu4dXrvR\n",
              "XWnMIkJkyWS1/WO69ZXxKL2gqsXsrIhNcaUqroZKJUfIGIlELCcBtLT5mMNfR0cHq51UkNZhLdCt\n",
              "hV7iIhRupdD1zr93NxaK0SH/AbJGXshkObS/lQR9KPPAcxky47csfEHByOMMGMrsdvgq+EESQX/l\n",
              "ic2cVAvhWx5xQe4VXdsodGPISAWLJ8q8ALudOpwebIWRhO22/YiTUhb7CRx3VAz2/3QpGZpfEdzT\n",
              "f/KC1JR+h7/GJay9YYq5CkWRlC3B1dOGAmPZun4OHpfdYtQEqgoKIyv0z7h2Z+n+5oWabcJKfbJ7\n",
              "3Cl+pnqb3N/sB+UlxWhDuvZLv0k0nCh6SGMN74SmqIT98ggNCrlZXMYCBZId7BvgcvAD31YSqc8A\n",
              "Gz8QqEc6nGapx8pQXfunTWMcB2PsaJLzIzjfqJn0nIyacY2dXVpTWn3ZChpcklVSDdwvECB9Y1dq\n",
              "bGt9S5+G72RZJRCBHaAbUZMIfeKpBUuyLV9tXeaVc+oA7+z/m3DYPHp3Hx3pLYV+1m3x22XO68Ec\n",
              "gBjn5WEbb+0w0+p6qHEjIDmFED3FyKAgFdsbaDfmohamrEbUqbWwn1m8+xT+/2dUg/0a5kXQoOJf\n",
              "CQT/z1kpAy2y902PAzxWp/7BvIR0Swh1wecgT3oH0za6J1xi/WzWs8c6e3mW3lNeFavK6Gdm14Ii\n",
              "bZJt592P4AFJke4wj/jvoZUtlC/wC35CbtpBNoJpHPAgeJn5WlyrFsnMcGO2wDgHH+LTPV9QonMw\n",
              "UQUo5N1HoVd6AhJo/10jwMCj1BtOq0Tp3jTO1LZWEbrJaeWYffjxO3gsoMq0O3oFcgEAveLElAWN\n",
              "Z7Gd28rgce6Kh43mnuy4c4uk2qLqE6dTQfS5bvuB2JXYvp4qDIZuqjQ73NKT+PVmVSi4skpCHkCi\n",
              "VwIwe5zlsjQ6tTT1gJySNhWP1ZUiiCpRJrhhdfpTXJLQoyzeoWl1dTjgb5mdT3C8hxXr95ZiADTo\n",
              "1bOGMsVCSq/AX4zQ0TFeBqi/cp4W3T07lTa8SyX7WbHnyk0q37uHS/3ZHQqvZYT7PtnmBcp33b+a\n",
              "jg7H3Rq2rR7CtnQoRBGMS+wu7wrcBJ0RCTO2YfFv4e9GNXs3ajLhKWyDgJHkrIv+bPzJfo45LdIs\n",
              "33jlCv3nDwHg/gnrz0R18/tnvvRFqordczclR7lrIL8HU4ijw8MHMDFrW8oZlmOeVMXpC7CKjqPe\n",
              "qHztPPmAW4pHYHvG6c1YCOXgH/2c1UJSmEAkQemDfpmA42uIWOfMusUGWaSWSKOUpUJQ3+vuVBOd\n",
              "YcHjIgRrmARWDBaBXIYeJ1hiJc6n5xscmBlE9rR1haW2R/YWJ0Od7Zu2AfbC1yGDsX4+zFAz0Whh\n",
              "bdgyZgEeb8W3qYxRUyY/npWvVbbs6z4CJVH9vWmmBu9kC1MifOzCmXEhPnv7X4WBnIXw0M8HuUgA\n",
              "YebKjpAFnn8oM7aoyfH9lXRab2c0FpLaAfpES2dyu4aKaelBKlFQSN7F6b48wXs0en1L1N+D8zdN\n",
              "3WIdoqyK332RXAT/c7GcAv29uT/UFWZgp4gSNfCM34vIJ8k7xRnZEaEqs+UdG8Vbj6HF7Rz/JpuC\n",
              "yJeIl+BlF0EKM+n2pSj0D6J/nvHwJKjej1s2N2Xxaq6PMYXr8Dun7afUzNvHvEtu1H2ZXxkroRNr\n",
              "oD2kGV557L9J+1BhmnIEDDton9MFj22YwYovaaW2vdYzcSDSpN5PsAawCLGUD1EksXfC26BYY+iG\n",
              "qKoAggjr8kSgiw3+F4vgEgPJJM8bOOv5u2mRyihzKs/UiDXDtE/h3eYzblt4OsgV8gQYd7eiietN\n",
              "bBaE5N6JPOZLnyNKt0Y1mJ72fZVpwQGAAQ11Aol3I0Tjgb/5DVg73zbFv9T8gf1OW19VoxdQo6Z8\n",
              "TVUXNw22BFly6ST/B8wpa3r8R33xoCFeRpRs9uJXpifpCRYBqzSBFQKO/YpDcMfnSTknjkRwRD/4\n",
              "kZ5xnYEXuITfbfMMvTLPi3zUjkTfb33lwXDcMbYF3PjSs8fOrDjtn4RlE95PsrOOGsSHgfQVF9e/\n",
              "57v0KxG36Ho1lIbT8SzwCNxCG4ckmX3am/PG/TOnscD2IVkKqZI+RYmqlSp1t6nEbnRWELuvBGb1\n",
              "OaaQOPfjN4C8JqrP/aq+/hlqV0lYcHWa1+Fu2mGaovRrr9N7yLT3+ptoJlM/DWVqU0UaVKRT6/yQ\n",
              "iu9advZqDqWYTEth5OedtxmrqHkwW4xEKa+OavHqTN5yQOhHfDBzuMbcPhFrxzmuDRqBQm8+aGlo\n",
              "DVTkqHsj91RYRLOrp/85VYj4W8Hq/A+bSYnb/pQplUwwckE4S/R1G8aJhBkZV4U+CFI92eO/+RBD\n",
              "tdXo+xWqm/fprInTHLLHoJlvMxR2gkj4Smr75Ee1l21HqRnP7LhqeyGw0jtR9Js+J1hie5vaM24G\n",
              "Oh5/z4Fo+VNkmmIKumDuRnebcyEMbJcR+K36+IT3ojfXXR8Cz7xceazLw0oaG9a3/HNquBd3PpBi\n",
              "jmzkwBMlwM4H4wq5JxKQUdmhLzYFlLJAVdXCoHFXlqnFadwjNiYEJ2ub0ckNyuciCGs6LmAZejOc\n",
              "yEixuflBSa74O5nXjSZyo9s5w5Fz3TbxOIsyNCiqB1rSAIiykLJ0akkES8/ME784bGYdl5+f02xd\n",
              "y5kq8J9YCKwPZ+kudFJ9Qjmlj5ak20gvV+hN+/fe7bzBxVvyiKSLAsf2Inc2CtI4FdHi5K0XM1Ov\n",
              "QH3Ug1jIqrGw1ycYMCQLWtOhjou5vXm2luN0rnUxVbVsKcvhiIUhddMEjWvZP9HwMXyKic0MGjBh\n",
              "yeXI6CtS/vXYuG7OpaI3QKIxX6nql+Dm8sWJsgFND/kLoU4UgvoEZqO6ovhG6LumdjzbRv3a2pzy\n",
              "8JWdVvQ+uoT1GuYoW9iu/gVTjJF5kOpwUJMjwHVCEG4b3KaAGKmKVCcdhj3ofmqvFGcU0frmojvD\n",
              "JD603u0gTemTzZfyob0NTQVKXASCkiVFTt8kal63q0eOigmLAMg5Y53aMC+MGh7TyF2QUM1p16GJ\n",
              "UgX0G4mKcB4vWgzJ5WH6F1lNh2psDiXfOkjxP/AvEljEAHi54Kw49QqJYvOj1F7EilkHsnbDIv+4\n",
              "BvFZAzap7ei7j0p+sPatwcIkrKfcON/ekms2/HadO88xG3WEUsOWZMGPyP6XPOtUXJVdNpszVkzt\n",
              "J9OKlIQqUDodJ4/VwOD2qdpLx9nbiwsJa24M5rrOQgKnqyhFljH8sTJ/9yp9eiQdsVo2vIwSk0xe\n",
              "DO7BNT+kiIvn/AIOrXETvjTruNcQTKHIVRiEvyOsjrF/oOB0RNBAZr6cei7lbiL18az8N9LTzGgu\n",
              "OK85c7uQ1NaZ331IzXyrucjbhcJ48FlCUo7cHDehMMGhXfSJYjXGwtWQEh/wI4M5G/tMnXW2tfRn\n",
              "9QnevFlovNx7QP1cdtHm0hSCzHyJHftyKvmE9Qkz5fEM5J0GL+yCUrv76cYPUw2x2DBNkL+q6kgW\n",
              "ZkzHrQky1nErlwfM5KtaOqAxG7fg45814/6UdR4dRwgFotP4f4v5NTXluDCzyf7cWQ76DLteMfny\n",
              "O6/N8irWkCgcNPla4tFzxYg24Pac3u5YxEiK+0oY7ySlt5pKwGTSbcTtICpn8nyqi7sr/17hpkG+\n",
              "VR72R7U+Wls5ZonCyBPaPc5d7VF8RmpKUsKhlCziflTwq4eSO4XSsnH/DkfENiqGEWe+g+hEoMQf\n",
              "Q/9nWYrscZ9RiVthf/elMd8jG64orJwytNB0tGLbhmTocagD4BPAHncacrjzcpMS3GnwfH7znDGP\n",
              "kQSGJjeqS/uwi1t4dDRvJCR2nHmhv2+80QlCZgxYupuLc8LlAcN8zOsAAAOGbW9vdgAAAGxtdmhk\n",
              "AAAAAAAAAAAAAAAAAAAD6AAAAyAAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAA\n",
              "AAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAArB0cmFrAAAAXHRr\n",
              "aGQAAAADAAAAAAAAAAAAAAABAAAAAAAAAyAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAA\n",
              "AAABAAAAAAAAAAAAAAAAAABAAAAAAoAAAAHgAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAAMg\n",
              "AAAIAAABAAAAAAIobWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAAAIABVxAAAAAAALWhkbHIA\n",
              "AAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAB021pbmYAAAAUdm1oZAAAAAEA\n",
              "AAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAZNzdGJsAAAAs3N0\n",
              "c2QAAAAAAAAAAQAAAKNhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAoAB4ABIAAAASAAAAAAA\n",
              "AAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMWF2Y0MBZAAW/+EAGGdk\n",
              "ABas2UCgPaEAAAMAAQAAAwAUDxYtlgEABmjr48siwAAAABx1dWlka2hA8l8kT8W6OaUbzwMj8wAA\n",
              "AAAAAAAYc3R0cwAAAAAAAAABAAAACAAABAAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAEhjdHRzAAAA\n",
              "AAAAAAcAAAABAAAIAAAAAAEAAAwAAAAAAQAABAAAAAABAAAMAAAAAAEAAAQAAAAAAQAAEAAAAAAC\n",
              "AAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAACAAAAAEAAAA0c3RzegAAAAAAAAAAAAAACAAAK8gA\n",
              "ABSFAAANqgAADHQAAAdmAAAMBwAADr4AAAtyAAAAFHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAA\n",
              "AFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0\n",
              "b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjI5LjEwMA==\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# convert to image from proceessed tensors\n",
        "clip = example[\"pixel_values_videos\"][0] * 255\n",
        "clip = clip.permute(0, 2, 3, 1).clamp(0, 255)\n",
        "\n",
        "# np array with shape (frames, height, width, channels)\n",
        "video = np.array(clip).astype(np.uint8)\n",
        "\n",
        "fig = plt.figure()\n",
        "im = plt.imshow(video[0,:,:,:])\n",
        "\n",
        "plt.close() # this is required to not display the generated image\n",
        "\n",
        "def init():\n",
        "    im.set_data(video[0,:,:,:])\n",
        "\n",
        "def animate(i):\n",
        "    im.set_data(video[i,:,:,:])\n",
        "    return im\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=video.shape[0],\n",
        "                               interval=100)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e0cd5d1-961e-431d-8dc3-f82e57702852",
      "metadata": {
        "id": "2e0cd5d1-961e-431d-8dc3-f82e57702852",
        "outputId": "726ed09b-77f3-4cea-b9aa-180924cd065e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s> USER:  <video> \\nProvide a detailed caption for this video. ASSISTANT: The video captures a sequence of moments within an indoor space designed for art activities, featuring a child engaged in painting or drawing at an easel. Wearing an orange knitted jumper adorned with decorative elements, the child seems deeply involved in their artistic process from the beginning to the end of the captured frames. An adult is present throughout, standing closely behind the child, offering guidance or supervision but without direct intervention, as indicated by the proximity of the adultâ€™s hand to the childâ€™s. The setting includes abundant art supplies and evidence of creative work, such as paint splatters and various artworks, which, along with the consistent lighting and ambiance, affirms the spaceâ€™s purpose for art and painting activities.\\n\\nThroughout the video, there is a clear focus on the childâ€™s interaction with the paper on the easel, indicating a progression in the painting activity. This progression is subtly marked by the childâ€™s changing posture and the positioning of their handsâ€”initially engaged in unspecified manipulations of the']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# and the caption associated with the video clip\n",
        "processor.batch_decode(example[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edeff3a9-0988-485c-b9a9-f74a890489dc",
      "metadata": {
        "id": "edeff3a9-0988-485c-b9a9-f74a890489dc"
      },
      "source": [
        "## Load model\n",
        "Next, we're going to load the LLaVa-NeXT-Video model from the hub. This is a model with about 7 billion trainable parameters (as it combines a LLaMa-7B language model with a relatively low-parameter vision encoder). Do note that we load a model here which already has undergone supervised fine-tuning (SFT) on VideoChat instruction dataset. We can benefit from the fine-tuning that the model already has undergone."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbc13ffb-4c61-48a3-9a8d-8d96d0247bfe",
      "metadata": {
        "id": "cbc13ffb-4c61-48a3-9a8d-8d96d0247bfe"
      },
      "source": [
        "## Full fine-tuning, LoRa and Q-LoRa\n",
        "As this model has 7 billion trainable parameters, that's going to have quite an impact on the amount of memory used. For reference, fine-tuning a model using the AdamW optimizer (which is often used to optimize neural networks) with mixed precision, you need about 18 times the amount of parameters in GB of GPU RAM. So in this case, we would need 18x7 billion bytes = 126 GB of GPU RAM if we want to update all the parameters of the model!! That's huge right? And for most people infeasible.\n",
        "\n",
        "Luckily, some clever people came up with the LoRa method (LoRa is short for low-rank adapation). It allows to just freeze the existing weights and only train a couple of adapter layers on top of the base model. Hugging Face offers the separate [PEFT library](https://huggingface.co/docs/peft/main/en/index) for easy use of LoRa, along with other Parameter-Efficient Fine-Tuning methods (that's where the name PEFT comes from).\n",
        "\n",
        "Moreover, one can not only freeze the existing base model but also quantize it (which means, shrinking down its size). A neural network's parameters are typically saved in either float32 (which means, 32 bits or 4 bytes are used to store each parameter value) or float16 (which means, 16 bits or half a byte - also called half precision). However, with some clever algorithms one can shrink each parameter to just 8 or 4 bits (half a byte!), without significant effect on final performance. Read all about it [here](https://huggingface.co/blog/4bit-transformers-bitsandbytes)\n",
        "\n",
        "This means that we're going to shrink the size of the base Idefics2-8b model considerably using 4-bit quantization, and then only train a couple of adapter layers on top using LoRa (in float16). This idea of combining LoRa with quantization is called Q-LoRa and is the most memory friendly version.\n",
        "\n",
        "Of course, if you have the memory available, feel free to use full fine-tuning or LoRa without quantization! In case of full fine-tuning, the code snippet below instantiates the model with Flash Attention which considerably speeds up computations.\n",
        "\n",
        "There exist many forms of quantization, here we leverage the BitsAndBytes integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "626e493e-504c-49e6-bcdc-adfff462e12b",
      "metadata": {
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "a97903f3bcaa41698b86bff92daf7576"
          ]
        },
        "id": "626e493e-504c-49e6-bcdc-adfff462e12b",
        "outputId": "0db81d35-d484-434c-c2cf-7270bca26188"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type llava_next to instantiate a model of type llava_next_video. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a97903f3bcaa41698b86bff92daf7576",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Load model\n",
        "# Three options for training, from the lowest precision training to the highest precision training:\n",
        "# QLoRA: model uses 4-bit quantization, which helps in reducing memory usage while maintaining performance.\n",
        "# Standard LoRA:  model is loaded with standard LoRA adaptations.\n",
        "# Full Fine-Tuning: no memory optimization are done. In that case Flash Attention is used to speed up training, if hardware supports it.\n",
        "\n",
        "if USE_QLORA or USE_LORA:\n",
        "    if USE_QLORA:\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "        )\n",
        "    model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        torch_dtype=torch.float16,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "else:\n",
        "    # for full fine-tuning, we can speed up the model using Flash Attention\n",
        "    # only available on certain devices, see https://github.com/Dao-AILab/flash-attention?tab=readme-ov-file#installation-and-features\n",
        "    model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        torch_dtype=torch.float16,\n",
        "        _attn_implementation=\"flash_attention_2\",\n",
        "        device_map=\"auto\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "605968ce-713a-4723-ae08-31e76dafc49a",
      "metadata": {
        "id": "605968ce-713a-4723-ae08-31e76dafc49a"
      },
      "source": [
        "## Apply PEFT\n",
        "After loading the base model, we're going to add LoRa adapter layers. We're going to only train these adapter layers (the base model is kept frozen).\n",
        "\n",
        "The difference here with other models are the layers at which we're going to add adapters (in PEFT this is called target_modules). This typically depends a bit on the model.\n",
        "\n",
        "We defined a function to find all linear layers in the model, excluding any layers related to multimodal projections and vision models. This function will help us identify which layers should have LoRA applied. We're going to add adapters to all linear layers of the model (nn.Linear), except for the ones present in the vision encoder and multimodal projector. This means that we're mostly going to adapt the language model part of Video-LLaVa for our use case.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45034f1e-d533-4b28-8c91-95c601fa2ba2",
      "metadata": {
        "id": "45034f1e-d533-4b28-8c91-95c601fa2ba2"
      },
      "outputs": [],
      "source": [
        "def find_all_linear_names(model):\n",
        "    cls = torch.nn.Linear\n",
        "    lora_module_names = set()\n",
        "    multimodal_keywords = ['multi_modal_projector', 'vision_model']\n",
        "    for name, module in model.named_modules():\n",
        "        if any(mm_keyword in name for mm_keyword in multimodal_keywords):\n",
        "            continue\n",
        "        if isinstance(module, cls):\n",
        "            names = name.split('.')\n",
        "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "\n",
        "    if 'lm_head' in lora_module_names: # needed for 16-bit\n",
        "        lora_module_names.remove('lm_head')\n",
        "    return list(lora_module_names)\n",
        "\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=8,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=find_all_linear_names(model),\n",
        "    init_lora_weights=\"gaussian\",\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64822f99-dd45-40d2-9d3d-cf75b2587f02",
      "metadata": {
        "id": "64822f99-dd45-40d2-9d3d-cf75b2587f02",
        "outputId": "fb378bf0-9108-4c90-bfef-e46f3d07d583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlavaNextVideoForConditionalGeneration(\n",
              "      (vision_tower): CLIPVisionModel(\n",
              "        (vision_model): CLIPVisionTransformer(\n",
              "          (embeddings): CLIPVisionEmbeddings(\n",
              "            (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
              "            (position_embedding): Embedding(577, 1024)\n",
              "          )\n",
              "          (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder): CLIPEncoder(\n",
              "            (layers): ModuleList(\n",
              "              (0-23): 24 x CLIPEncoderLayer(\n",
              "                (self_attn): CLIPAttention(\n",
              "                  (k_proj): lora.Linear4bit(\n",
              "                    (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (v_proj): lora.Linear4bit(\n",
              "                    (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (q_proj): lora.Linear4bit(\n",
              "                    (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "                )\n",
              "                (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "                (mlp): CLIPMLP(\n",
              "                  (activation_fn): QuickGELUActivation()\n",
              "                  (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "                  (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "                )\n",
              "                (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (multi_modal_projector): LlavaNextVideoMultiModalProjector(\n",
              "        (linear_1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELUActivation()\n",
              "        (linear_2): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
              "      )\n",
              "      (language_model): LlamaForCausalLM(\n",
              "        (model): LlamaModel(\n",
              "          (embed_tokens): Embedding(32064, 4096, padding_idx=0)\n",
              "          (layers): ModuleList(\n",
              "            (0-31): 32 x LlamaDecoderLayer(\n",
              "              (self_attn): LlamaSdpaAttention(\n",
              "                (q_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (rotary_emb): LlamaRotaryEmbedding()\n",
              "              )\n",
              "              (mlp): LlamaMLP(\n",
              "                (gate_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=11008, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=11008, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=11008, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (act_fn): SiLU()\n",
              "              )\n",
              "              (input_layernorm): LlamaRMSNorm()\n",
              "              (post_attention_layernorm): LlamaRMSNorm()\n",
              "            )\n",
              "          )\n",
              "          (norm): LlamaRMSNorm()\n",
              "        )\n",
              "        (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
              "      )\n",
              "      (vision_resampler): LlavaNextVideoPooler(\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5dd652-e76f-40fa-9c28-23f60adcb9a0",
      "metadata": {
        "id": "cc5dd652-e76f-40fa-9c28-23f60adcb9a0"
      },
      "source": [
        "## Define HF Trainer\n",
        "\n",
        "To streamline the training and evaluation of the LLaVa-NeXT-Video model, we use HF Trainer class, which abstracts away much of the boilerplate code and provides a structured framework for model training. In this section, we define the TrainingArguments and initiate the Trainer class, which will encapsulate the model, training loop, validation loop, and optimizer configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ccbd183-f15a-4f94-a526-9ceeec3f61e0",
      "metadata": {
        "id": "4ccbd183-f15a-4f94-a526-9ceeec3f61e0"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "\n",
        "    # args related to training\n",
        "    output_dir = OUTPUT_DIR,\n",
        "    eval_strategy = 'steps',\n",
        "    eval_steps=20,\n",
        "    per_device_train_batch_size = BATCH_SIZE,\n",
        "    per_device_eval_batch_size = BATCH_SIZE,\n",
        "    gradient_accumulation_steps = 8,\n",
        "    learning_rate = 2e-05,\n",
        "    max_steps = 100, # adjust this depending on your dataset size\n",
        "    lr_scheduler_type = 'cosine',\n",
        "    warmup_ratio = 0.1,\n",
        "\n",
        "    # args related to eval/save\n",
        "    logging_steps = 20,\n",
        "    save_strategy = 'steps',\n",
        "    save_steps=20,\n",
        "    save_total_limit = 1,\n",
        "    fp16 = True, # we have the model train and eval with fp16 precision\n",
        "    fp16_full_eval = True,\n",
        "    optim = 'adamw_bnb_8bit', # adam in lower-bits to save memory, consider changing to 'adamw_torch' if model is not converging\n",
        "    report_to = \"wandb\", # install wand to use this\n",
        "    hub_model_id = REPO_ID,\n",
        "    push_to_hub = True, # wel'll push the model to hub after each epoch\n",
        "\n",
        "    # model that was wrapped for QLORA training with peft will not have arguments listed in its signature\n",
        "    # so we need to pass lable names explicitly to calculate val loss\n",
        "    label_names=[\"labels\"],\n",
        "    dataloader_num_workers=4, # let's get more workers since iterating on video datasets might be slower in general\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1608aed8-d2f9-4ff3-ab88-c2d7664e9d48",
      "metadata": {
        "id": "1608aed8-d2f9-4ff3-ab88-c2d7664e9d48",
        "outputId": "8cec87ee-4110-4fb6-9adb-38afe0cdb121"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "CODECARBON : No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "CODECARBON : Failed to match CPU TDP constant. Falling back on a global constant.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    tokenizer = processor,\n",
        "    data_collator = LlavaNextVideoDataCollatorWithPadding(processor=processor),\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = test_dataset,\n",
        "    args=args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea64e3b8-bbf4-41ba-bad6-8afd1346f6eb",
      "metadata": {
        "scrolled": true,
        "id": "ea64e3b8-bbf4-41ba-bad6-8afd1346f6eb",
        "outputId": "fc872e12-094b-4d85-fd06-4078fb03f7a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 1:31:00, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.494000</td>\n",
              "      <td>1.473312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.457400</td>\n",
              "      <td>1.456758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.452000</td>\n",
              "      <td>1.448649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.447500</td>\n",
              "      <td>1.445561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.440500</td>\n",
              "      <td>1.445036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/raushan/env0/lib/python3.8/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=1.4583057975769043, metrics={'train_runtime': 5497.9532, 'train_samples_per_second': 0.582, 'train_steps_per_second': 0.018, 'total_flos': 3.416160365364019e+16, 'train_loss': 1.4583057975769043, 'epoch': 1.1220196353436185})"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "285bf5ed-8e17-43e3-a198-59e07ed6e3c1",
      "metadata": {
        "id": "285bf5ed-8e17-43e3-a198-59e07ed6e3c1",
        "outputId": "e1c7ea81-bd16-4279-88ca-05d6e1d107c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/RaushanTurganbay/LLaVa-NeXT-Video-demo/commit/b81b02b023fd4ba5f2392da889205b0d50e99c41', commit_message='Upload model', commit_description='', oid='b81b02b023fd4ba5f2392da889205b0d50e99c41', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.model.push_to_hub(REPO_ID) # let's push to hub the last ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "566e9061-486b-4a96-ba06-f0aa256e6625",
      "metadata": {
        "id": "566e9061-486b-4a96-ba06-f0aa256e6625"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b5bda0f9-3328-4dd1-80bc-ee54f3e032e1",
      "metadata": {
        "id": "b5bda0f9-3328-4dd1-80bc-ee54f3e032e1"
      },
      "source": [
        "## Inference with tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76dba71c-b540-4035-a386-5c09d8b74ecf",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d997ad73e8b4487f960e7ed1a438e722",
            "fa6c7a28b7a14799850a302a25397f49",
            "ae47cc26df1a4835adb5bde6af9a41f2"
          ]
        },
        "id": "76dba71c-b540-4035-a386-5c09d8b74ecf",
        "outputId": "d0c8cc83-b8ac-4e2b-ab88-e685fd8b589e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d997ad73e8b4487f960e7ed1a438e722",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/884 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type llava_next to instantiate a model of type llava_next_video. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa6c7a28b7a14799850a302a25397f49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae47cc26df1a4835adb5bde6af9a41f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/84.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "    REPO_ID,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a90dbe8b-296b-40f8-aa6e-7d9180f71434",
      "metadata": {
        "id": "a90dbe8b-296b-40f8-aa6e-7d9180f71434",
        "outputId": "7911d338-ce01-490d-a278-25f4e265a855"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAACV921kYXQAAAKvBgX//6vcRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MTUgbG9v\n",
              "a2FoZWFkX3RocmVhZHM9MiBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxh\n",
              "Y2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHly\n",
              "YW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3\n",
              "ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3JlZnJl\n",
              "c2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAg\n",
              "cXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAxvGWI\n",
              "hAAQ//73gb8yy18iuslx+ed9LKzPPOQ8cl2JrrjQAAADAAADAAA/yP425VR62BLgAAAE7ADZy//E\n",
              "Y/K4ACvgUNItcrm2vXdyPQ33PzKkTM7xM0rqAWnHDJhVFhbietpFdEks1PY568bNHEoLuh9lt7ty\n",
              "aQiWK80N46Y9cAmWgSM4PmP5W9/UH3J0ixVO/SrVz9gwBgDDgitOUNFIX9094CvQ8SsPBND6Z3e6\n",
              "F8l6cO/sl0tgR5IvQW1AzIYHPD+Jc955A6J96y38PLy5i2642qEmm5cCf4HpMJoFh3R/h0w+Gmf7\n",
              "spAuKgdvq6hwMVtgPXNVj/h2U79CioEJRoJdC4ZPZqmfehpftiTUaAbUNkHCRH3P7HnKaUR2NcGF\n",
              "Q3Ffkz4YuF7ckdmlC5siAKaJXIX1pLDkGrajp+EwzGuJ+siF2wejQ5Uz470p4GmToe3W3usPd6Jc\n",
              "UelS9TGObikefqxs7ZZ5n6g4KN8leIFM2UG4LZ60bGCZdZkZafE5APDKPTy53V1h4PImhI74W2tc\n",
              "/ojWTvy+buUVVJhfIMLPewTkDqca29/o9PhFLgoAOKQ0V/LuF/ZvfezmjU4q0To0wdzpOmtiRW21\n",
              "moQY1pTpOLqV7LELSVJ1gzSi59aqFfxXRZ79U/T7n9WTzNx1mPRIT3pC3eAqDoLgsqU5XjfLr/q/\n",
              "AeOBLkwFZccz16GTs8s3iNxs2EJjDy3IGKc86Hx9xSuVZa7fXM+/09gT3M3P8pXwV9nt8udQ6ubF\n",
              "XF1C5+CRVgNnfkm7Geqg+3C81L5y+C51iuVAum+sA835ccgE+KJ9EnKIVnTsA3hZa9ze6cfxe5kA\n",
              "C1k+Usppbmf22kL03XCXGWC2dJvGfL8crX98lPKbGzNIAGps6TY1Q3kiqc/MHi2DJFv88Uf8cNC1\n",
              "Tk9JfS9NaWd9PjfO+LGH/5K6eNYBJR23EZOoedESHMZynT0kkUtYAL4vBFcWAn1eT4AKJLZb/xPU\n",
              "KsmJWu5gTaRPyTqBVnva/KLSlu0mupi0YFHa50AdfQg4hQXlQt0tdKjyq1JecDEwiFhJ7QK4dm+8\n",
              "ZJIBt2bnTAKJo4NKAm4zr/5L3OUhuUtZWnT0xyINlmwjBsDpbHiQ9L++BQafP4WF1MpSp5l92fza\n",
              "4x5cPl+QS2jqysnwGNAkqk1EMLPKwuQpbZG9TPzE7FqORga1597ZDkoqdxroLBDCPJONZ0Q7moEY\n",
              "VOv4sOG3HfC4k+NB1iiA6yvndTkBDuXHW190QpF7Z10bXH8mbvjyLemfenfNksuAghWo5VyZXhW8\n",
              "rayqN3cRh2GYky8Vxjcpb2Va6VVH47lFpy5bUSr+edYBZiF22G0jNiBTlYKweQp04gZgeZVHbKiA\n",
              "lEQc95rsRpJa0pZuHSBcEaufk94mEowijvh0nSRWFfEDhaHi9zETUogbINTXRt8rj8ceu6yfuYyz\n",
              "5TWrx5SlPGmGmsWkfsBTgc1TnbqjHDdmfYxx8jvpVjSSKbfQzuAZJ9pybpKiGwjgug6yQfnOR1Ps\n",
              "MulAvR4jB7y4qxKYeocDHIMLSVfT5OYfCSaoPQrgspzQxTkj9VN3LSg1j5PhisUuR10TCBw2IzI4\n",
              "L0+vgwk0Bzg4H5MxYfj7bElSDRrqqEHBU3MvQ/Y8Rinou5TyeE6AyFjMpGEMOZQHWlKvsnrJLU15\n",
              "fhCV41G8XRIJX/hZuaHp5bG6EH2jsX56//KK89Np+fhJdlYACqo0Sc6HQCCxL6PtxtS12dsXBKBx\n",
              "TwGm0yDc40i/OxCBKtT9qRC0re2DhmNEY9Iw/qqZASMbtmgFYPKqU0ks5XBN1qP5aPVv3XQh0jJC\n",
              "hz9UlhXf3y3YgEMJL0cqNU8NwWRsaU/1dYtPfV8HQI4XK46krBFjaO+G1qfP69RHJk+xFP2aENkf\n",
              "k6nogCaG7AAEdpVDi3VpwCeYOuYkf94y6/Z/0BX8ktbDMAMuYCkie5dpNy8fOZO7JFHcm5XLwMhy\n",
              "rSB1M72qHVZp8hW83kSi/D4M1q1qn0bUesmowkyNXWbvQ+Ej7B8MMHl8LwefWIL9Y1JPWr6asBfv\n",
              "u7dwVhfBPY+gT59Sof82wCnfjTkDVDiv5LS3GEH1aStN+hIegpfP690n9qIw3i8XxF/hWwZ+5+XH\n",
              "jv+HAAu84gMmrPDigy7I58/7rQ+7/sizi8oJ36hSo8Jx9FvsAEUNVFnkm4ucBSKvBZaMqTlpIX08\n",
              "u/6TWeMvD1UP0vVh7fbxB9www7JNjSzGkDwd1dxRKRo1LU8DF95bQm/313tmI4XT7HKB8S2jWKMr\n",
              "BpyWBVQck0IH4vBWT8j2rj/s2Ap6zLF375Y2lNzORyEUW8uC/pFtfyxGx6AIlIvZa+c9zHovxyF2\n",
              "AOgxcQPsWhgOnV1OGJBHk81v54iTOiHnRKe5uhb2T5Vfq6sJQTIdaPMVnV14RyqPrcvH7rp3hDHR\n",
              "+MK93JXbMaGRR6FQ+UTrLU36Q4GSUSE99FBXyYX0fsvejxt2Swos5+Du+LP8Y0WmjyFXrHa8YD4i\n",
              "0i2eVTcyYw7u2tP0zDAiQSIshR/3y0u62XcGMAmgTGImi6GlEnTzdvUzQDake2QH7BODBNAUruyx\n",
              "K5hufSymJFy9Q3W95YOVLVtcw1QN2nLTiJOrbinyuATwJhwTqJ5XlAkmjV4bSlknOtGodMVNILMY\n",
              "9RN6ZEGJxE46v3sE77/EuAea8M+O2FTCTrDHpU/WFZSZaif5MTMc/jD69pPhrfXFkucseGMacfhu\n",
              "rQAyM2RJSMLIGUthVOrQ11wyYBpICym672TAGYceweohklBB/N9XSzBAwcWbbCsyF+7MvjbiMcv4\n",
              "gCIzj7UNESLWfpkQVd2z1JCbTSec3eHZsNuJkix9OvutVqtAnexJbCDGd9igojdLAj8vg9QkNOIu\n",
              "C98g6Qrm2CD/asePUBObVLgDxpqm+yvcjoPgokgKT68E+Yt9MpOlCaNyivpd+u7RHsMdwQ+qVHsw\n",
              "AIAhhYYAKbNrvbDOfh8KwNb29dMg2k9ACwDaYpZKXvY/KLGiuXwufAKJ70Nm57qUaTe/5o6Jz8QL\n",
              "16SvdmB2azULoR/HD5/5YgkElvTfivkn/O/nNZ9Kl/i7uakHRo+mVD4wV3hdkVMsXec8hPJpEKuK\n",
              "AYlPoZACJhWmLQba7X+B6GKTkiH8ayRFV9gmKwDV4DEkhhe5RdnRRwtlfxY6yeMIG92op/oIxYeP\n",
              "m6c3ELf91U0v6GbYvzyc+HQH80ds8iX1ohoBQMpsca9qliyq2l4hwehIBBeEijodyQT6Xc0HYjvX\n",
              "zd0Ch9D7yekGIP8qeTJVRGcGAgIw1Mo1FVP/pCXKEC+bnhcjm7SOLNplwN4jiiFwTV2gF6w59GLJ\n",
              "3UKW20z9wPVOPzDX53pAJ+Qj9zFKaHQDZ+wozQOQuHhUK2oIipyzXlHqdCEkVHVcJ5FWxdrSgknK\n",
              "3x06bAlqyZnAYYntyoMps69qurtEcXatBA9tngGbqzhH6317nKL190EilFthvBVPX1g/pjsNSBFt\n",
              "ocAf9Jb2HZpb6e2nG8pzUZbvEHcBrWGD55NU/bcdFC4KYVES+RC+PqS7o5qVHXSkqtz9EQBeahLQ\n",
              "nUB2v9vPkZCr8Ahi1ctt4yPp3cCvr4N+faqmSLXzIvoauUJzLW4PNlko8NNWTFp9w6nYPwQiChos\n",
              "ewZkD+tw/rJS2SxpT5gt+ZxBsSiDKm73Z71B2SlvfUiMJ35Wh8xJVFCSvhJ3YN/IVnIxtu7WmS7K\n",
              "LMAtUL+RlvDWsa0GKRbV9WRKP0vqJ438rwmyz8LBjtzupnBPGpnHfngKpjIJb2GyL0PNKJYyyzKv\n",
              "50kCPzpzLPuTSpDEZa//x8vaqVrAAdyMinZ6XcVA/kozmkw3KSv66zHtlPqnSce2qSGuUimk0q/Y\n",
              "mL9jtGhFj/zudoUfam3W1kiIGVafuSHCVE3VvAAACfyZDih/ZZYYMIA7ksAfGJZgcSHFWgs+nj+x\n",
              "ogZR3pKb3JVtuigDDrmPKuSCcrVHxgEytsH2FVYVyL6zS8+Bu2e7Q/yKgNl8s7YvFHtFF1m0lzZX\n",
              "0rps0xQdNDSQg5KVTfm+5wi7YCadGntjvcm7eezm/f/K8LERdVaddbYAIKUu7chFECBWqRAoDBvX\n",
              "4I8PexNJ/QkvlD+HctvRJZXua4zO69Yvd+bBP0njJdNSeGu9/8R7Rxnm5eSnVfvs+iOX9SQDMN/0\n",
              "kFGd7QmEFRIRdSeb/ygfCfb0dC9zxhiHgfsa6spX5kPZnZSTY04b/4ji54w/CFhF9ZzL8jiagSJS\n",
              "btpBZypsQqSFrQAGmNW2C3e+1yNW7rnY5tAAMoe2/XRNbYpjr+XQrG9SpuNJXpjras9XN99OtHPM\n",
              "ySBSglfx2N/U9DPvXJIhz2ktLoAjsxajTEqiQjW86WCoGsF/UD6doOr7UWqbfMydz6kjAVr2PzOP\n",
              "Y2+zwr4m2JDDJA/eA/XwJ8Zov+C1Y7hLMratne6L+9PA9mVqO78Nogrdu7L7PcjU94qw2hz587wP\n",
              "1cL6DdZHj3sXzoMCpXxWFuhBtfl+x6LLyQqh8VBPT3duDto4CJuzuSB/PrQ6SuyB4B7o5pjYStjO\n",
              "nkUdQjdIfj+Uf2jMi4+QVUY+ZxHxLU5cmYd/CqPGxBXTT56pmJqbzC+QoZI+CHfRmP/bLyfqCEaa\n",
              "pmlmUB1C+EjFiqHIUsrYAew5zr2DntnEo+K8h7PVSxIbGl9x7Nb/t4biFLZa0TtP+gkKiWi4mdMx\n",
              "vWboDmUC6Yo4o94AT4hf8oOrtCfImAGackGaxZVFha5KFhefmGxEJmjNaSX0NSoSBJWcB3DMrglm\n",
              "a6IeLyvYQiQW7hrPjQNxMs+0fFyKF/mIf9esffIBQYC2/u50uWDFPdLhoaRLzbzN+QYFO1b1lW2b\n",
              "AhK3hfNgfjmDlhCg52lNQCI2lDoPfDwayew6irPmLezr42FwWpR42gpjoO2KJ2AF2nNSLapHy517\n",
              "fE1OGyzVHp/FLg5Q6uPX2U06tgzKTapLzn4zStZI0Hvc/aeZqqvzVRt/5MXDxazWMA9TwFgIfjRo\n",
              "6xHTghygxus34dobpaXS3KE2hqXrFZQv8rdwrCKduF7mzjXCqCsOK8eCd9qegNa5WxMgPs4o0niK\n",
              "U48l/jzbP+pG+NoQXS7pz6OZpE0PHw0gAAc8x76LfLAqWCVw+FhcOHnby8OEOqQf0WTTUe69N4sW\n",
              "AEbm+U9VsyaDIdqnJpjilnNLN2oyiGAg1TPu4rmcexgGsAAew9emkanwvVedIiOy2jo7DrL9RsDm\n",
              "RnF+tCbjh7uF6EpGtNE2akhKIMr3bgjqsVyd3TF1g/CjPA/FKsXifOwJrucFXfFUeDYeMsPJ+v45\n",
              "8zPSOwYpnegmOYBIHYOkT1jOA/ym+LqSWTIlJSMh1G7IE9cTRYuTGNVobw+n3ze+lL5uvedIgc33\n",
              "Ebc6797HF9GLkJ2jdvNheI3x6ZprPL2x/zJiVbpcAmgJoUibe0n2ttDZU3Mz8EcT/4VlMkY/12t4\n",
              "LIQLEtzS1fyACBqQ1qLyrmRQGm65pfqg5UO4U8HDu4soUEOdwoiosji+YsorsLvJB3KUvp65I70a\n",
              "Mo5+f+W2Jxulc3IzSE3PtqZg2LONs+/Y6H//MsRh/INX2I53oL5w0M1BcMai86BiUTb5AAAaP5qv\n",
              "JzjVbjfrCsRoDtrG/iyaWVhiWpBkmbkgMnB9N5mClh734hihc1XmKNMte2PxgVBLQK7Ub9oDQvoE\n",
              "GWmnKpjLAtR4NkiKPBejoQRHrR2O5bC+hmuxxtoyBI4wOmslHue0lXQXFpreZQBMC8S3TiZMEpmC\n",
              "kk4/eCQhRHsbuEbwdKbhmzqJ+EQy73Xb2YXhRCQCMgkMHzp1yxd89uCrbGuLg/nQPB1Enx3ktCWZ\n",
              "6UHxg7n+UrVqPkrOpvK2H7stYzsw+eHo2LsaqKLRUtxrKfsHNiNQiNzOviSPJgDwhRmEV0aVCrra\n",
              "nDayQxzN3HRh6oBxTyY5zL5YF2+6TbY3BpW6FFh4+VaUBwt5EVXy6PImJie6TNWPwrmsaTbfqe2e\n",
              "RlMmSBwqTwDT3aiJzTFRgjOap4SO89/Zhf6XaowXJBhJ8PrW1GM2+p5uWaeDj6u1sM2k5+JpGPi5\n",
              "YfgmD9ITu5x0thtD9FIY3S2e/O9IhLo8qZ1cPu5wUoIzLHmpJGNa+3XmEtfjhZVhZvbF+E3GtWlo\n",
              "tNGJfQLs7ARuYnmPiVr9lzBkIJRVm3J/4k1w2Tqi9Il0dTMSivtWbYouvOsxSKQjFpt7yvYhouhT\n",
              "TJW0754/9ZzCfTarDnxUIPzI5eYJsLjnnfdVdy9nKwDYk7dj5UI593r85Rm+pBc9u3VXaBqIzLtS\n",
              "wfHMpsSOqAgkSwjOekJFj5Gl5p5omlYG54H17F4esCRgVoQWMtbxY6dtO2fATgzUnNFZXg/TOebR\n",
              "ohYed9yDvoMBg2zqkAZCjZxdkf5sbYdn77qjSe4lHhT50LXvI1Tm00Qag6Nqv4vJneAB4pFpw13v\n",
              "P4zxZrOLmhhTFOo/DwlXH8TvRdwG5Gzwv3pdBOgM0MMNgSMjUEhvw0+ybFc9ixESqGZAFLAVfLTa\n",
              "QL25PXmsUByH+cmgm5zBA/RbQbDrXadEM74143Rt7ioYfXV716OLI9h2TCmFMfl3l5xTLoHfJFqM\n",
              "wzKM/Q62TXqkHz7O1dKiQA0a0iD4Jog2YbZ5psLIEEa0OGCl0PVaz146xN1eiDCaYzeCrWG4y3JI\n",
              "2vVj+fT+LIzS4oIekpMYsElmDylgeHd4ZdP4IeOggffeI7GlG/UC62LLbVH7GQdiKCvMCD6SIWiV\n",
              "5iX1r7Gcc5pjIuVlR/vn9FkQR/INumwfWyihCFD+dSk5RY+948ocC/Bbq0tSV3jR0oOoqijrg3Dx\n",
              "SMmxpQtoTWlpBRupXS0qJ+1Ih4Cw305P8T0qzzr4+chpQ2w96McIRC+KAUnxV1o6LcF8ne7aXrHf\n",
              "JLDg9RTvyyG+yWhsqN68QX5wQ4GFea0dPpZbN8l90LuGSA2cOoyAq9Wu8YLhA1R+5MEMr9riSSZR\n",
              "dj8fkhuBL/STHAnMoxpFxl6hVSMeEA0Q3F+DkNSqK51IFXGP/fuOqXekMRHYtQuwMcRnO+J+0SyM\n",
              "gzoV+HsrRODCcDIMKOCBPKZr3o+jJiU8BCHraSuRzPIPzsOavIR9UKzhFgKTt6rl8IQVZ+i0JMbw\n",
              "XRl6AiNIF0RG+I21h0HIjRHC1xjEDuArhwvDQXTGWXjon0U+hEMqLbnvzqw1UJomT62RO4oqWj8j\n",
              "/IGllphp5Sy2M5VvFYndJhVdLLeqLyYjLIFfTskIu2u9g3zdaXpvJRI5tkmckaxXFSLoLgmH6iTP\n",
              "1HMxtPcLlqh78By5RiDE6ut/xttViSayjEQrebcTINJEnAODJDHw1Csn0Vipwxea/r98iAx2KPHv\n",
              "MsTw1Yz8Z+GO68aTl+M9qfytDv3KieV6kRt7oGQ/NazbsJMUz4ZgoRLG90vAw8WsYZEM2vhDvUKM\n",
              "c8Gh/XAorYOknoKuHFhf2iXsrjrVbcghUrCFP9JyOB5UG0hpkAWR3cJg9M824yDjP4AdftsYL48B\n",
              "SVA4AHEfubAZ4CtKr+oSvI/htdPDgZMKC6GCNjgvtOsQAqpNi2+FB6KQj0TJpH0q/KTN5dvNx65V\n",
              "RhNkVym8jgcKJDsFxlyXJO/NiJ2oFUTqB3L8XU/hHQ88UGEmYAyoUd7JqHYSIa3+hx8wdPCqQq7+\n",
              "n3szOul73197MUHPuykoxgBKVq/vpf4r5dN1hc75oMZ9mDatrZYIuC1aCXEORnpspdUIKu3f6+9o\n",
              "nAXcxcZWXdtYA55dacNtQQIirmCorP57hmc7gkjfVOgmlVVEQvxqa2F0SI2NSMol6IP5XuJjVsSY\n",
              "LITNBgp1xCKWYOCaNi7jDPgu/6I0g1Ltnc4C333LwTYG+eOXlAslNajw1aItNhHqQy3l8XAmDrGV\n",
              "ufD1GB0NHLs6243d4kaPV/hxXrWGJEeKLKTNyXtjRh3YqmtFtmKNGYshZxYbb1C/5CU7JgLb1s0z\n",
              "+8OFIB76OHvYHaY7qIXc31e4FgWZz7oQaEJP2cg9Mo4KPXYN1xA4864+BTjTn6KXDfZ86Bj+MEmU\n",
              "HOiIXADZIWkSG30A6U/jO0JGL0f56ApUNjWnENAxH4uDMBi3P6MgmjESStGQx0cmdbGRXQN0N0B2\n",
              "gD3XMv7Iu4fo2IkYNVTELsVdtkSRhd4LDwkN3HriGvYFEqeeLyqAzE67ICJTUc6CjSStudgUXB2F\n",
              "vkW3QHonAdJB+M1W88Bw7lwDHmJjL7cnN71A3ZSvyc/sn4p80AIxoT7I89Bx0dfQ7LyLmwCAKU2j\n",
              "fwOHihq/f/bmeSyhuQbSjdqwQY0JauQx3ZjJ8HTYZWVLwMCQeUKYIiGO9A76Vv4aFcLvHLKqtj0h\n",
              "D+cYoQLIxa8VUgOcfYbDR1rkasCykiWOSCL1yclVVwzfa/Thu+V3utavJtSrqoeFuwq5tquwlE8I\n",
              "tWY2SxCZB6xtyBVmgZqFRUbcP4nxJJQPxMEzF/Yw8AQtMLZsb8X+ztYyP+AxrgRMmD4emzYFJdvA\n",
              "vpOhCu+U3b0HrF/s8mtCLP3ucX2iqZmsAlptj30AelHAS56yMLpPUjdvBhGs5ryOWSom9J5imfOX\n",
              "doLKxtEeuMdNgi76pt+ZkqKcBChvcN6IJz8dac6atcGA4mjaYB8gG3cuK3YAAp+dGIvoaePSTk1g\n",
              "BTXp33DbCNCBXAcdroaGc8FSoGixOPwyW4ylu1pKzQRQw/TzEH7Uddl3I/ov+Jr/j1kMn69MKcFh\n",
              "+zfNcGHlQj/F5B9afzvK+1GQQAwvXaFqzTn61s+Pw5rze91QMsdaqSs+AwLCR9vM8Vw7PHnNqSud\n",
              "e4brVsTK7sBmY/jybQfNIb2bFOn65jNR+EPXyohxJik69mA4zKza/wRVRvIlwfa8uoUPH5NNbcEU\n",
              "kwlY9gayg3WtBWZtSvwoy0bcoSrikiaV+vUbjGR40f1nYUoYS3aVsuRxep2RiJORajJivrD735Z2\n",
              "xi2qEifkgTNpdyEQ1o6sSVzlxPukva8acicbrG6FuWWp+BakWUiNeX9dnPUYIS4AERm/QA8ffnRt\n",
              "v6ABq6boElnQx4D0BdKUY2nyW2wvgxK3S13APLct+o093l5x81MlhsfzMmH1ssDLhAGkEDnVp5TN\n",
              "vAK6fDFv5wvk+4fQ6E5WwvumZ0yRQbeD20MTsMIll/yeZb1/w4NMmsYtHKNqmnwuvCceVL2SBqL4\n",
              "Yjbhvhlb5TH+/ZfIXeyv8z0Y2mS4emae7bjEJ2pet49k58gPGeSBtWIZlS3ij+Kn2sjHezn4xOwW\n",
              "HR8SfZAX3EgLbZI3k9k60nf72pKGhFDTaxQg3Q5YLTlmW+U/of6j4KDnJk2erVVkqXyWqYz3U6PD\n",
              "0uwJcFC/MvgqMJiPFkKgh94sITt1GnoI/idymUrJnMdtd+1VDU4+11VIqjV0DDoiRviWOSoppBcY\n",
              "EJBb2yqiYcP5bkmezFfm1MLmw8J3BO704r1VH4jvzIYbcgMfuewT3I0Weu5Z/kAhqoHtCIVpLIMh\n",
              "5jwLQ+ziLHCZQVLbG7FdsppukEkiT80vUz/84eFk7JWslYAmqmnvQU0pruJNOghkKx2e3vjijSrS\n",
              "+bZ7P2xOjWujsD4DaZwqrlC3kDZhsYza+fhx/nHWbI2jasZOxia29ThH9X+uVYEbmuN28AoYRe2V\n",
              "BFo5BBCyUxiab/NOfU9PBE/dmRxRk7t5fPyP+uxII4ITiiKmtaBZvLjmdUgtt1PLFC/5I5Z0GkiO\n",
              "NhckygiULIdcyXGufXFNPBlILPWKJRa4QcpLzMxrvGydr4/gejcnprJiBPKY3qEsoWzQSg5htjnz\n",
              "DlvHR/s7Vq+B2SZnJAnB2sriuFl/apcgWEK0/CuVeKTMgfEnkLalIe2I/KI6IBbtFWACsaWCbRyO\n",
              "0yuVxvTWOvLZixSjxpBmY7vLX0I7KRuAetZ+bkdONgS/5CxeLaQh3XAx3+hq0IqNjAIXTLz8pbqg\n",
              "PKc18KvVwy/AMCR/O404w+rA/U4n1YJksHqvRXCxZG9KQUCPo4lJGDrG6nVVXomwCBqGyKlay0J9\n",
              "mfQNaPapzEawqVq8m9Pudc+WMDdzRstLNYw1jB7O7yyW2Izmh1wHrc0HxZZdoVditzLEq7qW8gx6\n",
              "XQIawfnyeI87VtpUrCDkdEpUjnDelVr0L2niUhIEC1bgyTOFA4n+07wOPYdatVOtg7epKt8zSLWX\n",
              "eCAOA2HP80IrCGYZU8AG6yA4r0UlHrjjDLtSr6n48StUNygT6H0wZ4xVsrR+73ixhps9ZPBVBeTx\n",
              "BgiweNhoB1FYN4M1UCtExT1BhunlCLcr4wXHZNx+9Cl3HZzoNHy1v+V6vfsUosTmjaPkYT7drp8H\n",
              "FR6q41bJsCgKmnZiXw5qsWCd8QUbGRpiTrssus4MAFLcNJBlh6qI75ZErMUZoHsR9exnufBcNkMX\n",
              "K7KSpq3NY/A/3Qgg4hQSjSogaDXqcRayvCQ9t1nOEgnUxaoUVKJKjcCj6b4XcZAr6k/v2hVqWaXC\n",
              "s0RZI6HML+x+2QgGJrES+lzlb6b6y1snwqHnkNyg2oO3PC9x0CHdvfqjGRq/6gNs2C4+5yw5I6fg\n",
              "dSpXx1ksUvuyMMRztTTm/qTTCMrtljv9DSYI9mt7bheAcqH5j3cFUJS5fWXd/sqmzflafYzIREEB\n",
              "fE3RnfcM7K5SGmsY8ZEorUBPLgCMWyIUnihPr/cxNnNNqWAFZPGMj9hsSvp1LejOpEOeOAhKbWP2\n",
              "8joRZTQ93z0XttSPAc7KiIyVQir6Oy4fByym60HPwGKpUxF2r3BNdNpuyLgAKXvNNS3PnK04yLWw\n",
              "zaipauKqhaioF0e5/Ple8hc1mmp2Cc9qci59glg3pBbG8gapYeDi/6UHWY6ek3oRzuhCPjYrDDAo\n",
              "Gop4JpJavBaAKLpk8rN+CDGC903eT9ZwbX5NXNZVAEI68LxzvlFG00/kn4DFOd3Tl7/B598lzFz7\n",
              "WVnmRUvMS6qM/ZvnljkuIiFYlA4poR5qIrr62X99clT+2DRkqrrFeGOWc/WK8p4RnXzxCpI+dGpG\n",
              "QiybPtH4J3wHmpuaxphF6HFzlC8Eo1gJWQjbeYxi+vQfr4E9pbk+MQIVvhlj1hRF6QYKaO/6+J3g\n",
              "gPs4TiYVFYTh31CprCX1Q1LGGgvyKsz0EjsfEgObKSkF+0uTDZ2vZaALzKtXefYLuGFoDnzd0Zr7\n",
              "qsRPPlzPfJIlxEXs4DgGY2dlb+lJRg7uehLrQa3xTfOTkfSAWBpEa+gXz6UTniRy3j6s4PJmU3p+\n",
              "d2wtrPDunhR/eWtcxv+sYF1gmzEA5xsNRkPPyxA4f11czwvUNsG3uRcjDfoBSOJsU9yZK6gRRhVo\n",
              "35BnJIOosBvV/vQ7AxrZZ1BgEeDVU7p0t+hNQRD37kgg46u6AgBKMvtSVhK1dnQvPkl7wNBU7fG8\n",
              "FBIsy4X/KV6vAIv84sj/p3gNDYKE0g6NBFJShA2ZOpfcxh4YdYm+48p3pYUr3VaWzjQr5L//dn+x\n",
              "8/ARudOC6NLN2OM878nvQ/W2MTwKlvERKhhsoYO6G+cWuAOOZXXs27CKNPvl0hAoWIXzZlPyHftD\n",
              "Ylh8B2WrL/HcVA3ZJbpy6PcgPJVdSDWfbjng3zdtxxD+K/TQOqz3mefcoNst78E5SoG01PkhMhQj\n",
              "Hn7pfn1+Oc9QhvUYdZsOXT7bozeJOf2AYiEZXY5IAgncPMV1mjxKALAYUAN+sVR3tFlmiLsjNRwF\n",
              "0lUmytX3IVjDyvKVR0wPARQh7ZRvwp/ehQxZYBdG0goFi3+KljsddEO0r2w8SV341Cgt/BmJgvkq\n",
              "zvWvn0JypGCXRqyNOXtsbhOwtWf7GXxBiFBT8M1yFKUFUU4n14xaKuPOIxNrGtRykqhlgVEKBEf7\n",
              "GerbB4I/vdBZ94TsKUgpxN+0bIP5P74Hhxc3HSRCaJPPUhLihhV4N68F2ZcxYhuLfg7H7PpIVLwX\n",
              "Rx0u/AgeeD5A9LSDq1n/aTDD99Zyd9QF+XP3z4aAuNITcwP0+0ItJKGQTNFi5LRusmvTtPn1IEDj\n",
              "HKEiX4JZ8B6Wvtn2SdUC7whK0GRvtVl1vgu43Rlgsfb1mDox7FqEbBnoWV9kpcDuJKnVhRBOPy13\n",
              "vff76Prwm/XePpPq/mnuAtEyAWUgOwXk6716sNB1YI0WuCWoXUgQKbPPljDxeTMl/cXb7/lLhDex\n",
              "mfgvQaoGIFh9wT2ITzplLsbXsfo5891H3wV2IhOKfM7KSkGfgDJQSWQ24kDPSo0Sr+4TiVBnttgc\n",
              "VY91aA/HbpB3yoNrkgM0BPgCqbzFhF52E8rL1ZirKXiMw6Egwc9Mnf3FAYsHEQgGn1ap6X5TkXyC\n",
              "aMObx9ZwIY5RndGcs4+sW9oeynHrVUhP9XA/a2XI4ddeHzYEzsZI2X1TFA0XEY5AHRHXpTXmi4x3\n",
              "Z1LV1aucqf1OwqGcwJT0k9nXWijhqRaEyfUkwfyZxhtSuW6tv6MIB1JZXkug0eVfoLGWlNQqFye3\n",
              "AOq0qM/W8r9obdxfS+4iKpZP98U9OGzAlvlB3+dYVKyebyhiyaEbqsTQ22iS2/C5ajGREU8nqxc0\n",
              "OQASOdYSCj9CqRWMSmDA+JxuGVZjLKeXJg/W+ey1W/wU7LK1eyMdCs/xnYq+7/c2dbVY3Con6/5Q\n",
              "rwpSKNx2FthZ3uUOSe16hLS3caOnihY2NAUJjjqgnzOcBYMuB4CV5hHqZaXHhifTTIRkmlPwvK7P\n",
              "NrsZPdtbmOq8qCNqo0j95wGWszfCDkN1HE5qTen4NOJQfu7M4tYrAKylG0PJ3pVHHvmIVHLIwT9H\n",
              "3gk9nEBxS9YIcJqlnY+T1MshUHxZ+FBqWtCiaJDCVViQZdLGv1pAeeOPdr3e2C2UfcIB304SXdY+\n",
              "DVYaf/ocTrMSdsyMcdmZM9hzy5LaKMbxkNorXRK8wENyD4rJnV1ID3z/ePLuZ7HLFrTu71hx7QfJ\n",
              "Te2MZ3mFgxWJpsHJXJPrf8HdvmPSFUJEoA0qnFEs9k6cAJkTh4JGTijUHXja49dbMj0/hJtv/G8E\n",
              "LjnwunrbYgloHzN5kzLk3Sk9caX73Pi3dKSmIPHntTpI3FE4G4NWlJQxmcbxc/KL+dr+w9JTGtUp\n",
              "Hthuok7rPpmnuKTVEQRctHsjx11eLds8BLt5ZwRLayFriAQ9iemMzSuKRBX0z34lFRhypWRTsT6E\n",
              "md8HeXNFP5xk8pDhY5vDL2vCBgoyTWYtIrP8p6Ca5KRUacgzwjlYvX/RHBEg4zIIpuNyXfZYJiT0\n",
              "R4MrLPA0wS7ZuW5c2eHSc2Wp82BM1DQafdOn6n2AdIy6GZc+msA7LcF7sh0oK2pGPniVrFj608no\n",
              "dZyEgcvWbRNXmYtwFNp3Gt06ZaTOUIP21PitdLMcafWXwBlkUkumjKvHIK6LmEiVd+D7L24lPjjc\n",
              "WugDW56ynSuGjuQG8oorrpMMj6fGltSKWLfFI+ZWUcYI9fpiiR5kZH0WRTleDJgLyCIVs2GYI/g1\n",
              "hMFaZhKaVAic+k/UG3k9sRQqIAY1Sn0KNwiWgkh6w1vf7vgaZRJssuZVbaO/0Eyq2oadvMBr6Nug\n",
              "U2F/wjxz4M5EuXtIonAbAubem4lCLFSoda6o+3vKELLlbY64yZHAkRY8eE/eptV6l6oqfDtsc5dL\n",
              "iZ3AGG54RXJylWwFfbdWS1hhuM3a5PzNzlDgGLczoXNOl1/hHkowez5rcO3NM/rxYEhVTlBLclOA\n",
              "AAWGegA3wm7yYL5LlGwBi3ISdqPehn/G+jonBWV33+vIxFEo2NbCggy9x35NJPMb9oIxPusc3xos\n",
              "VAtj/5XSkx6EtTXpeNlFoelH7Y9k9Pj9UUh4fAFiZQ/M+en27vbYxLMQgv3kvmEioRQeV8tpcr8U\n",
              "5qYcuuV6OE/ufeWxTvlK/S5oQmTmyezJzD9rNdvWzsrVTYsDLycU5DRTGxrYWxk4dzIwui3xY5JU\n",
              "LtpVzPLGZhZwD6WDNGm3nWjBRsdOroXwhI8TAaU4BFJ2GPAOAVHbVtApqrT41TCMGX9TqQgX3Mg2\n",
              "CsT836QVQjBkZEuzpuOoMslDHPffjg7j189Vg36Vh3sRegCqSTHtozHoscgiXQ23rRXGNh1QMDCE\n",
              "IKiQC2+dxB6buKAaTSglfIN6S37bscfimAdO3KatTFz65EFS6KF/PXqm5DBsbBCjFqMbIS934Zo7\n",
              "SxYZsC8aBcSZIRw+EvGhlX/NseYhsjbBt0z8XCPTQ42Zo4wjQ9778vqzRymvhf487mSbS/0V4Ssu\n",
              "K9yfC50f6o2Yl0R3XfsKWgJI3EF0OQKnwKYHZcOCbafphEu8XhBf3s2jTS/ReEYccn2T174PI2b0\n",
              "RQl3AQ/cEguWGUuzKfNITCtXQUUW3U+0C9EhY76dhKeDmZmtOrocLCJWUonMI/vFaFchsFPgHjX3\n",
              "rfOPH8gOf/z3eVOP1W4F9FVV5ikiM3GwAELceBPKVewlesyXzwKjML754honQ03GhnvZAhyEZg8V\n",
              "XDWfzMzcdACztx7z2sVteKAnLKjNTH7tuG0uk4c/yZ7waAD2MquFZONXXMyNgAABDeW541v4LBE0\n",
              "JHCIadWpMv///zcA/WktuBoL9IEOZIPfLqgF0FD4n7c842nemX2g/feYRdzrKPQzaC1Dbz8QWHg/\n",
              "0bp9H3LURwSGzbUkQ10z4UAj6o6Z9hCFk4qChaQTOaXaerJOKxIl3cTfM7M96JeNu8IaEV3ISp9X\n",
              "CXvF48Lv+enJmQtZBf1I3eRaPujS23qt6M4enXWwQsXgdGdFJrxDVGPAJ9RokkK20e/P9aPT2M6U\n",
              "ZaoPhKi0q0tOx5IvYsAvIQCNAZ5Nbmy7Y4FPgCTBuEcgPgQpqskrIpSMNTD5pSQQP+bsHE2P2nGf\n",
              "iWu/SdkrG0bwCmnsQNqQgW5gDRQX1Iu+gT68oAVf5K7d8lB93dmnwWiw65UB4C4x1yGTQMIiNvp0\n",
              "v7mFc9S192eGnPAf9DvVMkCU1z4aRB95Jri3G9vhEgmWbTvC59DoPPVhn4aJyVSQgllhVG+sBPcP\n",
              "DWXYaO/BiXB5VLxfGfoHD7o7AEcQimZ5xXDTFiu0EdaCrgIQOoSDkD+vNQ5pBn5K/znPpE3xFuTT\n",
              "E4azwbCW5KINlt8RwxB7KwNTFD7RO+bft5ymSWtuZGiuaEUZUB49Dc9vTKxvPypnFum28QERL0tF\n",
              "2eZ/44lzci/TpMlMXPyr9/1GJZM1tZEkNoJx8+ETMAeMvre35iKr8c25JOrDi8gofKM8yh+itVWD\n",
              "RHYk8P/GcUO513+HeG6+r3haQmL3iHw7190HpQ/WO72uGXS9v3sv5JiJJ0Ml1O2zy3KhAAPk9QpL\n",
              "AERsWxrCUN/Kwu4PmICzHra8kneoViaZowa5JFQiTBa3sxG19T+ZE+L27CdSDbA0OpDUOtB0FXqo\n",
              "EBZA6UvEkmZgVDN3GSXGMA8j4R6M6qjQ1WUBDugSK4a4qONHKy0KBSTa+QBSWY0A9xBxQz/Keku4\n",
              "32rD4q06AhUx2BJg17UfnsiZ4/e2w72p/0MlZ6Oed4FkWzk4TMKrZFg31CSScoZw6gOGBcMb21qp\n",
              "eq/URBOyC/pPghPc4cKjjy00CEd7VI1YuIitNbk6vF3CdypVIs1LaBEy7zD/v36mn0qXWbVrDsLS\n",
              "Bidlj7FoK/oIyChdz6oNd2V/ry62k2Nk80j90TCDaBsOKXXjvEShBN2a9Jgs57Kw2UyIJ2dSPa3Y\n",
              "9GE26AP2Tfuk8ra8twqpzQpQsbraMTM61NHmNtYiEwwAOqapYwOnrK/LTZzLXyPm++GDJ4i9Dhq0\n",
              "qcIhdYFFdl51f0RGidA0oh07bzg1doNH9td1fIsSzv4Btp2CDgQYW2q/+w5AgiFwYwDU7lx7JgVR\n",
              "wQAtcjFY0JIF5/RXohaYlSlOxt3Eb8l7n8zm55twYOD/NKO+JAdSSj+aZ1unQD14RBxiaaZy2eHD\n",
              "Ic61g2a8WYgIzadbLzpkcBpdbMFIUJiaUZ3vBRY6chCxk7SEN13CBsNKLPQ8PUdED5Du6Z2RI0Gv\n",
              "i8eIFnxPitQC8ARoXKi04odDFjmIOpOBZSV2SNDZhGpGtFvXXwpLR9wn+9hCh0p92i3qcW9GszaS\n",
              "c4UHeVLrEWCWJZvWRbBa4qs3wTV3YXx9FA/yXlqo5rELkEZrkR+OUMqYd1hQpCmcNIeWxL23tMzO\n",
              "Pue0vF/bUsDDVhFsNsd+a6egESUIhEvTf8IY/8YyGxZa+37/c3x5wAametJUvea5b43ojolN1T7t\n",
              "LVatz+fWTMWLAXeNphBfpxORyqIPkSAYh+PzGkd8gcvrHB8cUO8Fq0aNcdXjRPOfjMycH+1WjBCG\n",
              "RyyUIHzcHl9dQ7O+OfYQdnIBc7ch7V2XrAXKFi2Idb28Qtuj8ZxCu3gvEJ5469KL4lVwMZpWFP4J\n",
              "aY24Dy2Q1w95CNvXWoYSfhY2b9SSHrZsxabybJnNWeSpYZdAMxGMRquPMtBgvPq4PGtKQmIhSN09\n",
              "ooba2A52RqYlHxZRaPyeGQkQ21jqcRk3UeUZtPLHwmLUOfEw/iCGz2o+oE62MQEldSTo4dwTAnj3\n",
              "acrZpxC70k/Rmo4crUST/ucGNL9Hhb5AGe2+jwP8ff9BRvahYt99KwukNT4oOu+VkA93sOqHHjSS\n",
              "PD0yRW8+eYCDtxBLMGA6wpvVbcA313cjYUNntWL5Vo0r/a8b0yCAJF9ISa+/0tOTfL++Z8dDUEDd\n",
              "UnwQJtyo1i/8fwwRQ6M6jnTAKTaHfAt7Mhd57W6imoULfaemrCMzOBkYRnGPTX2sE9bKCjQsXTt6\n",
              "c1kDoEbrDwAv5mFDJLxZMKtPbgYCeZcG5zZeQWZx2Ql581IpiUyJ97Ocd9F+pVXPXVk7nz0ytCmI\n",
              "xUvF0y8OVambFeCGvM+z3Yzrm6V2G1UZjmFcRqKBWHS5S7V/mrimA7fxZGBZEdc2ky5xuaiakT9C\n",
              "hsvFApg2Epp+HcZZ6BY+fa+ZOzsyJDL5hlPp8Vzwx3ULQEYd205oAWuU0FXrBpwBgyug/wWSAA5N\n",
              "liaqXq65dQno5AOHngAAAwACewAAF6pBmiNsQ//+qZYAG+6QCAkszZ51MYWSmVH1Z82w/StugO5M\n",
              "OMwZAK9dLe8tMC/ve26lIQ7ptpWP0cf7Gblfepv2FCab57sOA9vf1j0gAGE4p+laf0NQHR7hHMVu\n",
              "ettaA7J7UKph35lJc8XmQaAfSntHlmlnDi95vAOOMJPzZ1Xg6L9NJOIq1iWxCfm1EXHqB6kfqeuo\n",
              "Rkj50KxLdNS0+3VsBSR9yWG9y/ibCqFbniJPXf449Y9SBLmyL36ilwRwP15zgye+ffLYfwK9nsxu\n",
              "jRnnmfLaTp4MDQXriYiKzh3QwTN5LrtYaXtUiNDEQPEgWqHKFlQ5psiq+3G1KPRTBtMCYkT3A48+\n",
              "9U4mt73oZRs4HLrizKvCqgOorGj27KMZ1V3UNMnmb8HMs4WLstUTHLJlzoHBxYEQR9q2luL6FWnh\n",
              "LIzbqb1Jz7MtlkbOfSwKOjZHFELxeMWdr2RHGuGBhw5tmuMf4ex8RAyhDKEgf8O4usun1b0B3zNo\n",
              "3o74NJXNcXwrhVOCX7yXaEAEpxK3w6CntWSZZEIXMNwhoXh4aYjFcZagUSh/o6JMTmMhCrtFz6tM\n",
              "58cq7cDc2c5T3P/0mOAmGX44CWB/rMRBwioXgCJBqyQusXia1PJ/OwAsHxkklv5m2d2PNfn3gkv3\n",
              "PD25j5K0li7m84pbYe3/U6XcOhpAI1k41+iPSCv9MHLNrIYz6l2d/sH1Kg+LGZhbTR3w8xrp4kk4\n",
              "BbetKTG4Lfx0QoBcnJVgJdvri8/yeO2kgWap/MZ2VOfZ3sCroLArZWo7LkuSBaaSF/R2Oa27Cp4j\n",
              "8lVu+kdmtJUnQ1aBonFMPFS8FJBqbVEPNvxDG3UZ+BeYO4ycznnLYomFP1L9LhKUQHTfoKz5Yc/o\n",
              "hW9tzAP1Ubg4P+muKrhbbm2xQaq2envNzqDI50BZY1iu8NyQukX/zdoTDSXNomdGVPtcqkmwhEmu\n",
              "dCbCqtbnIms+qSJlaFIFsdxp88X7lvD8AB942XO0GLT9+Z0rY8ED8EY8A+SpWvLEB9p6kZcCsrXq\n",
              "0IkPfI+KALM7BDmue6zzTtpAXpdzHUjvQc4usKpf8gEBbquNgAwZ6bzGcxbum42YiJoR52xZxtIp\n",
              "ihjq48QbIsWWiwnXwiuTYztLIwYdK56tYmBzoxf/zU3Qrl+Jj9jDOXGdre+nvkehsM8uvI54pD/y\n",
              "oF/iWarD9JiCRAAgkQULXePXdZqW+/OTQuWSMJlWfRt/dt/9SQQVdS5fIfEQBRen5GoyL6thGF7O\n",
              "SSc5Zs7lPMMTJTo+3pUn7IxPxo7rNNMGsQPsgys0Cpow0a/QR3LA9rVIn3M+oI6bZN0HD01IE4Fj\n",
              "O5VdIVm0Zp96XYD7pdPS3ihRM37O/WUZ8UNPnsN1SJqr/hXorWrl3K+nmWHCpLVZBfk+x1RVvLRM\n",
              "ZeFPPNZPmV/hGvYsULwiLn/uwRucBE+GLkkLExNXvAMvHLLsJO71eSZ9Q1nOg/MujkkGsgY17PMI\n",
              "vIEU/cJHHFzSuBfuwfFkOOV1oBXl2/utwWcJDpHx5d2FRqsUL7JY/Gyy5Bfjv94bCPctQN5Vc6U5\n",
              "kEjkzwaXkY8+kUF3jhCezYnehyzOzMdKweFwHx+J2HqmBT4f231HLi4g2VHCWV9Z4+rS4LLJiry+\n",
              "yNHNDZV7gfWHwQeEWnv27LDJ73//GB8NPKQmRi9JhPOPEV0HZXDNKsha1OkZ6ZwLFfiFH9p3x9UT\n",
              "TPv9Myn/Z7grq5JyMsnVWzEamgYjC5C/BSR2C6QlxnrdAq0nAKpnpCS2GYoh5CutVYSx+daK/R94\n",
              "rvSazkqHS5Vyf46Ll7k/jGfDY5JtIHP/hbN2ksTfGOMkfF/QTOuLD4QS/3Scsa1+ZuVd2pER9Vua\n",
              "1sMIscnkXcmJk223GK5PhRzNggkz2R4h8Qgb6O0SYtb/NHBLCLfOw8qbIFuZNxqrYmvGoX6VsKSB\n",
              "6v83Dty+e6VleuhtlunDMrxLb4UUBeVxUN5FQU8ndl7qssEkuY5HP3fJ27HuSmpZeAhMz2T7yeiI\n",
              "cfT1kmDRQTpd8PQ/ybZSiaBw4vRoYC4cZQsClUcTBRxFlY7td1PFWWbnAv5meXIY/bnLTlegGPGQ\n",
              "wtMxJJBO0IbRmDOCEFzsb9198BcHsfS3bKpcCGMbDhWIcVszRqhbTlnlJhQaZKa2r+GHwDvLPpSi\n",
              "0h2YdtsZeoP9buHj4/+sQKWnUKuHSEGqsvSG17TSHti9o6Rj09WDoyC3GfBOEhGRhRmCK2/F/b50\n",
              "ZAPv66j0fAcaHIv4TX9598C93J2+tKjdWcRscvEv0fKgLKcEtI+JGSVr+byQFnp0KszdMWiffexz\n",
              "O9UkOavYvDZ0JMhCwQYK9Q0wfC6QMt/B8pi/GjMgkQbPjfQvZ2nuNM9wGXDGYyqHkE3kt2S7U3hg\n",
              "Xrsbjrhg0IJ/mgPtfMSOrkaBtlUoEUfs7z/lJHjabnkAZZQ0ae6qQNLb77h7EZI0f1+FKbspltHM\n",
              "GeuBtXI03y/dDBxa7tbb/0ZbSFq2Q145GQnV17ipsZuSILdHNgxwqwfEdNzxrIRcUqg/Ie4+DrId\n",
              "Kh1q/nmjpXHq3WfdEbOwBnLrc/69bFs7kfxiBWUsfb02jCCizpaBFefSAH241vb1Ru2mdptWolcC\n",
              "fTwmLUJPeV4bjT+uZmSs0A3Kmpvrj++WT0R6aJenNqZ+3TMYyrPMgAKXrT90BWT6mRwMaAqBBPJu\n",
              "rEhATTNqNy+a0yLqQZRDBrc83965L/OW2f3YR3MNUmSGSY/A8hxKgZIig4hmzGaKYCRRAbLIupFT\n",
              "vz4tirGjQVjUoEmG3Tox456u9tL3d3slJu/gLtMiup5JBpiIi8/kW1+ChmLyEEUNbaENqDmlEyjd\n",
              "hTQvXb0typybSYMq20CHO5OJ4Of9rZbnnfAK7Ts6B0ROf8pm5We58nl4cFJRD9YT4jpzC624cW5U\n",
              "XpYW/m8G8IDy9/n1+WFMcySvopH0UW4Z1jvvLjAENubJrsvDu3N0FKNMoGXI8598A2tW0l4Ukal+\n",
              "FWts6xEbRDIWTPuOXTG9CfeHLp+iSU6p+liZnMiDRSqrnkcpr+LnYGmJUKal6UgxDcKZHXOccps8\n",
              "duJXdb+8/crx0nwpWNIZ6VkQ6Qa7kmtp1E2xKoo8FcTI5SjN/TNq4WvouDDys1rK8RMhRgks9mi4\n",
              "RhJxgjtwnztZM3hUhpW/XX1wmFf3tRxl/LfZWz8rskz9LookEZbogDEksNTHK+wBXEnNL+n+yfLi\n",
              "yPreSkEv3hBVQkmiqOPfooHGJdyf31IhhPp2P3xxOlgnBkJDVMRI855KFZRrGWkdcq0JLx2DzPa1\n",
              "Ko9Ppfqc0j0Sr14WR/zHH7JdFlXjdqblgxMsBuZXX/aN5LKJ8uUvUvvjNEVOSPr8nuVTHNSR60jy\n",
              "1V23iYlFr+x+2zdRzMnW6GAd0ayVgO3Xp8khnKOsfba63hbUGDWEUkwrWCMOMiw3k4YmND/HSZ8w\n",
              "a6OBenyJA0huMxQdEuS6PUpXneDaSIHIsDv98dLXhHmatqRuaLWqzFLDSdqjUl3mfk3YCXUqfayh\n",
              "B2FvKpR3EFGCXzHdMtObOss3vUpP/2nSwiUIemKxHCx7E0VYVhGroHEFUVplMi9HUtEmt59HOfMW\n",
              "t4GmUpxKUF6YTNWdp9pkpmXUn2MgiQsqVf32SrZVLYt1xx8UA6+Ou1fVkjlTDOJNDBpwJk2kMLpN\n",
              "GGO2hV3ex3BjisgYyO8UezKKu43jOQB/Jli2RtFAAqXsuC395qFMs+vSIGOJct3fNRbU3WH55fmF\n",
              "QgSBZUud/yP+rQuRvX8zSqSomd0A1m1qlX1sSnjjeFgEpMAJTbipPm0lxmTagO6XYoUtdaQy/oio\n",
              "VkAH+1JrQqrOBvD7E+Xg389lxkBjbRwhdCrGPlc8Ve3rsbHD5Y0ZiYtkGDqfK2iY1bwxvqRKXINH\n",
              "RdiC3AyP15eRMMX4C+mXkZIZhxp/Ie4xgj5c7S0v2aGojxAp+nNYIzqZ2cwi3C0TNcDdmZYjW2CG\n",
              "0tlayf3H5/VvrbgTel+UVCFJlDSHa2y2XRkKl2DgY8JW1MeR28EEJGM3Pgbti4lQm7BL8hbX/9yC\n",
              "F44ABPUH827DlikBqlCuTwVPIimUMnq+4xzn4wUTBXsNx7sEjlXIS/8V7wi6iRkop4/ffKNbmsSz\n",
              "2CHB1oUj+eyV7IDyYcxZ+oePgUHVVaVhbjaGTiPaLc6Shrk7VUJfC3anCHic1FxQasi/y9fpPEiB\n",
              "9vR6N0ux/AHAfxNdHIQ7Bx6jGqyVHIqAQWSE0gCGyF8ZxqnDPp01x45gyzKWNvo6gtOqfWDDbNwO\n",
              "t3uP+GkSJOyhmVUYob10jBf7Z5bpbxHMW6BNgpPN13/MwBThMLcFMmxOj/cPRokifINoOGMV1pT8\n",
              "p3lVMJu/ZIVwKD0W/4SmaN0mv7ruTo6lN42bLwOx0ZxiSEH3d7ElGjN2MMnuNhxBo70tDfvNL8J7\n",
              "F3w/DCdza8REc4jacwNrX+3ns23o5VRTJ4Mg3l0fIvanUb23//5HQC6uec65wJd/AktCz9AvzaV9\n",
              "Mt1ZhxQTKskcjQc2xUQrLPZywzEzIvN5yjniXtLxExXCsPpNSRknwBYLQM75Ev9uer2FlZMfvwvc\n",
              "HqzYUN3nc82ugWTQcAQhg61vl53yaCUNuiF9go32NNdHgyYfivgK+dMIGvxH1HqwBdMSOt2dTdbe\n",
              "3Ed+vedFmHBRvbVi4sSdxFp1+ngrRBmIZNE11Skr3fHbVopdIXSnUUWTaRqvPw1xaKi+93Vwkko6\n",
              "RRAsjgyxD/52k7M2AanQHJLyoBOB+2de3ls6zaFAiUEbMzrILrLweGaNXQ+WZXukVT1MSlRB4MLC\n",
              "nFG7a37jofr3TVzR4EUt9MExt/yPvad6APBFrcfVqBJtHmPlSqoes42t+TN9/VL7Gmr8RcLwtlde\n",
              "pJoBF0wG8erHYWnCoRAkZMa6+Im1f/L5XPjGS5/9XgxYLiapMO+tEWJIu//hr6/SoWX92j8XQXNY\n",
              "BDvIat4EtiKE6IcazB0eACMswXfFQQ40adHqS8LFtUWl6VtzR1knJ/ayvWB0RpCjCkVD8TfY8LAK\n",
              "VQqNePp9x4w3LCqqbWLNAZo+Kk8ChmtYWgDykt30uNCHPW9QL0TKCB5ap4G05p78G86EBXvhiSdz\n",
              "xNqlYatpdO26guTYvc4ddA4s5K9injnOUzkNpfK7Eh/Vlt0apsNriyMQ5aEildFBjdQUQI+l39sy\n",
              "6FnxNZLgUeN752AeLHHV3DLSSN+WuCfJRLCOyuougl0tO80dUgspcrrSl9TNnTTyht1NsFp4aRvM\n",
              "/YXi9e935T9HFQ/bBO++lBiOvd6iP1xhh1Dn/RLOCDU8EETmeFH65w7Kd7LrHyToZdoFwpTCR+fU\n",
              "PcaZ3a++TIKYfrSj36Mt4f8bX5PWBFtvEJELlA8QfoLZ0Q/Nzn6ocHGCh4LVQDYGG3qrGBZk7pC6\n",
              "Gy+CFH73s5RCpyxVLm9PVeuW3F7caZ7b3pVFdRWivJXW4B4mL7OGAYfMES0wmviR2Rs2Wg6qt2Ba\n",
              "RjWIVg4DmnJuVfEqKbl3vTi2e/aXlUJyLfgyIMTZeibVimEUgeM/TWHJ09Vyb7oNT6ijw7bOtVnu\n",
              "W+u60SeJ3ISc2FFSqd5seLIIjTlTbOuxKpmHJEyItkM3ohX/h+zU37dOi3YDNGrTIA2/sbiHdwee\n",
              "oumGBqfFL2ah+OYNrldNledE7Em59cPQ1T3xAeNUYlKrz2mayzO/wX2AVjXLh+DjB13Zf5t5uKkp\n",
              "QSaEVrnGwDE4cc8KWxUI5SlFXfbwKTawLiMLqIhUr8iCGYblreT98s7GgB3fDInedTvzRIeqDmfh\n",
              "69ojK10k0SSxMS7w0s0zS9I2ksA5mqMeHhkaG9AMWNzfhW1xcTqR9rJWTK4/RRRXtprdsxogmM4X\n",
              "CLE/LTv768Km2+sXIqQ30BOIIF38sjwpvX26JvWyIgV2aNeAau6Jv7K2mvGvFFtu2qcm6BCEJEIk\n",
              "c7EHKn0lU4BJZ5fsDwFRx1CWdjNRdg1elus0duZRBx50RxBLXM83UTSJmN9m50OKhp/s2DJu7ueH\n",
              "zggNso0Ym07ufgMxfLStPhAiIMrLQoNfmlFoGlKJyUI4j1cVyawUTHvlEsE4hQ0Aqid1NT2IkHsJ\n",
              "sKvO/noJUW0/XpmF0fUnQ1M4V5VJCJnnw2T475AXvp1iPIZtFDjIqwsyHrw+eE/TXAub+xMIVzGe\n",
              "jr3I/mn9dsT5FQ+EYF4d30gkz0AZHSciqQRQs0BpJc5NKHc3Ak4Nhcnz8LJndLhgR6FeKr4IScHb\n",
              "HNIZJq9tP99HE51r8uixiKDmtpn0LaMYE8fYWuEoaDg0Wh/OLKIxLgZIXjAHuLqx5cDxLrrJp6QF\n",
              "jabYdNWi0LgqHIfDofvHdMAV8eGYNgXPMUoB9/SVfR7j1PVZe5VRT9FEFtgwmdLMBEWS1JbIfq44\n",
              "5PG5vAD/8kqd85adWsLF+hN0n/KtulW5VobrPF4O0fMRPxbA5a6jhs5suHy86/ovwsaW6U0pEF1D\n",
              "x7pdeR583TMUfuhUEhLSJfOi4yDv4O9E4NM5AecqbfWrHXGxt/xVEjjCa8qc0fooq7U0B82VHMpb\n",
              "9HE84299BUtqpL7QhUhP0poIRkKFBnfyawjOP9LI6ytTnug/pnghNADBW7azqr+hRNr6vTW6Q2VP\n",
              "0KNQNjFKM1kJpTt0JCoz/pxV04Pg2IGFMmkHdk94sEiQOgmjCvTT1K8ufzkU/V0aCZiSgCrTrZII\n",
              "CuvBzmBdF5WoAbLhLfdDH15HCC+fkKaKDNilQSdeIkx1KkQcIYtLAMqj91q5zsCQEtaWxeMpkwdv\n",
              "XFZz+sphlCxf+Dqvek/8utSgfJ9eRbQnWzkgM4alAvNZ3fojycq7lt7/m+5nyjpOIO+FNaMi7lod\n",
              "+VhKawk50wFR9Jkhe6l6CgFO+xKhYhH72yoDFpe0Hfx3kQFVcGl75Hno1SNfKSIX1SPe+eHceOT5\n",
              "4Hd8amNK8SQ49pUsqWuTW4ns18Tz750YQL8VVJve4xWvChJ4Z7SsYB16QAREzhE7nt0htaLNCabN\n",
              "3F4/FTUdt4P/o7DzBNUXa5eYarVW4Ts6MDDWBIxL1pb9Drsl8u46fMbX2l1/1BpayHFLUFs1+pQN\n",
              "oO8T7vg3ozMwelKVdksIL40fJWTE5igncj3cXHJp58zYq9ePizEvi9VQAAd5OxCtdCWgQszzRSEL\n",
              "0E2E46cY+8TlsdSl4LYPN/JcRIslm/GLIMtNrc5aQ1H5Ri5ytxjhhhCx92FdPe5M7XCIMIK0IQAR\n",
              "xwyDe9sg6mC+ZDbtBerXUNmdhZzRf03QHjLi43nJAzL/34xq3syLqp71NKYNb30vWvxcmHEzXwn4\n",
              "rwr4cY+FJcNZgWSdirhzyhPPUekthTRi7DE2ycrIKAM4FVnobtRpjvcCsRl69QcH1bKWXu1y/G5q\n",
              "z/t2kHH9Qntjj+8VgQqY41qVL2FPyB62ahQGcweqahRcAo5ExsGYbgsnjT/+ycYr84nPHmuCJgO9\n",
              "QD20iAyWDC0+7taH1IGu7joApDex+R9N93NzKRjv6tSsCemx7kgVtqD0YLSpJA35p8dzLVpecmR2\n",
              "1f0e4/2nz6J0bZw5pw3pJ/PWCCYQGhPJepelkexd+XgtXDz3zC43PPi3IqaKWD0dwm6mDgFAkWqW\n",
              "Zz5eU9mU+yRM6okyzYERrGBJgk2t9zEdI2ZFpr1HIu6EZpkwP/8ZHqYJbGiqldzGnfbw8kD/Th8b\n",
              "elwqaz/HjTLdX9JufVfLxsS8XiN37SEAFh3tAsSqMP5YJJHIGhwrDQYZm25m221GXM4NumAe5hNd\n",
              "8p+MZknD85XbPXVK1S7A5nfIWIDOCr2w7wK966VtVwYoJa+GLWIzclrVcSywno88f5ayfDVDnvdw\n",
              "3r3DfJg8pp2CZKgf7lxFiJJXEGnBKoD7FJCXzI0cq7etrQVOYJSQ6Rrle4/zcd/QAvU1aCFC1N7B\n",
              "JABqctlqbBV1XbGECMYYgcBO/4UY1En5ni6ASceSDnGIpW7SEATRwKPRoVf1Nl/Kyf/otK9d7Rjo\n",
              "dD6RI/4MXhtI5owEs0m1iDgrZt0pGrxgQXakh3cY8LA0sg8xK6oIAAALA0GeQXiG/wAT5NdQON34\n",
              "MCBto/2ouH39ABc+CL6Nz6auXxefM6wMNxljXyL9VOzWUhATRd+N4WqtD2zcJjbjWLEVoyl4whAf\n",
              "ojVJtZCb74Rwdwf74hAg46UZQlxJpYQzLhAu7hIvcwtYXXavlBsdT3bPhgDvvP72m1oqwxIsutZm\n",
              "OyeA0jgdDlY23JC3xV64lEJdCHNd3MPFVhrTYBOCKZw6T9OMTdwpRAR6p4H3lNIMdAUSu093Q18R\n",
              "xXK2K1goHWWLjx+0KNATGS06mcb2MBHEi/y4bmDYx/apkywXQORP7NbpKeE2TQMaeGwaorAlNhjy\n",
              "/r76Zuc9m1gwPwnaBH/CDcXiOZrHRGWgMTxMYS8nJlxugIjettiWxWP8W+Q4eBFmj5wEK65YfgGE\n",
              "8sqjRz+aZqvYpiyBjPIGcIoE9xRd0bUweEWvoNUoUyJ7u3JojuW8yot5TQn3b9ZzJBA1lhe29uwt\n",
              "4C1IC8uQbH2UiyIjbHF04//JI1OeQ9zMKKD4JBQqWh1GT4006zhe9bAyW6eS6M09DDM2nSbQMcY/\n",
              "oqgLuY9mVANHNHkRjkHw4vr3ehUE7jkuVt+G8MxkLEFVez7agw/NOiVh4hDkjYREguieDp9OcPCU\n",
              "Ktg8NPv2ZYRe6i5Zp4Vofzxqq0R+afN8yEWft0/y+LLkwfVQ+zA2w+aVik34FBImGFbEVJ4yqBSY\n",
              "lljSDxej5GurXTrJdBBC4nHRyPSe3ne914hIkuNzEH7KsP8OnppWUnrNA/ucSmqwKy77+IMQSbl7\n",
              "xm0upVqX1Y0EJ4dpMWXlbxdkiZBXEGkH97GoasC6ORhkk1pEK//sIU7h3fnM7MwF5q2kTmHGRzu8\n",
              "KygjmeSV22MH5ij/kzT/CyCXSvj1Uj26r8V0Nw1WVcR7xv5ULuVrH8jzWAk5lNc2nyCMqUzzbYl3\n",
              "S9uewm4D37nWovzIJSfEKFEIAOiWD27RUU+sRfy6ZynGWu27ob4TkvRt4m67iAZQ0RUOKAENGp6e\n",
              "vKHq3dOqBMCLdAzgqiG3UaNUC0qa2ASxRyA2Hln+SRwpuxJQKmP7oOW2fzFegJr3ykU51C66+wt3\n",
              "pfgpao+OXR+T/t/dm51MVruWCMFfbFMFfRd4RPlSF2GKMWW6DiutXGXOI7ernltmiybKyMp8jGtG\n",
              "hnyGBWk85m8EZhVTniP717QtUs1rtFbqnzuWaOsrlaM2/lcjCzYD6P3oEkuEl1ys0o6+vOQggJ4v\n",
              "q5h+UUl/qKPBlP5XdwJKX4FAekpkHKC73KyA0Kd3OKi1Bgd8MoOnFG7pbQPsaLt6x1sA8bujYHrk\n",
              "kie8B8I2lu+bOJH5EGqpp4DK1/xUhK++8iT/+/ffpHV8cwuwANi720fKneji2IqijlAEf3rWXgvf\n",
              "U6RQWPYuvVj85x3IvLnn0xt6Zn/Y0gAsXJ93kM/hmMkm5OBt7/uo4x7/FjLo+ljd7N6yYhvfL2ov\n",
              "jbaRrAncF1HxrF5NH9G1DGej0FDcZXyCsst3Fb/kyGaBW6Q9S5Ehs+Kd/XtjOvCa9Pi/Huukq6w5\n",
              "d4u1cKWawAAaO/aI3hcslmA3cmlVQKTNpVvwcI9PFIfY8tWIUPtt1bGMrmRrk/l9rw/4dIrY5V7f\n",
              "lziwWuQIfzianfFaf/I7Eqojft3onuRQo2SrOBp+TXvv2XHZRqJJU/vk+gRz1vZ+Nvy429myWWB3\n",
              "0v3ob/+9nKSIghrJ3DCc9kmmQDt2xOOETC5MnD5z4t9INA+c87/cBnqcE6MCLgcGUS7s8YPLRIv4\n",
              "Ca4NY97eAA09dSFUWjW+B6oTNhoNf/LXSlBzYt13WRCyaduBbe6sl8Y9Hw+1gRy84VBs3rhoMU/s\n",
              "BpF7NRSOfHqn/QfC3zZdFv0Y9NMYMm7J2H9fYnkKEnmDvFx1XrtzElBZuFAYn0rklczxEG+apGhd\n",
              "7ZawNzjb2ufidcvT/yBlcEsuRsn4n9eat9495EM3BAecOx9UC7EoJzP0JfjWrWadgJ4TO67YEVEj\n",
              "738+08qLo7JqpCmKJ/ONllB0V7v5Joi/BcvqZ2QBe/68+Tw1QLSROXUtdBTVlQsFfNXk/pDJbkPs\n",
              "qGMQgNtQZ6pQzBoWsp8piHdaITdJMnCkORpYmiS5MCMhsomuxpHbDjW59+B+AL8JiuTzr85MJ5Rk\n",
              "eEtz3rU+FTaVWl+Es4Bvk6LldXb5TZ3e+DzrObsPr6AWTKGzydM3c1g76dkrzF1EgcbsWBng7xMa\n",
              "s8opG7wCfrfoekZoi45jKjSzFlAgNQzsbcda2lP1oqnT4vUJNp/e6FDkGBG3x8Lf0PkkQujO79e+\n",
              "QR9ZZtC6XHDSZdxMgEau9JTRXEt+H/uoz6s2YI4qA7Df1r+wS8OL+5p3CgVxZXQ8Y8k+ueisoQrb\n",
              "jSR5VhRFgzSN49kqwOanvtnxvWYlod+xXM0meWBVfXIiCSKSkDjPO7s22/tm9nOgJHr/FR7qe+0D\n",
              "7j2pr9fs2g4Pdu5X65agu/zaLhxviWAullmrc8uZPp/K+K2g3K1o/JkChmzTL+b1OHVSXwYxoVGp\n",
              "1uN/iq7C98UnwZCrO8VGKRSZhiON22AgQQzRtY5/gX1zrade7HL6mKRz8R836YIIm+R0GhAWf48I\n",
              "mmFLfZSDYkl6HSIMWKUmFG4EjV+2Df1sWX+UxWQpiMYmYhgvRoG758xwcp7j3GulvBnK4MFf3LI8\n",
              "FZohFUwelKh93J1PLfUIBUkQMVGF7njEQaojuaSM/ID8iddssJjv20KJJIt7iOS1QcMT5hvSyTgA\n",
              "VaRS7tRs6zgwswQ+gv+WjVM+UTp8s67kByEvpRBleg7VFDS5b067it2xGKFnOz1Lcjy9E3bmV15v\n",
              "Vnlo2GbG0ZgbUGZatKKEQXOJDYOy82+iSYCAip25cApqz4zDhNBO29bYAhqAHLLu/AGGq6rX3MhT\n",
              "MFM3mCJxqjr4gIiFSd1lTmTm9zW9doYaHxgZ6uurrefackbdCm9WszGpt/dCDd8CoQvOLYmzZov5\n",
              "QkJ3T02y76lzB+kgK8+Py6Ffa5MlN+BkJ4551vO/mIcX3YGIpMuQFmv1kqWqj2tO3JLfme+yYQdy\n",
              "K/sQDrWdTO+Gse+jG0VpMLHRaM7klXE/2iI2Dl9eU0SMZO1MrpedgZRzKMlSA9ydeYvPoZ7RhwMf\n",
              "Fsvrpq0/fYtkOwSNnzNtkYNSLWnTk9F2GAAVNfO4p8EFORQ9U6Ddb2Fe0Rsk9kd5/hHqwJsA1J1Z\n",
              "FLF4pkoP4sy+nmk9Igb3eV7XCxeCjUT7AwYPklHIZvCo6jfru3BvrfEKJrYphS7DL3sG6CsVE3iw\n",
              "BxQzUK1TTJzUgz6W0EsDY8kOhd4+vpXm4iMqZRsu2GuCS70MpSPodcr+NlSQKLSnmDSGPRQfCx/H\n",
              "OPrlHHwThT2yuy0UMAq+QmNEfIsCDAD26M2+1f7c9NwRveCZiD8rlg3t7B9X9H4RJNwLPLy3MJik\n",
              "GneVDk5rwGVT9/e1RZXdiANkXqtuH/B1sirxd3PMYLxOOv5djy2xA124M7+qXuGryeEOPsU7Uv8y\n",
              "aJZUgA5srmCWD9zPQ+gwWU+CgCEKwNchqYbuzSHxVh0HNMPGDP6oxmYCPwkEEnpJkVW4w6oP9mPf\n",
              "vSuV8nECljCAB9zA1wjGQMiWq/nLJmNajzFg+U7w8+aP23jR05URez5mBdfY8OYLxsRG5sqDAagy\n",
              "ppsM8FaDjX2u209vg5f/Wv4lfS7f47+PkW+3C2VOEGW695OWRaVF4dzKcKq+XrdyE2lIfZvDZXu4\n",
              "X51Iea5aLa33D+OBAAAI4wGeYmpDfwATWAYR9IehosR94ANpQK3Yb1SZjF/D1exhQ4jFwZEIZsII\n",
              "LolmQA5IJk8npPMd6HPvfpRFAcJ42Y8bYzhLadxdfz3Ks547jKq/Cfe3gl846kdggz+Cf4mH3uWD\n",
              "TDpK0kqyf8hcU/VwFzslo6IEsIPk4BsTX2wEoM0YLFaybuithjqD4TvK0BqJZinAzgcpvwJoSbJS\n",
              "TdpxyclzQiCK6pUZuTxax6FUIESbPSD+0s2P/L8x7SOGxGTwI6E4bxRVegeNItHf8bNIJ5ap4+Tq\n",
              "hjiQfS2zoiiULlWPwhd/d27YgtZtjx9T7dmNznb9SndhpSTKkoSPKGAwGBtJSYWzPUo0k9gz5gVR\n",
              "4leedkfdqe6u6Tpr3Z58RESjLQR6qn0rbNeusuthz9D5asmjYWStVIWs7GBIKWar4YV+8GMAFuVq\n",
              "oFJwMbp15Vz4A5hxsiMLMkkpKT5HZPaBNBwRzV8dlq50zvdZK0ErcHQKZH5u2gEQVoSV6bJI5AYh\n",
              "xSbT5QFCarRAvU/A5EFiMorIXLsbAniiUhMZM8YwZO9fDElD4Mynjd+S8Qhw/FyTfZmKh5J/pb0y\n",
              "S0KxJe+3Pzf2c3AIQwWtIC3Rcm57w96JkWaurDTcBUogFwyei8T0LTfamR1OfCQW4yU6ewA3SwZT\n",
              "oIZKDvXZKRGkIoKHWFifFLlE6ddxWGr0COmnV8rJDvpBgSrcF6gVgO6BOFS/nqG8eJusa5SKLYFC\n",
              "F9bDmA0UHoicJVthpqNUp1gm856eXSqm4YNHA2KXNFO1X+WocZLEpRUf41IzifmAGUx6Majwjz42\n",
              "Nm09/VLQViDJXd7LcMXGfhBO6im70KMWcTDePs6/EwhlhfhuPfBkR+7qIeQEJ9MUkfGrH74ddQ5D\n",
              "x77t3dNZR5OIGxMjKpbHHrEOPKkrJMIU2GVB6JvPpeKkUoXDIVc1aGxLD2X8qqDRtww8YKs7YtOK\n",
              "IoGjjJjJItwbS/nLbSwCueTtak2ILWFxZAmJCibgQ/+Va/A3b+dxXh4eic9BGSmT0tB2uMFSFrvT\n",
              "afENEEWP2eddGDEyMbYFZaHZ45f3k1KzgQVvlCIouQeOzb3KsizM5xFUCTfwmhP4mIEOPYywKCxH\n",
              "VsRHp+BB5gvVVeScgmAf20wZRg5Gw4MlMDvqDZFjwMwI2YvFImLWhOW/P/BGYbrX+GRn0n3Z9QnB\n",
              "2e6MzpwYPa4BGwDPTC6TX47l7vWfHzxWV/5vxNIY41Ug4dsOqDL3z9KrsoU7m583Y6f/iuiftYFZ\n",
              "AXgivI9Vcwla5jFTbKLLB7Yf8SyGFHOqXUBfRX5dFVXLJMvGrBzZJUej7I39EeJmVPBMQfOIDf2W\n",
              "m+RVcDIocc5Pof90GRVd1d+bgxN8IwKtPCA94rkUobl/qvFliPKPdVQdkp+YNMSDG4650s0JbA5h\n",
              "FuaJ9OvmNRyJJ3N8Kut+AdwFi/SPDmYjgeJyeBTEkaV9+rXxOL+0bhuCx3X7LatGl+iCwyR3i8Wl\n",
              "uw5AQKZ3ToX8m6ly2gzz6duwxWQk0yisxkkJfSPGSKe3amYd2KjkpUHkd3wVAzD1lgc9e+liIcmg\n",
              "d5vgyTdY3KXsaIkSCPHBhapenoe6C17gtTIcT/fL7bggOvL2opLWKABR6JJv1XSP62WEsHAndSHa\n",
              "ryb0EGE9rwO4hblgRxc9jG0N3m3br0LouMFZEe17Yg1pvI+00Dyu0Y9NmDiAkF7E8usLaK27DZlq\n",
              "nh8h5kVYN9UensumutGIO5vrWQk6Or58MXXDw0cQHX7rj8LPZkkGgs7N7Yf4AIPUy25zfjLP/pI7\n",
              "DlL8MDFGw6W++qz1VblVbIKk2lDfR/IQclbFDIwlBJL0TD5RY8O0HxMC1BmBlJhYCtt0YN8/X19V\n",
              "NKiVlvWSoc2SbHbGQPcXwyBBk7vZs/f5HYWEjkFXKAL+XN9qwuKdLgy2g85MocSpmDyFb5aTSYww\n",
              "VZRI6h5vhnKp8SUDIVyxu6pXVQxhcD1MY+EOMVCkUfNrQmGerXDdoTRlswZNV7L7Rv1vs7qMgvP9\n",
              "LHYNh7yL4JwAX0FiM21gFbI+gTThn/SSnjKBygv2t+xey1VHkqNE7Ae6Cy5gDzHsFmvZWP0Kyd7j\n",
              "L2OOR0mVR51LTyZnU6l8NQcPAFJovT+QggDeMy/HU6o2u73dz1yNHFCtGUOGNpNGDsCPhpeSr0io\n",
              "6EweAqmFiqkixdZrv0xp1mR/oaPApBCMhhEi8axsRqC/mDex/moYDbTb5g9EKCmi3FwU+YI4zI2X\n",
              "fl+Z6a717QmL2ezG2fn4T11rHYT7GwJXXgqvX/q+FKPThFzCV3zSTaRrcFDjG9GCauADdlogUjSt\n",
              "HfqTT4oxfbMDRvWj7Yo6+acG0qhlU8vYqpMNIqrfLOGwVtYTGC9vFjVAIQLcrj4DEK9WFIDxKua9\n",
              "FfKfGMkdCpBVqMJ0Pnf8GSsblBb0J3Z3yBrL4kIQ5xadmCeOXgTr/rHqHciGv6ohy2pC5hOaw/uz\n",
              "BZ1Y4A7ya9Oa3mudMZ/VwCdhXlDzEys75YRdZieHDxYzXPW+8MavR2Cp5qaBaqXzS+6piK+SLS6j\n",
              "j8fhm7IOe0hWvh49Ur3XtBUoSAn04bRPfAovGNWF4Dy7CScdTxvoElpWLRdgQH0lBkigAfTWjekj\n",
              "8au65ZHn2Cd3rUCnfppeErDmqv5IsU6tz9Gg0hWQa8bdb+INOBaI2zO1TnCNqIPIsnawPYbGRV58\n",
              "smNGdlWplcUksY1m7iqhXHaeZAEKvxhl4bCmpBFjVd/NOfSaHuJF/TZQoZFq18xShQb5SILYvJjr\n",
              "fmEm+7QRCMhk0eH3jz5shblORt4ng5XyQziJY3Gk9PLCrszbDp3ixnsB51wm+r2vFo9ApJNnI3LR\n",
              "uBU1w/gzdq7Ta5ak+uNx9B4ao730ZGJuLYbqYNKxy4FZ9w8dFZiqJgiGP4QtCQAikPpZl4g6WNSv\n",
              "G90QI9LFiJab/9v66wqsnFJeNRz8Wl6FUcnWch2VxSEnBtJcuBNEWNOmpa/5oRST1GFsbZJdkJRH\n",
              "rWcf1ToI7z6RVvAAABd8QZpkSahBaJlMCH///qmWABsovfVMAAtyb678a+2Plu9ANtN1uqifvIm6\n",
              "7rY4tqFIZfYTypfxi+af8Zwfkl1hqbPuRmhWuGvS7WNODFpmmEwFKLrqg+6So7bYz063hMdEl0kU\n",
              "NR57zys67Y1ivy5hitieo1gygr3iUQ08wjMHlS64Emxrg0m4by3IDva8qME8WTaBsKezDGvIveF9\n",
              "ugih135q5jE7V6ZRMDiZM9oX8b0xwVhG2J+Iy4g3QRf+Yz7brQiW0lNrdBeWSXHYWXZKUYGc+Dbj\n",
              "ahVyNbvDlg/ikzYcXAkVqS8jDZ91WQSLa7nEO47cfkiV+PoyU941RWFKRNE0Y671hs+We3UL9l+/\n",
              "Uf89KlQBkPrKThV5dhr4PY8oiq1BHM7IxLTsKQxVhsj5+SwOHRYKI8YCen94VIgURDCO+XiknKdI\n",
              "6Be6gHIBZoEANk6K3W2GyoGt6T0IG69hYJULIChbtibrmfhk4xV9D/BCm/yJ6PHY6gWu40w7C92K\n",
              "teWZFdAT2XEYJdlXL6Bfx4Yy6RlO4/g1AC9z4pOHR87gSzCY2rm62/5b0LChD3GshlSNA8T2A2if\n",
              "kFrKQPhAvqFHy5eaQHbsleSGICY7/BCN2f5F/AvkrghszNx2koHT4+Fu30/ipZvo1CTvdhjYoYpc\n",
              "7rVSPdA8D3hzZELNeFcAQk7RK/4lt2bfaWPTaefx0yAXSn2DNPN+W9GuQRDBjxl9/6ur7b+kKJ/q\n",
              "N8ytq1ALQyNF2EkGiOfDXDH+MFxcPsqimcjnkYdz+aWWnofUp8cBa/lhXNs0o8/ZYHqVvEkK+gVr\n",
              "85Fm/2MgCfG0ZwG4/jnskwSGLZ//eF/t98d5KIRnpX2lXMGnmCcllwacyXv2LBNyqUlgT6ZwjYQ3\n",
              "eHN6g3DhpXzERbju3gyr+O1ifqSGSesPQoAMmCtajAQo8IH/ombrhBgniwA8JqmKTJHymHVDX10d\n",
              "sj+sclvGg/iQCIev7qFPFPLVpBsW8djEZyxQNunhLtqpo4RNAXaFADrqhhyetKJ428nC3A1MeN8K\n",
              "/wkhYx1k8RSezNdTtOzumrlk2xrzOSs/Ed1xFz9lA2yZqofSj+tiZTjFlNiW9Rh+nw/Jud6q6IzG\n",
              "a3gkElPhXKuF1ntxQTV282wwR7Zb0AUk2prLWxgxR3/2EijW2k8ATeCn2PdRqCIeJP1SMciz1NMq\n",
              "QQGZ4W7djohT4E+0IToi/raaECMzjKN+tljZtzWtHQ+i9B9eTzEDumo0AAhOxgKulIUAPCWoeE4/\n",
              "z2VB0po6Wm6ITutgroHWaTUYuLG7qsry5TTaM6vk8KcWsBy4M8ClusCfK7tqraErKrvDXL4QD6Fq\n",
              "uJ1y5VntmMf1fH30eNSk3ri2nImB4mxcnhMRnBoXdOT3wT0Yhnt6ySPmpui6Js452/zkGMraXZgq\n",
              "owvveL3F8aWbyawoxX0FDdrX6zXfs/CZdgCBuKRXzf3tT/qz4/mIS3cTWgcXmeLatzB6yfJMW+Ed\n",
              "418sT0eGvy/e9H+skQzlOxaT+WHKoGIYDPa/QqsPv7pgW4HG10MNI62rNELxCJ+/s+78FZnaW2ij\n",
              "tF3KOOh2yxA15ZpudXQ4LslgFvX3tiMIWMUke43UmVj1uCo2rOdmEE1eFWLC9EdZK4ASHykgkABI\n",
              "MSr0v9mNUlfgzYOjNQ7K6yOjEYyPD15eawB4NGpMri20Dn6xJIKMRJ1dUyussWUWGYFg41DMe0lJ\n",
              "85NBLu4Wc5/M+KRnUclJV/0/oLBpcncxU3UVjOo9Mz7R8z3UuIMiK0HJRg8j77KILYfeLhHnZ6Vs\n",
              "djkVcHCfEMfNEO6Qm801NDdGUOFHh8Ow18F7qiBHnMfLSkZXLypV9wvULDpppobdlTH90H6h2Iva\n",
              "8Nl84GGj1dbmrF7hcWimbwdXPKfUwmR3ylt9ap4jEYQ7aH3Ow6J75V4yps2vkGEqJ5L65cQtsVOI\n",
              "C6cPSpOd9IyUaNigKwecnlLMk96waigavEw9FCEtAmHlXbA/+IfdvzyRD5Bvz3A7sREI6GHDgXhq\n",
              "VwM0i2+q+jQM0QcjuV0Yc4niy0r3LWSqtJmQV1Eqr+KRxq5B03f8lXQy3mLj9U9rQ9eTAz59sqJX\n",
              "gn48s6HyD9Y377voJVdrhAlHqTy6Qq0zqdXYgZcv9wL/jaHLmKZOnqhHGPzxyp+wwojEnF58eBEI\n",
              "6MSD6L/Y1esqdf0C7ft23c5LIciLjfy5qGxDuGru5bf/RZLOiyofwhY4WtD1kxc/J8h7BtOCnalj\n",
              "pFJTgf1Kg6HMyUNHAsu4Wtr5tkztg0zb1FeIxVxpTlD9Dn4pwXyRZ4ugWmeTeWiBR1BPC0IZSKVA\n",
              "6Q+L17Qqw7lIU3/StOAjv/n7jEwpoosUyoyxYeSZfKODogUbrpLF7skZvwX5cINAQRYj4BIkdsEz\n",
              "QJ5pIp5/cqqai6TCv2UQpEoBGfGqV13bhtAWIR5hTTamOnCQ++eUVz27wZc6S+gM+7cyXL70s2Zd\n",
              "55H/l3rpiOjTTniFY9DjSrmN0KoDKsTYsciux5LI4eGMNAQzDShVRViPWKqv55Q/CKwMoTed1O5A\n",
              "6YHW30T2bOEFNoeDEtemxg6k/uIfPeMOkrN5qcf1CK9S4Q7chJSJi46aBvskh8L9UYSpnPbaF3ja\n",
              "8DlFBY2yVVKhV+SpSOTCyJMCG8Z7ZGlBJJ4+/BMQEUqIPkapwVi/Jw4rrnIOKLgVaXGXYIeWx9Bi\n",
              "0o7bic6jOtytzsDk1ddlI3F0Ug8mkGTMO7LM5lryRZQejWPceYZJj6vYMtjRRtlFfyN4neQnfD7x\n",
              "5q/bVkdijOTHJICQZ6xUlsbUjsplMs5EYt+eIqsC+ySIcy/xVNrx+3pu1c2fOBLtzZfo7bOOzdGm\n",
              "2CN7osbxOVCfzIudZTAxZSNxJBc7COaE4Mnt7pEfjiPkQBrzae5CmgIp5OowKmFh+3eGSeiEMld8\n",
              "deSmDrxzDUUEi5wCUiF1ptYhTZTtyLwk/I9ytYopJzjQPwO1+KBfTVfLYPQfKGTkxPazDZp0dkg8\n",
              "zZJVOY08i+Nh8/i/eWbCuHFG91ocYlJFfBSbCLrVpoIeV8Jm05FGOqSbWaGwxc65FN4j6d61CE/a\n",
              "YTneDQmeWu7DcwQWWwe80ktG3jfoeDbHdmGrYNexGdBQ9GCn9wu3+Dpwj1kfACIP/19+SPM3j5Gg\n",
              "QswZqL+Wrp5WZk2s5huvoJDPWe091zUOp0aTllPd7GGufkKW2yPm+sM8GilnNdZ4n6Jd67iNnXjU\n",
              "IYtNEBWzd2nTxuGDvnrWr8hB0leZr2JK6N4Om6frQLH8RFwl8nPmsUxWfb/THSIrbt8H/oUprR7G\n",
              "VQiopHYAstbuBLFYWYhweBzqP5/WNw02myermMVY4eobmT8EW4b5ZayCJZvshXJnIT7nFQZpRcK7\n",
              "oj/w+pMFFMV0OLaNBkmf7M/8PK6Vqr21wOwoI98S/aQPgQ8/P9qMwUts06Xq77Ls+cZcrLQ5FiH1\n",
              "iH9TIEeyT81HPI4KvmjoNJ2ZV2DAlXPp34Pcyuq62DD8yM6B0tIsj05wMbMB7x/Ii3cqViR9Z5XY\n",
              "46J6+Hj8EQ0/dfmk6rQUiiCIMuw2tyuBPFifwew7crNGwQiLh2JgE+5zivTOoTEqyzmIbYesB85x\n",
              "R9Y500ZYslUJq7BShMlkXgcdfWJL7JHscDNJwtRXIHlDOXt6n4OuRym6RJaAZwFcJZOJJKXIfeXZ\n",
              "tbPXtQ+rWUXxmgzfXIaQwxW+a3zGwSwa2E6MMO9ce9ROyrfqh62/yMZHbdMebmmhDPiHgfQZ7ZT8\n",
              "zri5Ev0fwhjJn60A7nkmoZVLzgsG90dNmpGCb/FN5SYeDp0ZxdMtoDthHQCI1NmmZISCTcuuSdQR\n",
              "XV6GsoLjf+xO+b1xET4gLjJ+2pUxFI9FRT0Zsz3cmn3jOz5McSNgFm+dk5qjpBJWLqgXD7hM9unm\n",
              "qpvZi/pN/ZGFZGuh2i0dGo8HFuVUZIQjvCtARRYNBVQcYktYs2tNxRJMQaD7BMTLlpjrbso3Q5PN\n",
              "vgUrLvy1SnjndZ4MPRIFz/Z2XYdewmnHry4gV/r0ov95zAi899E0SpMlngRn7Xi+3Jc8kJkGskty\n",
              "tMo2LIBKH0j9i1hiailoLGNMLLPkY7ed+Vel99VZOKowFPqpBjJ9yNMNu3QAAzykvf7WchayP+xm\n",
              "xyeRe97GPBd1SANqKOOQF0DfTBDS9Vz7kDl+5lsb5ww7PKstYS0PU4f760EFJQHfzZKNZGKSVddc\n",
              "p+u6pNsVy3UupK8kICqOfr+FrOpk+Vapo6Wl/4w3JfnHPy6fBWqA6gC3HuUeYEyH9vBy8/2uGTff\n",
              "pXUf+yECPUo4OH9Ux7dfWatw/NPULOgGGdgZC1dx03Z/XmQUYNX0M1fYu1VgrfrM5PkY20xZY15n\n",
              "KEO+FJMfbq5dTLIOOJeIGgxOPi69Nbfloz5Yfjkk9WfeLgOoiJ5ipBO7vxbf7AphEyoyrH3iNZK1\n",
              "dmbwtR8JAFYcSRtCAJDlW3TzDJ2FvGw4M9mh543apx09H+G1+jbsuvOdbAVoF7HB4RidpiUDskr6\n",
              "334Pynbejn5htH7YuMDcCH5ES05+hACA0eJvziSZ1jkGIVRN0krqBuxGq9hSAD+E7sEIglPO6n80\n",
              "Ua2rOWj/9pKG2STh6WDjtSTkoForEd7jbLgBUH5OxsdH6mineXFXbTpDZSUKIQpP1oVQDRTpASdu\n",
              "QpCg0qnPudICyqwK3AOTjOPDUAr8afVZS8C3tvOjn4pUXb30TbpVJhwwJy5IGM9Mdi/ubd7Fgutc\n",
              "6M53Qr6bmiJUsm1ZU4c1bVft/5/ixDxtWHZMB5FiROGAihpP+Cn3X2R9yRPDpZGxsvXx9LHUD9mS\n",
              "N1oA/OKXD0xknoRdoNUwY8IjuT0c/T6KIoF99LxT6rdTHlJvCL03ohxD8XwJKCgzbExBJBcdaOr7\n",
              "Yus+gyrpO/Sr6mImmGKz7mR6ZhcNF7u1cpA+smqF/mJFm6bUT2HNb9cT39twTEJ3a6opAcCIeX1w\n",
              "9QemedXGanKcfIIBxPHP+efKTdjPgrO5zLAsEHZForG4NxHgAf/Ho530GO8l6K3DfWOtW3cyHHLx\n",
              "pVgyJH7GZcyuD93tQYNax6YU67b/qFkDooY9kHkkLdnpfSCfNeXByJhU+zsCNJDaR6OiXXYYv83a\n",
              "K2iRPjDTd5qKJTf8A/WNTEaaBvCmgOqwJJBhs0cRZaNvZ6xWEDREzMsER0xBokvkxeuQ5pkqye2D\n",
              "kBCz4l75Cc1/ORSE671VdpeuB3upI5xN9r9dpuxy26RkCR1HkfnbgeMf4yN08f1n3TCT3ock9nx2\n",
              "tER3q/AJUJf0DBLIREGu6xqIWuiiHWtkiT5Gfmjv0WwONDhZoJRdEoMieILJuMwuKFaHW5M7hMrX\n",
              "TZ0WTtQOZmX0p/L2kTUn/xmXYWrFJQQxpskD6moGExi/c29AmiFkIZ8c5cESJDmzlXgbvxuu3VbF\n",
              "WL3N8pVL8/b+Jb174YHIjhTFXpPGsAMSF9t0vZs73bXXA7YYv7t2Ym760+XcXxQDb7eSktG9x/dN\n",
              "8hDW6dqmtSwGTxg6uCYTBUGet75F18yhg6Q6Ng0p+UDIUkAl1rSMSul++KEPKNDbJ6s30gPezaQb\n",
              "NybMt6H1E/78tfwen1Ol2J318D0z0IUc7QN0IC66Q1zTSRh7zzN8Z6RIS5tg1clHTE3CVK8lJcBI\n",
              "/1Z20p6pueDK3AQtkQ8BCnGiKEu6HNjazuT5blc8j6VWJhEovQFAZLU3SL7FUILGLkFsVLg5aiGK\n",
              "eaUQiHSK3VLqQX613KDTlQ/80YEObOUNisJ3mvqF/iTldCo7ReVRhzlqBWcjnim1uiOtUvnuxM3P\n",
              "cfPHOEfA8MRXBWVdpHQBVGaIwmMxQE0lXWooGeTvt8ICZuOUVkXjbtfekPtlnrGLdUy3T6AXXWrS\n",
              "Yx1XLjOEvaqCmXVtRi2qLSU6YEhNKJZ8mk7ZJSJom8IrjKFff35xhkuWWecTuFXVIVnzw0eeMyRu\n",
              "H/KgfaZtgfRmRDlX5CCSopfBglV/fzzKnzu/ksgUzKQbc37MhFrzVYn7py++iWYeVz2az6Vuulqu\n",
              "jBiz1mwoupRkIM/HfblHr7LEuqx5L5zJxS4Fox6B5nNttY9o813B/Qo/iwPH13r48IpCIWTXBTEQ\n",
              "vkvNHRkvEg0JwsSx6UP78yGmjtYkUesQOvo4OBQOcKu4KVKIulcggBe/LzL1RpRUzLCfCYwTsznv\n",
              "2IFMaKR/bNj4xY6dptAyQh/oBQrAaWTax8MBQpx/6dA6uIP8UZ9jCRKNhvl8jelB5zbku/h2iI+s\n",
              "1kK/Aq40Ba2skdjXe0sWdDQAlxH2MVHlG5PZAGVBTtJd3iqUMxPbDMI2eeXyhQbxamH2QpwIj4xg\n",
              "N9XGiyqKuLYFGOVFT6aM377IvG7BY717e+pW9ICgx3AWXD5DRv5syJuSthXsrnQMlbsf9FnqYtbD\n",
              "pyOqihnr0Rr67f1lF0ooVOKUYPvzBJtZsz+k7IOnPdK+4b7I/N9AMjVw2GVOR++u014V4dtiqfeV\n",
              "vQbWKfmg8OQwMDC6vI7Apic4aPR0BSDLQPV6J+k3wLnEnhGq6QaVwT3tPYqBB4rr8Iii2LEzr4PN\n",
              "zZ9IIsouvKs275UBxql/trnm/vKdakY31DZAlQGjJe/RQ/oYGSNXJQyTipnZfwkyf+KwOSN7QnLG\n",
              "DJvGAqA6BE6H3XHkCS9k1nqDICHf+b7T9QWrieJW5shdNL6yP27UT8My8kv993OWG2M2Urytiycd\n",
              "w4D/yFKx3Pk9NSPFrFCLU1SymF7LPBVFkd92c/2BHCH6qeCCU1GwJeiZalZpTItx1613I44X6hVB\n",
              "UmS0blfAe37JXkvZBCfdeJ1gnaZicvXQjom5sTYsp31tviNWm/NHvlrYLg63hCkfngGiIN9HWUZW\n",
              "ddKOrA0Eek+i1IBXdfWiHclZ/V6iN0+7DZwyvLjmhc9SNCNlEaMbpVMJGakLaQr0RHOBWLLH4QmA\n",
              "qcZD3llyU/DSPZMba35+LppmtAKJu3cXX7Qvezysl+/FtHxsWmaZM/8JtIvRTVvhVaDuAuaySVlQ\n",
              "5nM8QLGdwEIkmbaH77qCE7x2zQy0i2lda4+l9u5e9ryACpQekcMnXyWEtJj5Nlgfl4IvdUIne7Zw\n",
              "eVpSdoAz4svfP+NAeiFA2OQHm6EH9pdyjzy3InBdIrNfuztUvvS+ix2Qj7GTiUZjOwuFO4ybRGOn\n",
              "6OPFjgSYRrn+7+ZeWgYnQQuyHvqWRBq8tN3TMRxEOYQTMWPRo5/otmDoOUGn1sImTSgxjfutKzwK\n",
              "Yp6EB14Qc1fdQl5HYBbda716EdUkzoHNzEu0OgiwgV1TRb2ovzG+WHjm4fpxigzeRpNBeDX++WbH\n",
              "b6/kAGmU/pUeSjh3CVXnlhb0hIl0pwcSCs29+G4WlqRDdgymvs6we4eXYgQrl7Bg+lhHmOb8u4VP\n",
              "PXxAEU7f5eAJwzTet92NieUVzFwjd7TNEgU6PXuuQ9fzMRrnuxYh4h6/AMkywt8j6DJjvw3CGq8g\n",
              "g/8QUytyIEi3xE1ZkrCv9lei7L4RH0h3sB3L1LucXuOvthb07f2UdF7SmkDwJjki087cAhtJkgti\n",
              "hkXBRPAjEOqWWpMtZqTfAxlUUFcVKomIpsGQEmTpPGZW3LIvgDQQJ0c+Wf+X/GOzwzFPJrW+8rmE\n",
              "gzirh9MRXyIbkpDafrzBJV0le4pl2egUYtEkhU2Z5ChizvhIb/+f1z97i8jKJVXa8r02VGhc1wf6\n",
              "L1dC2FodWf5IJ6ntwwr+3LDxvCJ27zUwLkuFRvkg1P5wOYCwRVGsNu1Jprfd39g5RXK9cXcnACaN\n",
              "D34YcYr5GNxBcCtpzmQ4ve5Aho/uqri+UxCeE6HLVdlv7+4hCZWATJgGptrtLZuO2ans9snWWSXV\n",
              "g9EIG3v83lgTw+CsqxwF340/j6Iw1HHgfswpmF87U+i4m1OnrztD0qV6timmigtw27ip80sds/P0\n",
              "IpmyYJwAeFZtUh4cIJVUCHw1HLRTTR2P2ciJ6CnlZjVjnzgToK19eM6BAAAMFUGah0nhClJlMCG/\n",
              "/qeEADNssHV30MJszYAB0HYpHmd3UaxDjWV8xXBewOcjUtFPyl+U0TLuabzjW/NMH9/sJu7PhOCc\n",
              "xtTI0FBb4YavhSgqxJArCu2EtlbDzbNsMyvYAYilq7fXWXc5cBw/GJIB+r37rbkve1SA6dGIBgEV\n",
              "DU51sRIrO1eIEmFy8ALij7ujd9csph8LBis2rAWkID7MgjqvnJ4woLITfscYpxcZZlxuP6qlfuNq\n",
              "CF2SY/qml6aKJNhTFGzTgOXN88WlXobhzgv96Ws8WLweu5oeq7+STlVQzgEYFnZSZs0zEgEWpDkn\n",
              "bryYsYtEfY9RPhulQxK3LET79j7d1G0krcYXPDp107rurzTYtuLjrAXjwbbkhIwB/fexllAgDxki\n",
              "mZOhWy1DelVWa40ot0d8Iu5wE2ZgaMXwaKuiIw6uLMwkjdTjp1JbypiXE0IC9nolgd0/mJoUcMBd\n",
              "6BGfwKA6+NEW5wI+d8ichDI+ay+Lbj1tr17kFdUt1Ze30fNWX2AISu1+VMQxpJ3M70fW6lwjGzZO\n",
              "4Y9ZWNnuiwDotaothj0QQk+u4/inOAAkW/2w2JUH/QKboep9U0xWoBgTS6itj2LEqDsyUZEEaAZg\n",
              "yXkHczh7X+jegtOo3lU/JkVZ86FHzQjL7oulfYV60LULXlNzK2hivR9bmtXZ9cGfd8P2ZTnmehLa\n",
              "Wvg4m0Aqui5jBpk3xNV8ksNZUPro8jFM09Yc/y711w4swaE8CjbtqVozIbIFi6BAaX1oKBkyBuB7\n",
              "fVL4bFN+SJLv7LJSoFby+IP7/neJlF79gmWXND698eLMeFk3L+r3lhpdBOmbHhumUi1W8SFBi+jE\n",
              "T8F9svmrxV06B8hrv5QqwgaAVMsaoqfsIPMbi09MijmfmZwejEme05+Uk7ira7OlJq//fKAsKI1W\n",
              "3/G0gdRJkivxKFU2nb1kWZ+Wrt8mKTdIk0Hf9OB2ebxsJmDSRbOF7xGsQv28iEAox6Um63N8BYCG\n",
              "76b0AQpR72gRjp6J58offBfxD0cTm6IuC7zbyOS8N+HitEvPPDFVACLmqf7qGKBal5k4C33JyqJN\n",
              "jiXYfTrKkaEj+ehI42CBMnGiTNXVD/qKzWuAp+uFZiQMlj39k/Xs7wukcWFsOX4cF12C3A5ADW8d\n",
              "JVjuaIdwJD1gB3z8bLmY/f9u3v+bteYMaC28r1kCeEDPiBQBieRqCaK/xB3PY3KtZ7j2o7DbbyFD\n",
              "IAiRBy7FDt/E2pXkyMLtVSuq96mdc15kvnKCsgEneEv2XwoM8SNXzhAFiZoPKj/o+hOUtiQcZmWu\n",
              "AYiYfqa4NzgXpsL7n2RIj91IidqoQVkN+hCdCvm6yWrMNRk95veLuJFbrFd/yRil/JDG5GbKrCa7\n",
              "+WTEfAE/zNdKNedcaVnxxFtUhny/gB88nSVAaZyRvgxWAIL/jAPrfXgmV8+DyCWLUsGwPzxrLkCM\n",
              "Kmhy8sMNQiadv4BAsoVUCd/Fm66e42iojsp2H+s3mlsYopd8Qmq2NFEsQ00QIfBLwmXqfDEQwApP\n",
              "qBwrO1ufEATolAfatIu/qOZpSlT5xW6FQUTy+xMebhalUsYdl2YbRRcVSLJSMADz4hwP2ymcgoIQ\n",
              "itcczxa9Gx+Ts9fh4v6x9Ag1bNvB4uPmvVhilIbOA/mGXw8FaEvcjXE7DrRyu/YkRrQOnbO2w1Pu\n",
              "sI/VUZXgOQ/9yr1rm4AAzHHdkFXz+t/FOluUXej6p3aW5g/ONxg9RtXqULYHlhP/LabELW+lYcel\n",
              "WvuzFLqfq6Yx/qQsFsGy5lBzbDUZhqggtFZVkL6R+SpkRAg4195bulEhsm+Pi9b5hC1m5sWQbM93\n",
              "ZNJt5Be5aFf8lAlOfAQ9/vdBe7ex05BuWONvlj88eynbhSEA8Lg21mCqEH07Y+FX31i8YqPXF/0Z\n",
              "DIBc3o9m8UsJGdyHCo/kqI/6tGxFO5umDcJbj9HciNq10L42VeP6FvL+2ncHJLke242h15kqXAWr\n",
              "QmYy2Zqqqu7N0Gk2dXcEqi94h/iiTrBSlOfmc1Zy54Wy+5Tp5UMWHBqEsdQOwJIYd7nBNXzzzNjC\n",
              "V5qZ1FIhQPF1S6MYc6FIB9tgcG92RuhAphZdQlq5RX7Rut34fTk3y8K4QlkVN+bZdgsztFx8DXWa\n",
              "mHwq9s+K9wA9jH3OYdmpriY5jBpsKxAJRPk0PoA1wqce5ET73PIKOuOgQAD/qqTzm0xvgOB9Wf3g\n",
              "t0KtsAWEGkUcxcYRQkEiDZc+S1YSQEUtuD/h9L2uFJFQqlUabN545ssauoLuxa9h33ghF7NKALGj\n",
              "Lce3hZYzkXsbuOrPa9j977ybyBDluWDtUSfkHxG9OKQ1VUpEiDwEb6JHyNv9HFlCpPZx2QnHsxOd\n",
              "+XSbJbo4HRLHQjJjkH1cI34AMG8gHpII5ovmSDUw4XTvRSC/GN6+5as4Pak2+KAntW7FK9dmlGBe\n",
              "n7raHoRbbuPGoneZGJirMe06Z3r+xcSTnP70+JxnoprvqX51kPXwX2s/YU39bkz//FekhXzckK6w\n",
              "LdF4pdfY9Ar1yqYi70Dm9+KeT+isRhs6OWTki4tHB7HKmENiMusAq4VsrRa+19zss2Bo34qtQwNk\n",
              "5Zm+IqKDG9g1KM+Kva0xTWcb2rnHVj7DGxZhOFPEy86pS4DmKRypzhp9WCyKh9F1+vxXZ0PDe+ab\n",
              "6U8qopP6q2wUGFxPKfszSuwZ2gGaB2jJC/wmP3inICNYQz+8gWxSf+PEQmLfE+uv15VcCA4GuBDp\n",
              "zcTzCNgXGWNDSme9LEOjuhTIbYO/ngt7oBpEIp+chPqCu3W85HM1k0JHZddJm/2C86BUXtSDDR1F\n",
              "9wyprs4G00ZrmNqjDMvRT332PxzYjQ7P90pN0NiHzZxuGcfjXhZO7tEov6sAb6Ie4fIMvdxoxquI\n",
              "c8cNbzoqwdBM6aevuKPFgMiKFhI5EEei+yYflaOjil+zTMzLR6ns+9yTq0uBiPg1DicEGF6NW4nm\n",
              "j3C6JzYNGJMSOG3Fm5zSlgxh5BxlPJb4oxhrecByWVyStcaG1Mp/X2kMBggjU+mpnRmCxA2arMNs\n",
              "El4pmfN8SGkQgn0pA1L1qqU8ZTuHY4uNVTTqai5LddxEiMmGuAFLQQElAG2FMvEg1wb0Q0Ps8i7N\n",
              "Sb5GSJpKB8goTRqQyyvaOtdkp3EWz586AuuH5V5pzo2s+xV/+SQXpifbfhB3aZwNVVJZQVCvWtwo\n",
              "Xpd57JUSQ1lHq8KGhuoIystiY5VbD2RKn2MfU4FCsmzAzyeBOYOED5fXPrcQTglmRqtwynyHT/29\n",
              "BDnZeufhv4m2TvPZbqRKTPSE7xEyGAzoixxuAo6KpBs72m+/fzkA1xWYmF/yPWdISXJ5TergjeEv\n",
              "He3ocjeYaNAhH2YrqykOCQmU1SOdQmgxWQF85sIuDjSgZA5VjPkHVWdWgb4OPsGdREMtFm3zC78E\n",
              "96o8XYnG/HEDJUGdysNtd+h598COaYI3rSFAZKrEoNkL7qkw8l9Q8KW7sLzFWuNT/g7QvDmQgwgJ\n",
              "3ESK92cCOcmaJKoQ97/Y3XbNYtUj0FkQ58SokbuH/YUrdktcDvy4A3a2dgPMbKHhMQkAYtzw/J5F\n",
              "qEVXCqVdkogJZ3u0C3IHWFTwMk23ZlFwKlbtlbGVDHtFEKlHyKo4rVqXN4QZBGlcFiKaQTQ0deVc\n",
              "E9Ky2HzlFeqUi8JXSirfRD2pIdRLFd3mrq0CHrlE9rCfJ52SzUVBXRczjvgoMfWU3rTWSRh93OKr\n",
              "ykNe0fHAW/gKR9DDQy+5wL1eEjHmOpMwwavwMig6CrnXcfI4l1HRtwT4JjsiBY6oQkr6f/f5mbqd\n",
              "a72YuBFb0591JLvMLgfov1SpoJSA/3K9K48BDP3/zC+n+M6pMpGuP4xIs10Wvx8xWXwL5WwRGYrH\n",
              "ioEb5JpXbReAlz3s891ikZ2ssubXGX9OxEBDqmN35dpVuOl5swW8A+io62vQu4ot9J/uQHVnEPCN\n",
              "+Pa4sKdn5yAqEp5blBDvP0H+YRI+VcEmsihUSciz/M4YB6yCg//S0gPYjRQTtc1CF38++JxiQjlR\n",
              "CF1IKEtZ0i9PWD/+4CaS8dqwcaocHUB8aXadxox9sApSsd8HC9oG0zKqYkVEeE8HjUD0f+a8FJ+I\n",
              "iuhgQQAACSFBnqVFNEw3/wATWFvUnsyRQALoodS2v46n62cYlYwU0FQuhF2PTmPj+khURpb3MjIr\n",
              "qr9sZsp5WTecvND/DfpGE8nNfR7RzPlKAgoZjJpteejB42M8WlndTDGlUQfe8pW6OIcGksi2uwdv\n",
              "lDjaTw3CEvPJXnbQ0BEAp3MaLkWe5RN9EQlI7ZvRol36lh4km0tqsxy85lIT+f5VDludu3YPQLWp\n",
              "0FMT1GHTBuTmWrxT+JHTs6mZeQTLaBy1WtZnzfjXzSU1QwyfA6tQrb2Iuuv/vDO8pJVzeGO7mDuL\n",
              "1JkYrAE2SwTMBmzH1BqbYpSS17BByE3xlULnyH0R8Oli4XMzQ7aNO6beWzeETOOOErdQVfW9dpGY\n",
              "KjEHitJR1WqJKFtCRk/pQzyaxpg8/HBekDx1sj3LmMyknd0BAkqFJaJmHIRcKfXD86jTEpEqkVBc\n",
              "SlXmo9+9F632PHJt44HVyYKoQkNPfYIYzze1IZ0Zx0c8sGNh+FBNqRLyzZT44XI5zQA8bhaLiM5Q\n",
              "NE13bDTDiQC3ScXjK1Y1BSMZK0a7Eac5ModjS7Izi+kuc/GP5kkYepkuLX2PSJburqs5bpXYZOfC\n",
              "yo+qm4FcwKH++iD0dhaBTDTgevNm39/MKWeDt2K8EbAH1uSp3+90a5ns/bRaloy9sJRNMIISWnFW\n",
              "fRas4NJZSuYrAQYKE/g0BfNeAWtdhrvaf4PfjEi0yItXwvZPKfBM8yL14uBjl2+1cSTNdh53pVy0\n",
              "GQxN4+hXzkwnMlwjAXQE7hIoTxQIVYkVQcqj4YsJEixt/1nw/gbNziPQ1QEtr2aZpAUeTQGQxOg7\n",
              "syny4Ge6+ol4ceBFxFQlhvWmlNZngNh0p4zMy08fxpMTKj2I6zjtsMrcgTXtT0s2G2vmqcoQzIGU\n",
              "CKagRJ9xKTpXXjzbhbZw8gfjLVwAjqBOH4Rlr4WC7+eMHO/S4GBiyQVzJR/w5Kw10XO/KLfDgsVz\n",
              "k+h+4J242xR7tPIH/wjj37kvrlYyDGFHm2tlkdYCLRbnjHV4fhlJyEirUJ46cZRqmGuilMj7zBp5\n",
              "MxSzrxU02jEIAixR9Lg2g66nfQk5IU5yFH8T0cAsBUtYGJFUXiaqDH79gb/O5K8noSylnJ6hb/xV\n",
              "wWTXpcP7euac4c8qI96ysm307Aybz7ms0TtdVL0QXOLAUJjdderUZGk0oIpaihtkJl0ybnM+IObZ\n",
              "1PXOrQwCZFkMmH92G7FuZGyw3G+mmoZg0vNM49x8+r2okPHQj/pTNJiGOnQ9nIIAi7OKSPQjV9S0\n",
              "BI5WOEjtkkfXhjqiulV8tlSh+FTdBR1i+R7i9sW7z+AqEtYlA8S4rS6pERPGkD2WOeh4EHx3hhoz\n",
              "VxO2NquOFrujZdw8x90aIKT0eFv64m0pO8b2mK78hRDJasNMdmoQX9UNuLvGibtvTa8dZsuVLMvs\n",
              "XiXgZPNjcCF9OwfCWUEBWC3nMp5PuIrA+qpoNNRtOQM9lTzBfxcn+YxxEvdypviLQ+sKjJxzjoph\n",
              "BbihTMu/yhHw4/nnev8sj772JUXuhs5/AJln5KW2jZD7j6XFLRKPS1SfX+ic6FbH1LBiREZ4shR4\n",
              "LG/Qv4wYNIzE56ZzkDhHjahpR6tclc62B49Ft79anXFA0y3jU6/kPr/dAjbGGDOvuNwQ20zeIm0O\n",
              "0CKVdtiRgfjWIE66iyhLtn4DO2HReHUKYcTAYmxTBaOOgSVOabBSMET6aecmnDYS8YEBBBb3MllK\n",
              "Uy3sR64ufvSEJZSXH7DtdAcw/60en4oXC4+zmPSUuPFuZ7LtL8VfXTXebgYNijn1LP1RMHn78quB\n",
              "+JwkiQT2rqM0JZsgJ2+GebEf+tA2SYUCJakp+KVi7658IYe+9WYTe5kKLhNIXH4wnnRq1wXSI738\n",
              "CpKHJ7aYfD6oAAHueEN04pwMusaUzlvtltvmFs+XStB2UcR2Npm+RzbTjddxrMtrx5bKvoyo5Yec\n",
              "W0Y206aivP8g19ftgnmzOMl3MuqE/Aiun7v40cfMLuNSxMECLMc6MKMCuqPSrUM+6mBO0ldU8jU0\n",
              "/FpxXgr8M76WOGIKsP3eCS1Uv2SbOmK8uaUPNfKBm7QtYVq9mvMhLMtefnEeM/BsuNXR57ahr+Js\n",
              "Um47O7QaVhEnBE++8COCT9DATcxykJKYnkAqbf6gV3rjZI1R6FVsnrAvxUTZMLYPXcjtAjMfTgmK\n",
              "sK/Cs3/5C4hwm6LXzQkI0rAfKkNfPusBkpc4um5r8KDdTuHxKkzFvYFilkUK8p7aOy46OoxZm9kf\n",
              "8T4cUbOOHv2Zyl8v2QHYokSMOHQLG6J9nZXyg94b38w/v4H6Fw//vnd2yVjlIb+SEfD2UCjPHF9V\n",
              "/2CSNWTG0ngAVm0oFaeAGN/r55vsMcB736oiHsagN9YyhZEIyxbW0EMD2Af4+KWHCyUobzGaBbA2\n",
              "WiBqETC9EQxhLeZ9PdY9PLbWZpmhWc+ekAHMIp2HZRal5u74NPlwLXGf/DfBANYlYbzU7ZyKiEgL\n",
              "wMU0a6Nn0bt4Ennh569ZIX3kJMhym25M9Pb7o7tUiOTLj7/WQkD7HSauTVMKlpESHddsAS/tH94/\n",
              "VplTkvjIDK9k/JrjO9kF0obLVG7xcTmYOKoRpYC0nDNOwyaFqV+BdwxSlRsxYUsbHV8jbqenm42o\n",
              "/Vm9p66h298SIKdnWZveNXniu7Gb3+yNNhHvd35DlHbYDCXc3h/Ma4oOwK1x6ugS3WLd3ySEznUp\n",
              "8UqRbZPd7TfIs/3HQnyoJwc0tVJ4IscrO6LpJa+0wVN/A+OJAmd/sxbv1Q/kMkvVsjala/b35IjL\n",
              "LdvblPi3l6gJpUO+et1srcPdz0g0di6wVl5mdO68CVEb+iSOegIRnou59/eS/slZGcoTZ3I2tIqt\n",
              "ialA7mgur6Qhb8nsPdEmQmC7vX6U+DK/nzYbdigS6RPyiVGg8UiYp24QumwtxDifxqdLLrAhvsqj\n",
              "v3J/iSWtwH995/ctLjdIypSc/rZv8yy82Ul5DT3JYAuBRxn88PAfq+NhIUf0ypwx7B/2yJcHzv85\n",
              "lH/gqUBHfwyS9KQsq+sZKPKTMb++47EqjIOnHGz5KblDtI0600rnoaRM8ZX1HXqO9f7plcr6ZVyY\n",
              "MMvBUXLwgcEAAAkeAZ7GakN/ABNahHaH2/O0/vcDEB924ooP3rwAEGFpt8EZ2V8Pb5zFOBUe6MiH\n",
              "GkU7cfXzvD3+n+vQnIZ1VplrugdkatrrIUozIcR/yNRL2YXoroiCe5SzYQnxnLjKjQuvkL2e4UT5\n",
              "dNAOWLiji/FJUmtGg2NpTveaHudw5IplI3qlP9rttiEMej8AuPGoEDoN3ZljEw0L6KliQYUYKXJY\n",
              "HNvo5KEFXEjI4CP7jtw3rSJy1HL6JhHciWgCd0GzrqsiaDwrmxREkwKkVZILnGCIKLw5Iiiv9wq3\n",
              "GAyxuIvde0cs0kPPB8cApErNe3mnXtLXhGAVe4CfQou/lCbH2Q6Mwj3YFQRhjCCokKtwv8XaE1xR\n",
              "cQV9atgijApYgRo7Z1oYNC9SOuehRPSdtWWkcNgi5ENfnp+CbbyYpz44Rx9SdMpfnxLV8MYC3y3A\n",
              "omFE9SYFvHo6XOsSP4IeNy01evMnxXPaKHtOJpOayqeoUabv2FvHh3afSHUR+qaFHuhEkXGbAxwv\n",
              "6Kgm1rx6yETPNoyRmw0HOsp4VN/6FIhfTW6FORt9VKfmfdOqt6GVQTUtMrMdSKJN+/nTpDHNiciD\n",
              "B3c4Rh5Thb1NTJKGqvJT1D7eYODSWcwgzgi5oQ87Gspiys4mZY5iHtUOh1N69pBBaPdn7AlKAZRH\n",
              "V1PdAD/ywebzKdK+cEs/kXZO8ZCU5cLjJWX14pevtP0elbEbS8baggSvRoI09VacGWZbOpyZ0aI+\n",
              "O39yJxuo3TpL+4aQvYeQPQ1/bumZ+yEccGerY6MM21A+3sGPSaH8je1plQM0kG4S19DC6G1PtKcl\n",
              "osfaST2r+QUjSj0MmXk0PSnsvwqsf37WWF1/2UOXDicxB2OqhlzcqHXqBfpvQDxmKcxsadLuNnE4\n",
              "2T/2BwwVHvw1NejzIu4roVfmFWtFkBFLzcqLSAISJd3BmBVbdZPb1KYpwvKgs5LYzP28ZPWv4Kmv\n",
              "rgeUWJrfnSOsKpePm3ys21VjkKFn+aBY2wVI4b5QQbd3H75eHfqSfFOBXNtsOkwZwWATs5hfqEmJ\n",
              "YWCLoCtecbXk148dAtLLH8mUpr41bl6qf7LO8NyEbS6afPoEArqXp30bXedwyKTl572MPvSr/4WG\n",
              "ln4JepFcz4Sk1JymHqvmJT+Y9FM+DIdPUzXFzphP10SPVf8ZA1XkH3ya8XlhIPGw4McD90CXgFG4\n",
              "lChdO71bWtAkdzCnIs6YzrFIfspX3wsYQw/GhuIgO76/2p6zau6MeYbKzde+x+j5Ls17GasGAJvd\n",
              "pJ+bVGM9i/0USlWACxNXXuZJ6Dg+9+DOhjR2MGbeTh3RNt+N5/v5e1Vfc1QK/15yx1sLoGfo6Nwb\n",
              "Zjpa4dfP2eL8ziUj/XGv0R+WlF3jzOCVeaKJuCFCLk+Htse6tyTHlCFtmBBz1SagGTZSIxHSKG7y\n",
              "CSs8Jr0AP+39EAcsFuP1QTydzhIbhdfli3nIJVYE6bsgtMOWT+gHGnC40kOHUD4/8f1NyQwnJbh5\n",
              "7H+cwbznP6XSZeQSOgayUOlflUMnv6sriw4EgUBie4HVmrZXe62CBpPGgY7BkS7qwiRMov+JMfLQ\n",
              "DIJ7LbRDWjttN5KYnnU5q2laswFcM9CnZHSJVdg2SjT/DqfZhF0t0WpOp3bBllFl4v7GLzkmP2te\n",
              "OEsGsz9r4DaW/+Mu5mmvEkZHeFkqKT9FBirbkZfuIZyiEptC7w1ZsJYnqZvZdnSAaWoJ5bVhzlCf\n",
              "GwKD5wO9JHpgrbWa01wKof33FaQlgVKX2PMi43EqP4+pxThT3CCtiPEK4S1pr8U3CrY0dhu4licR\n",
              "okAa/6J1tMw2QDGoMp/H3X+ePTyl7AG8pbst4nzrZMn+ILGTK4g/JjlKkGiXHREDauXQE5jpkt1L\n",
              "xoo3Lnro3ezLJBch1xIZyPsGV6e3HlQj2aED4OAmbl3WwcOkhioziwHFtOYp6hjrLAAHAyXrnaEh\n",
              "I6VoTBx2SI2SNmDg9Gqd4keYFb9R/QrXgIN1IvHifFKjoYgA7v+iFzENMaZeh4D0RwDTQUHMgt4x\n",
              "1whK8NjfpIYud9un3qXcXNdEouVzEcJ7AKWMCz8zFNJ12WVzQ4F059Q1hbgxIGWT1NEIz0qs8odw\n",
              "hxU1dZT2cHqIKrWITqkvk2u7LVrDII4mJHu0vECYomBKirnNDVwJLHWvAm/watBW38HZFYH9/UPm\n",
              "TXfisHvsnT/LSYhEmB9L5IMWZgLRwFhh8A0LJGHbt11tBtx3KYtWOKB2xJzCGDVaJnfx93hhC6Yf\n",
              "+9XfVD9BSkOTS6VE958ITgF8eG+UnPYyQBheGspevFYacGzry/3ixD9h3Hdohd0Z93CN1fTpbdkg\n",
              "NRHc9da9wVTeJBHw//aast7FF/7V0N0XaqMUPz79p0zildJsXAGnYBTs6q74lofJW9dN3ua8gPp5\n",
              "pOCA/PBBfmC1wX4ZCKESR08UnaCitoQyp27sgdVsAvIYZ8u6IGgMeLSOv5WbyW+lIvOo0tlfQ/JL\n",
              "e+Yrq16p3U09kpCfVhrTVooROGGCojt5h9K3NU2fQpNBg6gY249VCbpVc7gQS1lkEQdHQqdW1KTn\n",
              "G9KqVytAlrF2R426ozG5tmQaRVFc9j5nhpggDeL3wWfta9FAs/g196PHDULc/dFUKX99EHmzNybl\n",
              "fflnek/0I0Pcq40DfQmz8m9UxOnlQFtR2v8ntk4WQe/vKCyScEBU5uDGSa3b146pqj2oy6PdjToX\n",
              "p8UFPRghmjHZAYXT8ddT9sZwRdNilYUw1uDQgqc7jClzG9bbUp3MraXsaFs/DAs/CrQdL3XRJ3tb\n",
              "UX5gtgZD8OSt+mi2e+horOqMEyjW6HnxsfWqZ+NEaV5+pANPbGvm0jS3bMSzEFYnjWAkf3h8azp+\n",
              "WFmgRs3enUcJDs9EWVTeXB5nBFnrG78oXm2/TZJFFGZ+sjLLXMjnXmz5sBZ/psV0rYOie3HOw9Dj\n",
              "w8kxEmpAH1Wl0/SXqBUBtl3nwb+0pDIFoO+jS+P6JAqNBKDBTYFVHxqUcOpYfLQMPKDP+zE3XMj4\n",
              "YZQ2gIxjTW7Uu6RT9iSh0ezsNWcdJRdTgIywzOENV8LaOVPvJB3RtNU/6Qi7zs+wtxAhQ+L8VuLn\n",
              "9LZEp1ku8kzBAAADfm1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAMgAAEAAAEAAAAAAAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAIAAAKodHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAMgAAAAAAAA\n",
              "AAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAKAAAAB4AAAAAAA\n",
              "JGVkdHMAAAAcZWxzdAAAAAAAAAABAAADIAAACAAAAQAAAAACIG1kaWEAAAAgbWRoZAAAAAAAAAAA\n",
              "AAAAAAAAKAAAACAAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5k\n",
              "bGVyAAAAActtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEA\n",
              "AAAMdXJsIAAAAAEAAAGLc3RibAAAALNzdHNkAAAAAAAAAAEAAACjYXZjMQAAAAAAAAABAAAAAAAA\n",
              "AAAAAAAAAAAAAAKAAeAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAABj//wAAADFhdmNDAWQAFv/hABhnZAAWrNlAoD2hAAADAAEAAAMAFA8WLZYBAAZo6+PLIsAA\n",
              "AAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAAAgAAAQAAAAAFHN0\n",
              "c3MAAAAAAAAAAQAAAAEAAABAY3R0cwAAAAAAAAAGAAAAAQAACAAAAAABAAAQAAAAAAIAAAQAAAAA\n",
              "AQAACAAAAAABAAAQAAAAAAIAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAIAAAAAQAAADRzdHN6\n",
              "AAAAAAAAAAAAAAAIAAA0cwAAF64AAAsHAAAI5wAAF4AAAAwZAAAJJQAACSIAAAAUc3RjbwAAAAAA\n",
              "AAABAAAALAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAA\n",
              "AAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMjkuMTAw\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example = test_dataset[0]\n",
        "\n",
        "# convert to image from proceessed tensors\n",
        "clip = example[\"pixel_values_videos\"][0] * 255\n",
        "clip = clip.permute(0, 2, 3, 1).clamp(0, 255)\n",
        "\n",
        "# np array with shape (frames, height, width, channels)\n",
        "video = np.array(clip).astype(np.uint8)\n",
        "\n",
        "fig = plt.figure()\n",
        "im = plt.imshow(video[0,:,:,:])\n",
        "\n",
        "plt.close() # this is required to not display the generated image\n",
        "\n",
        "def init():\n",
        "    im.set_data(video[0,:,:,:])\n",
        "\n",
        "def animate(i):\n",
        "    im.set_data(video[i,:,:,:])\n",
        "    return im\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=video.shape[0],\n",
        "                               interval=100)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b644b2b-edf2-420e-9b11-c7c5f87eb09a",
      "metadata": {
        "id": "1b644b2b-edf2-420e-9b11-c7c5f87eb09a",
        "outputId": "31f4b52c-a83a-467f-d6fe-f0c4a13a6af4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"<s> USER:  <video> \\nProvide a detailed caption for this video. ASSISTANT: The video captures a serene and contemplative sequence featuring an individual seated on a wicker chair beside a window, within an indoor setting highlighted by a white wall and decorative framed pictures. Dressed casually in a red top and rolled-up blue jeans, revealing bare feet, the person begins with a relaxed posture, hugging a white cushion to their chest, their chin resting on it while bathed in the soft, natural light of daytime, setting a mood of introspection.\\n\\nAs the video progresses, the individual shifts slightly in their chair., displaying a subtle change in emotional state or focus; their head tilts forward, eyes cast downward, and the grip on the cushion tightens a bit, which might suggest a deepening of their reflection or a shift in their feelings.\\n\\nFurther into the video, the person's facial expression changes as they close their eyes, possibly indicating a moment of deeper reflection or rest. Throughout these transitions, the surroundings including the white\"]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.batch_decode(example[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ad57e3-bfee-4099-8725-286220c8d52e",
      "metadata": {
        "id": "85ad57e3-bfee-4099-8725-286220c8d52e"
      },
      "outputs": [],
      "source": [
        "def run_inference(video_clip, model):\n",
        "    # Let's use chat template to format the prompt correctly, this time without the caption\n",
        "    conversation = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Provide a detailed caption for this video.\"},\n",
        "                    {\"type\": \"video\"},\n",
        "                    ],\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    # Set add_generation_prompt to add the \"ASSISTANT: \" at the end\n",
        "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
        "\n",
        "    batch = processor(\n",
        "        text=prompt,\n",
        "        videos=None, # we have a processed video, passing it again to processor causes errors\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "    video_clip = video_clip.to(model.device)\n",
        "\n",
        "    out = model.generate(**batch, pixel_values_videos=video_clip, max_length=MAX_LENGTH, do_sample=True)\n",
        "    generated_text = processor.batch_decode(out, skip_special_tokens=True)\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb9b7f7-e1bb-4e2d-ab41-5ecd841efb54",
      "metadata": {
        "id": "1fb9b7f7-e1bb-4e2d-ab41-5ecd841efb54",
        "outputId": "5fc121d0-0267-43d2-ce4e-9464da628cb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['USER:  <video> \\nProvide a detailed caption for this video. ASSISTANT: This is a video capturing a serene and introspective moment of an individual sitting next to a woven basket, facing slightly to the left of the frame, suggesting a focused gaze towards the distance. The person is elegantly dressed in a red blouse and faded green jeans, evoking a simple and understated aesthetic. A white wool material is wrapped around the legs of the chair, potentially indicating an interest in outdoor or vintage textures. The background is muted, providing a calm and unobtrusive setting that does not distract from the individual. Throughout the video, there is a gradual transition of light, with the shadows becoming less pronounced and the lighting more even and warm, suggesting either a change in time of day, a movement in the light source, or an indoor setting transitioning to an outdoor one. The person shifts slightly into a more natural pose, with their right foot raised, indicating a moment of relaxation or conversation. This subtle action, along with the progression of light, results in a softer overall appearance against']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_inference(example[\"pixel_values_videos\"], model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f6e968-affd-488f-a7f4-26e57a22993e",
      "metadata": {
        "id": "95f6e968-affd-488f-a7f4-26e57a22993e"
      },
      "source": [
        "#### For the sake of comparison, let's load the old model and compare the generations\n",
        "\n",
        "We can see that the tuned model started to get the ShareGPTVideo dataset style where the captions are more detailed and longer in length. The tuned model generates a more descriptive text of each scene and pays attention to the changes that happened as the video evolved (e.g. \"there is a gradual transition of light\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e262ecd1-2d26-4011-b05a-ddf14936d8ea",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "135fcebf7d064b4ab77cfcb059e98e1a"
          ]
        },
        "id": "e262ecd1-2d26-4011-b05a-ddf14936d8ea",
        "outputId": "9ccf1fe1-83ea-4ba8-d6bb-bdd13aca101b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type llava_next to instantiate a model of type llava_next_video. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "135fcebf7d064b4ab77cfcb059e98e1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "old_model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c2ea6a-0633-42db-b7a2-ebc3406c473e",
      "metadata": {
        "id": "a8c2ea6a-0633-42db-b7a2-ebc3406c473e",
        "outputId": "92c6539c-0cdd-4d62-8bb6-3c42aa49d3f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"USER:  <video> \\nProvide a detailed caption for this video. ASSISTANT: In this cozy scene, a young woman finds solace while sitting comfortably in a wicker chair. She's snuggled up in casual clothing, her legs bent and her foot resting on her other leg. Her gaze is directed off-camera, suggesting she may be lost in thought or perhaps engrossed in a book she's holding in her hands. The room is softly lit, casting a gentle glow over the scene and enhancing the overall sense of relaxation.\"]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_inference(example[\"pixel_values_videos\"], old_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae77b34-05e6-44e1-9d1f-9cdda5883ffc",
      "metadata": {
        "id": "cae77b34-05e6-44e1-9d1f-9cdda5883ffc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env0",
      "language": "python",
      "name": "env0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}